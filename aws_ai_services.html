<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS AI Services Interactive Map</title>
	<script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* General Reset */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Inter', sans-serif; /* Using Inter font */
            border-radius: 8px; /* Applying rounded corners to all elements */
        }

        /* Body Styles */
        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            min-height: 100vh;
            padding: 20px;
            color: white;
            display: flex;
            flex-direction: column;
            gap: 30px;
            align-items: center;
        }

        /* Container for overall layout */
        .container {
            max-width: 1400px;
            margin: 0 auto;
            width: 100%;
        }

        /* Main Heading */
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.8rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            color: #ffd700;
        }

        /* Mindmap Layout (for AWS specific content) */
        .mindmap {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 30px;
            width: 100%; /* Ensure it takes full width of container */
        }

        /* Central Node (AWS AI & ML Services) */
        .central-node {
            background: linear-gradient(45deg, #ff6b35, #f7931e);
            padding: 20px 40px;
            border-radius: 50px;
            font-size: 1.5rem;
            font-weight: bold;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            cursor: pointer;
            transform: scale(1);
            transition: all 0.3s ease;
        }

        .central-node:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(0,0,0,0.4);
        }

        /* Main Branches Grid Layout */
        .main-branches {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            width: 100%;
        }

        /* Individual Branch Styles */
        .branch {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
            padding: 25px;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .branch:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.15);
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        .branch-header {
            font-size: 1.3rem;
            font-weight: bold;
            margin-bottom: 15px;
            color: #ffd700;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .branch-icon {
            font-size: 1.5rem;
        }

        /* Sub-services (initially hidden) */
        .sub-services {
            display: none;
            animation: fadeIn 0.3s ease;
        }

        .sub-services.active {
            display: block;
        }

        /* Fade-in animation for sub-services */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Individual Service Item Styles */
        .service-item {
            background: rgba(0,0,0,0.2);
            margin: 10px 0;
            padding: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .service-item:hover {
            background: rgba(0,0,0,0.3);
            transform: translateX(10px);
        }

        .service-name {
            font-weight: bold;
            color: #87ceeb;
            margin-bottom: 5px;
        }

        .service-desc {
            font-size: 0.9rem;
            color: #e0e0e0;
            margin-bottom: 10px;
        }

        .features {
            display: block;
            margin-top: 10px;
            padding: 10px;
            background: rgba(0,0,0,0.3);
        }

        /* Feature Tag Styles */
        .feature-tag {
            display: inline-block;
            background: #4CAF50;
            color: white;
            padding: 3px 8px;
            margin: 2px;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .feature-tag:hover {
            background: #45a049;
            transform: scale(1.05);
        }

        /* Feature Details (initially hidden, expands on click) */
        .feature-details {
            display: none;
            margin-top: 15px;
            padding: 15px;
            background: rgba(0,0,0,0.4);
            border-left: 4px solid #4CAF50;
        }

        .feature-details.active {
            display: block;
            animation: slideDown 0.3s ease;
        }

        /* Slide-down animation for feature details */
        @keyframes slideDown {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Sub-feature styles within details */
        .sub-feature {
            background: rgba(255,255,255,0.1);
            margin: 8px 0;
            padding: 10px;
            border-left: 3px solid #87ceeb;
        }

        .sub-feature-title {
            font-weight: bold;
            color: #87ceeb;
            margin-bottom: 5px;
        }

        .sub-feature-desc {
            font-size: 0.9rem;
            color: #e0e0e0;
            line-height: 1.4;
        }

        .feature-nav {
            text-align: left;
            margin: 15px 0;
            font-size: 0.9rem;
            color: #ffd700;
        }

        .use-cases {
            margin-top: 10px;
            font-size: 0.85rem;
            color: #ffd700;
        }

        /* Modal Overlay */
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.8);
            animation: fadeIn 0.3s ease;
            overflow-y: auto; /* Allow scrolling for modal content */
        }

        /* Modal Content Box */
        .modal-content {
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            margin: 5% auto;
            padding: 30px;
            width: 90%;
            max-width: 800px;
            max-height: 90vh; /* Max height to prevent overflow */
            overflow-y: auto; /* Ensure scrollability within modal */
            box-shadow: 0 20px 60px rgba(0,0,0,0.5);
        }

        /* Close Button for Modal */
        .close {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
        }

        .close:hover {
            color: white;
        }

        /* Sections within the modal */
        .modal-section { /* Generic section style for modal content */
            background: rgba(0,0,0,0.2);
            padding: 15px;
            margin: 15px 0;
        }

        .modal-section h3 {
            margin-bottom: 10px;
            color: #ffd700;
        }

        .pricing-info {
            background: rgba(52, 152, 219, 0.2);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.9rem;
        }

        .scenario-box {
            background: rgba(46, 204, 113, 0.2);
            padding: 15px;
            margin: 15px 0;
        }
        
        .config-options li, .troubleshooting-details ul li {
            margin-bottom: 5px;
            list-style-type: disc;
            margin-left: 20px;
        }

        .llm-action-button {
            background-color: #f7931e;
            color: white;
            border: none;
            padding: 8px 12px;
            cursor: pointer;
            font-size: 0.9rem;
            margin-top: 10px;
            margin-right: 10px;
            transition: background-color 0.3s ease;
        }

        .llm-action-button:hover {
            background-color: #ff6b35;
        }

        .llm-output-area {
            background: rgba(0,0,0,0.3);
            padding: 15px;
            margin-top: 20px;
            border: 1px solid rgba(255,255,255,0.2);
            min-height: 50px;
            font-size: 0.95rem;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
            display: none; /* Hidden by default */
        }

        .loading-indicator {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: #ffd700;
            animation: spin 1s ease-in-out infinite;
            -webkit-animation: spin 1s ease-in-out infinite;
            margin-left: 10px;
            vertical-align: middle;
        }

        @keyframes spin {
            to { -webkit-transform: rotate(360deg); }
        }
        @-webkit-animation {
            to { -webkit-transform: rotate(360deg); }
        }

        /* Responsive Adjustments */
        @media (max-width: 768px) {
            .main-branches {
                grid-template-columns: 1fr;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .modal-content {
                width: 95%;
                margin: 10% auto;
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ü§ñ AWS AI Services </h1>
	
        <a href="./index.html" class="fixed top-4 left-4 z-50 bg-emerald-700 text-white py-2 px-4 rounded-lg shadow-lg hover:bg-emerald-800 transition duration-300 ease-in-out text-lg font-bold">
            &larr; Back to Hub
        </a>
	
        <div class="mindmap">
            <div class="central-node">
                AWS AI & ML Services
            </div>
	
            <div class="main-branches">
                <div class="branch" onclick="toggleBranch('ml-platforms')">
                    <div class="branch-header">
                        <span class="branch-icon">üèóÔ∏è</span>
                        ML Platforms & Development
                    </div>
                    <div id="ml-platforms" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('sagemaker')">
                            <div class="service-name">Amazon SageMaker</div>
                            <div class="service-desc">Complete ML development platform</div>
                            <div class="use-cases">üí° Model building, training, deployment, MLOps</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('bedrock')">
                            <div class="service-name">Amazon Bedrock</div>
                            <div class="service-desc">Generative AI foundation models</div>
                            <div class="use-cases">üí° LLMs, text generation, chatbots</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('codewhisperer')">
                            <div class="service-name">Amazon CodeWhisperer</div>
                            <div class="service-desc">AI-powered code generation</div>
                            <div class="use-cases">üí° Code completion, security scanning</div>
                        </div>
                    </div>
                </div>

                <div class="branch" onclick="toggleBranch('vision-ai')">
                    <div class="branch-header">
                        <span class="branch-icon">üëÅÔ∏è</span>
                        Computer Vision
                    </div>
                    <div id="vision-ai" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('rekognition')">
                            <div class="service-name">Amazon Rekognition</div>
                            <div class="service-desc">Image and video analysis</div>
                            <div class="use-cases">üí° Face detection, object recognition, content moderation</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('textract')">
                            <div class="service-name">Amazon Textract</div>
                            <div class="service-desc">Document text extraction</div>
                            <div class="use-cases">üí° OCR, form processing, document analysis</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('lookout-vision')">
                            <div class="service-name">Amazon Lookout for Vision</div>
                            <div class="service-desc">Industrial defect detection</div>
                            <div class="use-cases">üí° Quality control, manufacturing inspection</div>
                        </div>
                    </div>
                </div>

                <div class="branch" onclick="toggleBranch('language-ai')">
                    <div class="branch-header">
                        <span class="branch-icon">üí¨</span>
                        Language AI
                    </div>
                    <div id="language-ai" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('comprehend')">
                            <div class="service-name">Amazon Comprehend</div>
                            <div class="service-desc">Natural language processing</div>
                            <div class="use-cases">üí° Sentiment analysis, entity extraction, topic modeling</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('translate')">
                            <div class="service-name">Amazon Translate</div>
                            <div class="service-desc">Neural machine translation</div>
                            <div class="use-cases">üí° Real-time translation, document localization</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('lex')">
                            <div class="service-name">Amazon Lex</div>
                            <div class="service-desc">Conversational AI chatbots</div>
                            <div class="use-cases">üí° Virtual assistants, customer service bots</div>
                        </div>
                    </div>
                </div>

                <div class="branch" onclick="toggleBranch('speech-ai')">
                    <div class="branch-header">
                        <span class="branch-icon">üéµ</span>
                        Speech AI
                    </div>
                    <div id="speech-ai" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('polly')">
                            <div class="service-name">Amazon Polly</div>
                            <div class="service-desc">Text-to-speech service</div>
                            <div class="use-cases">üí° Voice assistants, audiobooks, accessibility</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('transcribe')">
                            <div class="service-name">Amazon Transcribe</div>
                            <div class="service-desc">Speech-to-text conversion</div>
                            <div class="use-cases">üí° Meeting transcription, call analytics</div>
                        </div>
                    </div>
                </div>

                <div class="branch" onclick="toggleBranch('business-ai')">
                    <div class="branch-header">
                        <span class="branch-icon">üìä</span>
                        Business Intelligence AI
                    </div>
                    <div id="business-ai" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('forecast')">
                            <div class="service-name">Amazon Forecast</div>
                            <div class="service-desc">Time-series forecasting</div>
                            <div class="use-cases">üí° Demand planning, financial forecasting</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('personalize')">
                            <div class="service-name">Amazon Personalize</div>
                            <div class="service-desc">ML-powered recommendations</div>
                            <div class="use-cases">üí° Product recommendations, content personalization</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('fraud-detector')">
                            <div class="service-name">Amazon Fraud Detector</div>
                            <div class="service-desc">Fraud detection service</div>
                            <div class="use-cases">üí° Payment fraud, account takeover prevention</div>
                        </div>
                    </div>
                </div>

                <div class="branch" onclick="toggleBranch('infrastructure')">
                    <div class="branch-header">
                        <span class="branch-icon">‚ö°</span>
                        AI Infrastructure
                    </div>
                    <div id="infrastructure" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('ec2-ai')">
                            <div class="service-name">EC2 AI Instances</div>
                            <div class="service-desc">GPU/AI-optimized compute</div>
                            <div class="use-cases">üí° P4, G4, Inf1, Trn1 instances for training/inference</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('lambda-ai')">
                            <div class="service-name">Lambda + AI</div>
                            <div class="service-desc">Serverless AI processing</div>
                            <div class="use-cases">üí° Event-driven AI, real-time inference</div>
                        </div>
                    </div>
                </div>

                <div class="branch" onclick="toggleBranch('security')">
                    <div class="branch-header">
                        <span class="branch-icon">üîí</span>
                        AI Security & Governance
                    </div>
                    <div id="security" class="sub-services">
                        <div class="service-item" onclick="showServiceDetails('iam-ai')">
                            <div class="service-name">IAM for AI Services</div>
                            <div class="service-desc">Identity and access management</div>
                            <div class="use-cases">üí° Role-based access, service-linked roles, fine-grained permissions</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('vpc-security')">
                            <div class="service-name">VPC & Network Security</div>
                            <div class="service-desc">Network isolation and protection</div>
                            <div class="use-cases">üí° Private endpoints, security groups, NACLs</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('encryption')">
                            <div class="service-name">Data Encryption</div>
                            <div class="service-desc">End-to-end data protection</div>
                            <div class="use-cases">üí° KMS, encryption at rest/transit, customer managed keys</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('compliance')">
                            <div class="service-name">Compliance & Governance</div>
                            <div class="service-desc">Regulatory compliance framework</div>
                            <div class="use-cases">üí° GDPR, HIPAA, SOC, PCI DSS, audit trails</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('monitoring')">
                            <div class="service-name">Security Monitoring</div>
                            <div class="service-desc">Threat detection and logging</div>
                            <div class="use-cases">üí° CloudTrail, GuardDuty, Security Hub, Config</div>
                        </div>
                        <div class="service-item" onclick="showServiceDetails('data-protection')">
                            <div class="service-name">Data Protection & Privacy</div>
                            <div class="use-cases">üí° Macie, data classification, PII detection</div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="branch" onclick="toggleBranch('ai-advancements')">
                <div class="branch-header">
                    <span class="branch-icon">üí°</span> AI & ML Technologies & Advancements
                </div>
                <div class="sub-services" id="ai-advancements">
                    <div class="service-item">
                        <div class="service-name">Agentic AI Models</div>
                        <div class="service-desc">AI models capable of taking independent actions and making real-time decisions, mimicking human-like autonomy.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Self-driving cars navigating roads and obeying traffic rules.</li>
                                <li>Personal assistants managing schedules and tasks autonomously.</li>
                                <li>AI systems that automate complex multi-step research or business processes.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Agentic AI Models', 'AI models capable of taking independent actions and making real-time decisions, mimicking human-like autonomy.', 'ai-advancements-agentic-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-agentic-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">Multimodal AI Systems</div>
                        <div class="service-desc">AI systems that process and integrate multiple types of input simultaneously, such as text, images, audio, and video, leading to more intuitive understanding.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Smart refrigerators recognizing food, suggesting recipes, and updating grocery lists.</li>
                                <li>Virtual assistants understanding voice commands, handwritten notes, and responding with summaries.</li>
                                <li>Robots perceiving environments more like humans for smoother collaboration in industries.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Multimodal AI Systems', 'AI systems that process and integrate multiple types of input simultaneously, such as text, images, audio, and video, leading to more intuitive understanding.', 'ai-advancements-multimodal-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-multimodal-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">Generative AI Evolution</div>
                        <div class="service-desc">Advancements in models like LLMs (Large Language Models), Text-to-Image, and Text-to-Video, enabling smarter, faster, and more ethical content creation across various modalities.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Generating high-quality text, images, music, and complex simulations.</li>
                                <li>Automating content creation for marketing, entertainment, and educational industries.</li>
                                <li>AI-powered code generation for developers.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Generative AI Evolution', 'Advancements in models like LLMs (Large Language Models), Text-to-Image, and Text-to-Video, enabling smarter, faster, and more ethical content creation across various modalities.', 'ai-advancements-generative-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-generative-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">Privacy-Preserving AI</div>
                        <div class="service-desc">Development of AI tools and techniques that prioritize user privacy and data security through methods like on-device processing, federated learning, and differential privacy.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>AI tools running locally on devices without sending sensitive data to the cloud.</li>
                                <li>Collaborative AI learning from data across multiple devices without direct data sharing.</li>
                                <li>Secure analysis of aggregated user data while protecting individual privacy.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Privacy-Preserving AI', 'Development of AI tools and techniques that prioritize user privacy and data security through methods like on-device processing, federated learning, and differential privacy.', 'ai-advancements-privacy-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-privacy-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">Quantum Computing & AI</div>
                        <div class="service-desc">The convergence of quantum computing with AI, leveraging quantum mechanics to solve complex computational problems beyond the capabilities of classical computers, accelerating AI research.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Developing more powerful and efficient AI algorithms for drug discovery and material science.</li>
                                <li>Optimizing complex logistics and financial modeling.</li>
                                <li>Breaking advanced encryption methods and enhancing cybersecurity.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Quantum Computing & AI', 'The convergence of quantum computing with AI, leveraging quantum mechanics to solve complex computational problems beyond the capabilities of classical computers, accelerating AI research.', 'ai-advancements-quantum-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-quantum-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">Edge AI</div>
                        <div class="service-desc">Deploying AI models directly on edge devices (e.g., IoT devices, smartphones, cameras) to perform inference locally, reducing latency, improving privacy, and conserving bandwidth.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Real-time anomaly detection in industrial IoT sensors.</li>
                                <li>Facial recognition on smart cameras for security without cloud dependency.</li>
                                <li>Instantaneous voice commands processing on smart home devices.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Edge AI', 'Deploying AI models directly on edge devices (e.g., IoT devices, smartphones, cameras) to perform inference locally, reducing latency, improving privacy, and conserving bandwidth.', 'ai-advancements-edge-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-edge-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">AI in Cybersecurity</div>
                        <div class="service-desc">Utilizing AI and ML techniques to enhance threat detection, automate incident response, and predict potential vulnerabilities in complex IT environments.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Real-time detection of malware, phishing attempts, and ransomware attacks.</li>
                                <li>Behavioral analytics to identify deviations indicating compromised accounts.</li>
                                <li>Automated threat containment and remediation.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('AI in Cybersecurity', 'Utilizing AI and ML techniques to enhance threat detection, automate incident response, and predict potential vulnerabilities in complex IT environments.', 'ai-advancements-cybersecurity-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-cybersecurity-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                    <div class="service-item">
                        <div class="service-name">Personalized Medicine</div>
                        <div class="service-desc">Applying AI to healthcare data to tailor medical treatments, predict disease risks, and discover new drugs based on an individual's genetic makeup, lifestyle, and environment.</div>
                        <div class="use-cases">
                            <p class="use-cases-title">Use Cases:</p>
                            <ul>
                                <li>Predictive analytics for early identification of at-risk patients.</li>
                                <li>Optimizing drug dosages and treatment plans for individual patients.</li>
                                <li>Accelerating drug discovery by simulating molecular interactions.</li>
                            </ul>
                        </div>
                        <button class="llm-action-button" onclick="generateTechExplanation('Personalized Medicine', 'Applying AI to healthcare data to tailor medical treatments, predict disease risks, and discover new drugs based on an individual\'s genetic makeup, lifestyle, and environment.', 'ai-advancements-medicine-llm-output', this)">Explain This Tech ‚ú®</button>
                        <div id="ai-advancements-medicine-llm-output" class="llm-output-area" style="display: none;"></div>
                    </div>
                </div>
            </div>

        </div>

    </div>

    <div id="serviceModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal()">&times;</span>
            <h2 id="modalTitle"></h2>
            <p id="modalDescription"></p>

            <!-- Conditional sections for Service Details -->
            <div id="serviceDetailsContent">
                <!-- NEW: Core Features moved to the top -->
                <div class="modal-section" id="featureSection">
                    <h3>üöÄ Core Features</h3>
                    <div id="featureTags"></div>
                    <div id="featureDetailsContainer"></div>
                </div>

                <div class="modal-section" id="techStackSection">
                    <h3>‚öôÔ∏è Tech Stack / Integrations</h3>
                    <p id="modalTechStack"></p>
                </div>

                <div class="modal-section" id="interdependenciesSection">
                    <h3>üîó Key Interdependencies</h3>
                    <ul id="modalInterdependencies"></ul>
                </div>

                <div class="pricing-info" id="pricingInfoSection">
                    <h3>üí∞ Pricing Model</h3>
                    <p id="modalPricing"></p>
                </div>

                <div class="modal-section" id="configNavSection">
                    <h3>üîß Key Configurations / Navigation</h3>
                    <p id="modalNavigation"></p>
                    <ul id="modalConfigOptions" class="config-options"></ul>
                </div>

                <div class="scenario-box" id="scenariosSection">
                    <h3>üí° Real-world Scenarios</h3>
                    <ul id="modalScenarios"></ul>
                </div>

                <button class="llm-action-button" onclick="summarizeServiceDescription(currentServiceDescription, this)">Summarize this Service ‚ú®</button>
                <button class="llm-action-button" onclick="generateUseCasesIdea(currentServiceName, currentServiceDescription, this)">Generate New Use Cases ‚ú®</button>
                <div id="llm-service-output" class="llm-output-area" style="display: none;"></div>

                <!-- New section for service-specific troubleshooting -->
                <div class="modal-section" id="serviceTroubleshootingSection" style="display: none;">
                    <h3>üõ†Ô∏è Troubleshooting & Best Practices</h3>
                    <div id="serviceTroubleshootingDetails">
                        <!-- Dynamic content will be loaded here -->
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        let currentServiceName = '';
        let currentServiceDescription = '';

        const awsServices = {
            sagemaker: {
                name: "Amazon SageMaker",
                description: "Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly. SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high-quality models.",
                features: ["Notebooks", "Data Labeling", "Data Preparation", "Model Training", "Model Tuning", "Pipelines", "Endpoints", "Ground Truth", "Clarify", "Feature Store"],
                featureDetails: {
                    "Notebooks": {
                        subFeatures: [
                            { title: "Managed Jupyter Notebooks", desc: "Easily create and share Jupyter notebooks for ML development." },
                            { title: "Elastic Inference", desc: "Attach GPU-powered inference acceleration to any EC2 instance type." },
                            { title: "Pre-built environments", desc: "Ready-to-use environments with popular ML frameworks (TensorFlow, PyTorch)." }
                        ],
                        navigation: "SageMaker Console -> Notebook instances -> Create notebook instance",
                        options: [
                            {
                                parameter: "Instance Type",
                                purpose: "Determines the compute and memory capacity for the notebook.",
                                values: ["ml.t3.medium (CPU, cost-effective)", "ml.m5.xlarge (CPU, balanced)", "ml.g4dn.xlarge (GPU, for deep learning)"]
                            },
                            {
                                parameter: "SageMaker Distribution",
                                purpose: "Specifies the pre-built environment with ML frameworks.",
                                values: ["Amazon Linux 2 (minimal)", "Conda (includes popular Python packages)", "TensorFlow (pre-configured)"]
                            },
                            {
                                parameter: "Git Repositories",
                                purpose: "Integrates version control for notebook code.",
                                values: ["SSH URL", "HTTPS URL"]
                            }
                        ]
                    },
                    "Data Labeling": {
                        subFeatures: [
                            { title: "Managed Data Labeling", desc: "Easily create high-quality training datasets with human labelers." },
                            { title: "Built-in Workflows", desc: "Pre-built workflows for common labeling tasks like image classification, object detection, and text classification." },
                            { title: "Active Learning", desc: "Automate labeling for large datasets by combining human and machine intelligence." }
                        ],
                        navigation: "SageMaker Console -> Labeling jobs -> Create labeling job",
                        options: [
                            "Choose task type (e.g., image, video, text, 3D point cloud)",
                            "Select workforce (e.g., Amazon Mechanical Turk, vendor-managed, private)",
                            "Configure data input and output S3 buckets"
                        ]
                    },
                    "Data Preparation": {
                        subFeatures: [
                            { title: "SageMaker Data Wrangler", desc: "Aggregate and prepare data from various sources with a visual interface." },
                            { title: "Feature Store", desc: "Centralized repository for discovering, sharing, and managing ML features." },
                            { title: "Processing Jobs", desc: "Run Spark, scikit-learn, or custom processing jobs for data preparation." }
                        ],
                        navigation: "SageMaker Console -> Data Wrangler / Feature Store / Processing jobs",
                        options: [
                            "Connect to data sources (S3, Redshift, Athena, etc.)",
                            "Apply transformations (e.g., join, aggregate, encode)",
                            "Define feature groups and ingestion pipelines"
                        ]
                    },
                    "Model Training": {
                        subFeatures: [
                            { title: "Managed Training", desc: "Train models at scale with built-in algorithms or custom code." },
                            { title: "Spot Instances", desc: "Reduce training costs by up to 90% using unused EC2 capacity." },
                            { title: "Distributed Training", desc: "Scale training across multiple GPUs or instances for large models." }
                        ],
                        navigation: "SageMaker Console -> Training jobs -> Create training job",
                        options: [
                            "Choose algorithm (e.g., XGBoost, DeepAR, custom container)",
                            "Select instance type and count (e.g., ml.m5.xlarge, ml.p3.2xlarge)",
                            "Specify input data source (S3) and output model artifact location"
                        ]
                    },
                    "Model Tuning": {
                        subFeatures: [
                            { title: "Automatic Model Tuning", desc: "Find the best model version by automatically searching for optimal hyperparameters." },
                            { title: "Hyperparameter Optimization (HPO)", desc: "Uses Bayesian optimization to efficiently explore hyperparameter combinations." },
                            { title: "Warm Start", desc: "Resume tuning jobs from previous results to save time and resources." }
                        ],
                        navigation: "SageMaker Console -> Hyperparameter tuning jobs -> Create hyperparameter tuning job",
                        options: [
                            "Define hyperparameter ranges and objective metric",
                            "Set max number of training jobs and concurrency",
                            "Choose tuning strategy (e.g., Bayesian, Random)"
                        ]
                    },
                    "Pipelines": {
                        subFeatures: [
                            { title: "MLOps Pipelines", desc: "Build, automate, and manage end-to-end ML workflows." },
                            { title: "Step Functions Integration", desc: "Orchestrate complex ML workflows with Amazon Step Functions." },
                            { title: "Lineage Tracking", desc: "Track every step of your ML workflow for auditing and reproducibility." }
                        ],
                        navigation: "SageMaker Console -> SageMaker Pipelines -> Create pipeline",
                        options: [
                            "Configure step dependencies and inputs/outputs",
                            "Specify instance types and resource requirements for each step",
                            "Set up failure handling and retry logic"
                        ]
                    },
                    "Endpoints": {
                        subFeatures: [
                            { title: "Real-time Inference", desc: "Low-latency endpoints for real-time predictions with auto-scaling" },
                            { title: "Batch Transform", desc: "Efficient batch processing for large-scale inference jobs" },
                            { title: "Multi-Model Endpoints", desc: "Host multiple models on a single endpoint for cost optimization" },
                            { title: "Serverless Inference", desc: "Pay-per-request inference without managing infrastructure" }
                        ],
                        navigation: "SageMaker Console -> Inference -> Endpoints -> Create endpoint",
                        options: [
                            "Choose inference type (Real-time, Batch, Serverless, Async)",
                            "Select instance type and count for real-time endpoints",
                            "Configure auto-scaling policies based on utilization or latency",
                            "Specify S3 input/output paths for batch transform jobs"
                        ]
                    },
                    "Ground Truth": {
                        subFeatures: [
                            { title: "Human Labeling", desc: "Managed workforce for high-quality data labeling with built-in quality controls" },
                            { title: "Active Learning", desc: "ML-assisted labeling that reduces manual effort by up to 70%" },
                            { title: "Custom Workflows", desc: "Configurable labeling workflows for complex annotation tasks" },
                            { title: "Quality Assurance", desc: "Multi-level review process with inter-annotator agreement metrics" }
                        ],
                        navigation: "SageMaker Console -> Ground Truth -> Labeling jobs -> Create labeling job",
                        options: [
                            "Choose task type (e.g., Image classification, Object detection, Text classification)",
                            "Select workforce (Private, Vendor, Public/Mechanical Turk)",
                            "Upload data (S3) and specify output location",
                            "Configure labeling instructions and review processes"
                        ]
                    },
                    "Clarify": {
                        subFeatures: [
                            { title: "Bias Detection", desc: "Pre-training and post-training bias detection across multiple fairness metrics" },
                            { title: "Model Explainability", desc: "SHAP-based feature importance and local explanations for individual predictions" },
                            { title: "Fairness Monitoring", desc: "Continuous monitoring of model fairness in production deployments" },
                            { title: "Bias Mitigation", desc: "Recommendations and techniques for reducing identified bias in models" }
                        ],
                        navigation: "SageMaker Console -> SageMaker Clarify -> Bias/Explainability jobs -> Create",
                        options: [
                            "Specify dataset for bias analysis or model for explainability",
                            "Define sensitive attributes (e.g., age, gender)",
                            "Choose fairness metrics (e.g., disparate impact, equal opportunity)",
                            "Select explainability methods (e.g., SHAP, LIME)"
                        ]
                    },
                    "Feature Store": {
                        subFeatures: [
                            { title: "Feature Repository", desc: "Centralized repository for storing, discovering, and sharing ML features" },
                            { title: "Real-time Features", desc: "Low-latency feature serving for real-time ML applications" },
                            { title: "Feature Lineage", desc: "Track feature creation, transformation, and usage across models" },
                            { title: "Time Travel", desc: "Access historical feature values for training and backtesting" }
                        ],
                        navigation: "SageMaker Console -> Feature Store -> Create feature group",
                        options: [
                            "Define feature group schema (feature names, data types)",
                            "Choose online (low-latency) and/or offline (batch) store",
                            "Configure data ingestion source (e.g., S3, Kinesis)",
                            "Set up data retention policies"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: Primary data storage for training data, model artifacts, and inference results.",
                    "**EC2**: SageMaker leverages EC2 instances for training and hosting. Choosing the right instance type (e.g., GPU instances) is crucial for performance.",
                    "**CloudWatch**: For monitoring training jobs, endpoint performance, and MLOps pipelines.",
                    "**IAM**: Essential for defining permissions for SageMaker to access other AWS services and for users to interact with SageMaker.",
                    "**Lambda**: Can be used to trigger SageMaker jobs or process inference results serverlessly.",
                    "**Glue**: For ETL and data preparation before feeding data into SageMaker.",
                    "**Step Functions**: For orchestrating complex, multi-step ML workflows with SageMaker Pipelines."
                ],
                techStack: ["Jupyter Notebooks", "TensorFlow", "PyTorch", "Scikit-learn", "XGBoost", "Hugging Face"],
                pricing: "Pay-as-you-go: Training ($0.05-$24.48/hour), Hosting ($0.05-$24.48/hour), depending on instance type and region. Data labeling, Data Wrangler, Feature Store, and Clarify have separate pricing based on usage.",
                scenarios: [
                    "E-commerce recommendation engine with real-time inference",
                    "Healthcare image classification for medical diagnosis",
                    "Financial fraud detection with automated model retraining",
                    "Supply chain demand forecasting with MLOps pipeline"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Training Job Failures",
                            desc: "Common causes include incorrect IAM roles for S3 data access, insufficient compute resources (CPU/GPU/memory), or issues with the training script itself (e.g., missing dependencies).",
                            solutionSteps: [
                                "Verify SageMaker execution role has `s3:GetObject` and `s3:PutObject` permissions on relevant S3 buckets.",
                                "Check CloudWatch logs for the training job for specific error messages (e.g., 'CUDA out of memory', 'ModuleNotFoundError').",
                                "Ensure the chosen instance type is powerful enough for your model and data size.",
                                "Validate training script entry point and dependencies in your Docker image or script."
                            ]
                        },
                        {
                            title: "Endpoint Invocation Errors/Latency",
                            desc: "Issues when calling SageMaker endpoints can stem from incorrect payload format, endpoint scaling problems, or network configuration.",
                            solutionSteps: [
                                "Ensure input data to the endpoint matches the expected format (e.g., JSON, CSV) and content type.",
                                "Monitor CloudWatch metrics for the endpoint (e.g., `Invocations`, `InvocationErrors`, `ModelLatency`) and configure auto-scaling policies.",
                                "If endpoint is in a VPC, check Security Groups and Network ACLs for proper ingress/egress rules, and confirm VPC Endpoints for S3/other service access."
                            ]
                        }
                    ]
                }
            },
            bedrock: {
                name: "Amazon Bedrock",
                description: "Fully managed service providing access to foundation models from leading AI companies",
                features: ["Claude (Anthropic)", "Titan (Amazon)", "Jurassic (AI21)", "Command (Cohere)", "Stable Diffusion", "Fine-tuning", "RAG"],
                featureDetails: {
                    "Claude (Anthropic)": {
                        subFeatures: [
                            { title: "Claude 3 Opus", desc: "Most capable model for complex reasoning, analysis, and creative tasks" },
                            { title: "Claude 3 Sonnet", desc: "Balanced for performance and cost, ideal for high-volume workloads" },
                            { title: "Claude 3 Haiku", desc: "Fastest and most compact model for near-instant responsiveness" }
                        ],
                        navigation: "Bedrock Console -> Base models -> Claude",
                        options: [
                            {
                                parameter: "Model Version",
                                purpose: "Selects the specific capability and performance profile of the model.",
                                values: ["Claude 3 Opus (most capable)", "Claude 3 Sonnet (balanced)", "Claude 3 Haiku (fastest, most compact)"]
                            },
                            {
                                parameter: "Temperature",
                                purpose: "Controls the randomness/creativity of the generated text (higher = more creative).",
                                values: ["0.0 (deterministic)", "0.5 (balanced)", "1.0 (most creative)"]
                            },
                            {
                                parameter: "Max Tokens",
                                purpose: "Sets the maximum number of tokens (words/pieces of words) the model will generate.",
                                values: ["e.g., 200 (short response)", "e.g., 1000 (longer response)"]
                            },
                            {
                                parameter: "Top P (Nucleus Sampling)",
                                purpose: "Filters out low-probability words, making output more focused and less random. Samples from the smallest set of most probable tokens whose cumulative probability exceeds P.",
                                values: ["0.0 (equivalent to greedy decoding)", "0.5 (more diverse than greedy)", "1.0 (all words considered)"]
                            },
                            {
                                parameter: "Top K",
                                purpose: "Limits the sampling pool to the K most probable words, balancing creativity and relevance.",
                                values: ["1 (greedy, selects most probable word)", "50 (standard for diverse output)", "e.g., 200 (wider range of words)"]
                            }
                        ]
                    },
                    "Titan (Amazon)": {
                        subFeatures: [
                            { title: "Titan Text Embeddings", desc: "Convert text into numerical representations for search and recommendations" },
                            { title: "Titan Text Lite", desc: "Smaller, faster text model for summarization and text generation" },
                            { title: "Titan Text Express", desc: "Powerful text model for generative AI tasks" },
                            { title: "Titan Image Generator", desc: "Generates images from text prompts" }
                        ],
                        navigation: "Bedrock Console -> Base models -> Titan",
                        options: [
                            {
                                parameter: "Model Version",
                                purpose: "Selects the specific capability and performance profile of the model.",
                                values: ["Titan Text Embeddings v2 (embeddings)", "Titan Text Lite v1 (summarization, text generation)", "Titan Text Express v1 (generative AI)"]
                            },
                            {
                                parameter: "Temperature",
                                purpose: "Controls the randomness/creativity of the generated text.",
                                values: ["0.0 (deterministic)", "0.5 (balanced)", "1.0 (most creative)"]
                            },
                            {
                                parameter: "Max Tokens",
                                purpose: "Sets the maximum number of tokens the model will generate.",
                                values: ["e.g., 200", "e.g., 1000"]
                            },
                            {
                                parameter: "Top P (Nucleus Sampling)",
                                purpose: "Filters out low-probability words.",
                                values: ["0.0", "0.5", "1.0"]
                            },
                            {
                                parameter: "Top K",
                                purpose: "Limits the sampling pool to the K most probable words.",
                                values: ["1", "50", "e.g., 200"]
                            },
                            "Adjust output settings (e.g., image style, resolution)"
                        ]
                    },
                    "Jurassic (AI21)": {
                        subFeatures: [
                            { title: "Jurassic-2 Mid", desc: "Mid-sized language model for everyday tasks" },
                            { title: "Jurassic-2 Ultra", desc: "Largest and most powerful language model for complex use cases" }
                        ],
                        navigation: "Bedrock Console -> Base models -> AI21 Labs",
                        options: [
                            {
                                parameter: "Model Version",
                                purpose: "Selects the specific capability and performance profile of the model.",
                                values: ["Jurassic-2 Mid", "Jurassic-2 Ultra"]
                            },
                            {
                                parameter: "Temperature",
                                purpose: "Controls the randomness/creativity of the generated text.",
                                values: ["0.0", "0.5", "1.0"]
                            },
                            {
                                parameter: "Max Tokens",
                                purpose: "Sets the maximum number of tokens the model will generate.",
                                values: ["e.g., 200", "e.g., 1000"]
                            },
                            {
                                parameter: "Top P (Nucleus Sampling)",
                                purpose: "Filters out low-probability words.",
                                values: ["0.0", "0.5", "1.0"]
                            },
                            {
                                parameter: "Top K",
                                purpose: "Limits the sampling pool to the K most probable words.",
                                values: ["1", "50", "e.g., 200"]
                            }
                        ]
                    },
                    "Command (Cohere)": {
                        subFeatures: [
                            { title: "Command", desc: "Powerful large language model for generating text and conversational AI" },
                            { title: "Embed", desc: "Generates high-quality embeddings for text" }
                        ],
                        navigation: "Bedrock Console -> Base models -> Cohere",
                        options: [
                            {
                                parameter: "Model Version",
                                purpose: "Selects the specific capability and performance profile of the model.",
                                values: ["Command (text generation)", "Embed (embeddings)"]
                            },
                            {
                                parameter: "Temperature",
                                purpose: "Controls the randomness/creativity of the generated text.",
                                values: ["0.0", "0.5", "1.0"]
                            },
                            {
                                parameter: "Max Tokens",
                                purpose: "Sets the maximum number of tokens the model will generate.",
                                values: ["e.g., 200", "e.g., 1000"]
                            },
                            {
                                parameter: "Top P (Nucleus Sampling)",
                                purpose: "Filters out low-probability words.",
                                values: ["0.0", "0.5", "1.0"]
                            },
                            {
                                parameter: "Top K",
                                purpose: "Limits the sampling pool to the K most probable words.",
                                values: ["1", "50", "e.g., 200"]
                            }
                        ]
                    },
                    "Stable Diffusion": {
                        subFeatures: [
                            { title: "Text-to-Image Generation", desc: "Create high-quality images from text descriptions" },
                            { title: "Image-to-Image Generation", desc: "Transform existing images with text prompts" }
                        ],
                        navigation: "Bedrock Console -> Base models -> Stability AI",
                        options: [
                            "Enter text prompts for image generation",
                            "Upload reference images for image-to-image tasks",
                            "Adjust image generation parameters (e.g., image style, iterations)"
                        ]
                    },
                    "Fine-tuning": {
                        subFeatures: [
                            { title: "Custom Model Training", desc: "Adapt foundation models to your specific data and use cases" },
                            { title: "Private Access", desc: "Your fine-tuned models are private and accessible only by you" }
                        ],
                        navigation: "Bedrock Console -> Custom models -> Create model",
                        options: [
                            "Select a base foundation model for fine-tuning",
                            "Upload your training dataset (S3)",
                            "Configure training parameters and monitor job status"
                        ]
                    },
                    "RAG": {
                        subFeatures: [
                            { title: "Retrieval Augmented Generation", desc: "Combine FMs with your data sources for more accurate and relevant responses" },
                            { title: "Knowledge Bases", desc: "Create knowledge bases from your data for RAG" }
                        ],
                        navigation: "Bedrock Console -> Knowledge bases -> Create knowledge base",
                        options: [
                            "Connect to data sources (S3, DynamoDB, etc.)",
                            "Configure retrieval settings and model integration"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing training data for fine-tuning and as a source for RAG knowledge bases.",
                    "**Lambda**: To invoke Bedrock models for serverless applications.",
                    "**API Gateway**: To expose Bedrock model inference as public APIs.",
                    "**KMS**: For encrypting data used in Bedrock and protecting custom models.",
                    "**CloudWatch**: For monitoring API usage and model performance.",
                    "**IAM**: For managing permissions to access and use Bedrock models."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Pre-trained Foundation Models"],
                pricing: "Pay-per-token for text generation and per-image for image generation. Fine-tuning is priced per-hour for training and per-inference for custom models.",
                scenarios: [
                    "Building intelligent chatbots and virtual assistants",
                    "Generating marketing copy, articles, and creative content",
                    "Summarizing long documents and transcribing meetings",
                    "Developing powerful search and recommendation engines",
                    "Creating unique images and art from text descriptions"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Access Denied / Model Not Available",
                            desc: "Users might encounter issues accessing foundation models due to missing permissions or models not being enabled for their account/region.",
                            solutionSteps: [
                                "Ensure IAM user/role has necessary `bedrock:InvokeModel` and `bedrock:Retrieve` permissions.",
                                "Verify that the specific foundation model (e.g., Claude, Titan) is enabled for your AWS account in the Bedrock console.",
                                "Check if the model is available in your chosen AWS region."
                            ]
                        },
                        {
                            title: "Poor Model Response Quality",
                            desc: "Generated text or images might not meet expectations due to suboptimal prompts, inappropriate model choice, or lack of fine-tuning/RAG.",
                            solutionSteps: [
                                "Refine your prompts: make them clearer, more specific, and include examples.",
                                "Experiment with different models (e.g., Claude Opus for complex tasks, Haiku for speed).",
                                "Adjust inference parameters like `temperature` (creativity), `max_tokens` (response length), `top_p`, and `top_k`."
                            ]
                        }
                    ]
                }
            },
            codewhisperer: {
                name: "Amazon CodeWhisperer",
                description: "AI-powered coding companion that generates code suggestions in real time based on comments and existing code",
                features: ["Code Generation", "Code Completion", "Security Scans", "Reference Tracking", "Customization"],
                featureDetails: {
                    "Code Generation": {
                        subFeatures: [
                            { title: "Contextual Suggestions", desc: "Generates entire functions and code blocks based on natural language comments or existing code" },
                            { title: "Multi-language Support", desc: "Supports Python, Java, JavaScript, TypeScript, C#, Go, Rust, PHP, Ruby, Kotlin, and SQL" },
                            { title: "Framework-aware", desc: "Provides suggestions tailored to popular frameworks and libraries" }
                        ],
                        navigation: "Integrated Development Environment (IDE) with CodeWhisperer plugin enabled",
                        options: [
                            "Start typing a comment or code, suggestions appear automatically",
                            "Accept suggestions by pressing Tab key"
                        ]
                    },
                    "Code Completion": {
                        subFeatures: [
                            { title: "Line Completion", desc: "Completes individual lines of code" },
                            { title: "Boilerplate Generation", desc: "Generates common code structures and patterns" }
                        ],
                        navigation: "IDE with CodeWhisperer plugin enabled",
                        options: [
                            "As you type, CodeWhisperer provides inline suggestions"
                        ]
                    },
                    "Security Scans": {
                        subFeatures: [
                            { title: "Vulnerability Detection", desc: "Scans code for hard-to-find security vulnerabilities" },
                            { title: "Remediation Suggestions", desc: "Provides actionable recommendations to fix identified security issues" }
                        ],
                        navigation: "IDE with CodeWhisperer plugin -> Security scan",
                        options: [
                            "Run on-demand security scans on your code",
                            "Review detected vulnerabilities and apply suggested fixes"
                        ]
                    },
                    "Reference Tracking": {
                        subFeatures: [
                            { title: "Attribution to Training Data", desc: "Identifies if a code suggestion is similar to open-source training data" },
                            { title: "License Information", desc: "Provides links to licenses of referenced open-source projects" }
                        ],
                        navigation: "CodeWhisperer IDE plugin output/panel",
                        options: [
                            "Review reference information provided with code suggestions",
                            "Ensure compliance with open-source licenses"
                        ]
                    },
                    "Customization": {
                        subFeatures: [
                            { title: "Customization for Private Code", desc: "Fine-tune CodeWhisperer on your organization's private code base" },
                            { title: "Improved Relevance", desc: "Enhance the relevance of suggestions to your internal coding standards and libraries" }
                        ],
                        navigation: "CodeWhisperer Console -> Customizations -> Create customization",
                        options: [
                            "Upload your organization's code (S3)",
                            "Train a custom CodeWhisperer model"
                        ]
                    }
                },
                interdependencies: [
                    "**IAM Identity Center (SSO)**: For managing user access to CodeWhisperer (for professional tier).",
                    "**S3**: For storing code for customization.",
                    "**IDE (VS Code, IntelliJ, AWS Cloud9)**: Requires a plugin for integration.",
                    "**AWS CLI / SDK**: For programmatic interactions and customization setup."
                ],
                techStack: ["IDE Plugins (VS Code, IntelliJ IDEA, AWS Cloud9)", "Supported Programming Languages", "ML Models"],
                pricing: "Free tier available for individual users. Professional tier is priced per active user per month with additional costs for customization.",
                scenarios: [
                    "Accelerating software development by generating code snippets and functions",
                    "Helping developers learn new APIs and frameworks faster",
                    "Identifying and fixing security vulnerabilities in code during development",
                    "Maintaining consistent coding standards across large development teams"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Suggestions Not Appearing",
                            desc: "CodeWhisperer suggestions may not appear due to plugin issues, network connectivity, or incorrect IDE setup.",
                            solutionSteps: [
                                "Ensure the CodeWhisperer plugin is correctly installed and enabled in your IDE.",
                                "Check your network connection and proxy settings, as the plugin needs to communicate with AWS.",
                                "Verify that your IAM user/role has the necessary permissions for CodeWhisperer (e.g., `codewhisperer:GenerateCompletions`).",
                                "Restart your IDE or try a simple code snippet to trigger suggestions."
                            ]
                        },
                        {
                            title: "Irrelevant Suggestions",
                            desc: "Code suggestions might not be relevant to your project's context or coding style.",
                            solutionSteps: [
                                "Ensure you are providing sufficient context through comments and existing code.",
                                "For team environments, consider using CodeWhisperer customization to fine-tune the model on your organization's private codebase for improved relevance."
                            ]
                        }
                    ]
                }
            },
            rekognition: {
                name: "Amazon Rekognition",
                description: "Deep learning-based image and video analysis service that identifies objects, people, text, scenes, and activities, as well as detecting inappropriate content",
                features: ["Image Analysis", "Video Analysis", "Face Analysis", "Content Moderation", "Custom Labels"],
                featureDetails: {
                    "Image Analysis": {
                        subFeatures: [
                            { title: "Object and Scene Detection", desc: "Identifies thousands of objects, scenes, and activities in images" },
                            { title: "Text Detection", desc: "Detects and extracts text from images (Text in Image)" },
                            { title: "Image Properties", desc: "Analyzes image quality, colors, and dominant colors" }
                        ],
                        navigation: "Rekognition Console -> Demos / API calls: DetectLabels, DetectText",
                        options: [
                            {
                                parameter: "Input Image Format",
                                purpose: "Specifies the accepted image formats for analysis.",
                                values: ["JPEG", "PNG"]
                            },
                            {
                                parameter: "Features to Detect",
                                purpose: "Selects the types of analysis to perform on the image.",
                                values: ["Labels (objects, scenes)", "Text (OCR)", "Faces (for attributes)"]
                            },
                            {
                                parameter: "Min Confidence",
                                purpose: "Sets the minimum confidence level for returned detections.",
                                values: ["e.g., 70 (higher confidence, fewer results)", "e.g., 50 (lower confidence, more results)"]
                            }
                        ]
                    },
                    "Video Analysis": {
                        subFeatures: [
                            { title: "Activity Detection", desc: "Identifies activities and events in videos (e.g., running, swimming)" },
                            { title: "Pathing", desc: "Tracks the movement of objects and people in video" },
                            { title: "Celebrity Recognition", desc: "Identifies well-known public figures in video" }
                        ],
                        navigation: "Rekognition Console -> Demos / API calls: StartLabelDetection, GetLabelDetection",
                        options: [
                            "Upload video (MP4, MOV)",
                            "Specify features to detect (labels, activities, celebrities)"
                        ]
                    },
                    "Face Analysis": {
                        subFeatures: [
                            { title: "Face Detection and Analysis", desc: "Detects faces and analyzes attributes (e.g., emotions, age range)" },
                            { title: "Face Comparison", desc: "Compares a face in an image to faces in another image or collection" },
                            { title: "Face Search", desc: "Searches for a face in a collection of stored faces" }
                        ],
                        navigation: "Rekognition Console -> Demos / API calls: DetectFaces, CompareFaces, SearchFacesByImage",
                        options: [
                            "Provide image with face(s)",
                            "Create face collections for searching"
                        ]
                    },
                    "Content Moderation": {
                        subFeatures: [
                            { title: "Image Moderation", desc: "Detects inappropriate, offensive, or unsafe content in images" },
                            { title: "Video Moderation", desc: "Detects explicit or suggestive content, violence, and hate symbols in videos" }
                        ],
                        navigation: "Rekognition Console -> Demos / API calls: DetectModerationLabels",
                        options: [
                            "Upload image or video",
                            "Receive moderation labels and confidence scores"
                        ]
                    },
                    "Custom Labels": {
                        subFeatures: [
                            { title: "Train Custom Models", desc: "Train Rekognition to detect objects and scenes specific to your business needs" },
                            { title: "Low-code Training", desc: "Build custom models without requiring deep machine learning expertise" }
                        ],
                        navigation: "Rekognition Console -> Custom Labels -> Projects -> Create project",
                        options: [
                            "Upload training images and label them using SageMaker Ground Truth or manually",
                            "Train and evaluate your custom model"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input images and videos, and output results.",
                    "**Kinesis Video Streams**: For real-time video analysis.",
                    "**Lambda**: To trigger Rekognition processing on new media uploads.",
                    "**DynamoDB**: To store detected labels, faces, or moderation results for querying.",
                    "**SNS**: For notifications on video analysis job completion."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Image/Video formats (JPEG, PNG, MP4, MOV)"],
                pricing: "Pay-per-image/video for analysis. Pricing varies by feature (e.g., object detection, face analysis, custom labels).",
                scenarios: [
                    "Automating content moderation for user-generated content platforms",
                    "Enhancing security with facial recognition for access control",
                    "Analyzing retail store footage for customer behavior insights",
                    "Digitizing archives of historical images by detecting objects and text"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Inaccurate Detection Results",
                            desc: "Rekognition might return low confidence scores or miss objects if image quality is poor, or if the objects are highly specialized.",
                            solutionSteps: [
                                "Ensure image/video quality is high, with clear focus and good lighting.",
                                "For specialized objects, consider using Amazon Rekognition Custom Labels to train a custom model with your specific data.",
                                "Adjust confidence thresholds for detection based on your application's tolerance for false positives/negatives."
                            ]
                        },
                        {
                            title: "Access Denied to S3 Buckets",
                            desc: "Rekognition needs appropriate IAM permissions to access input media from S3 and write outputs back.",
                            solutionSteps: [
                                "Verify that the IAM role or user calling Rekognition has `s3:GetObject` on input buckets and `s3:PutObject` on output buckets."
                            ]
                        }
                    ]
                }
            },
            textract: {
                name: "Amazon Textract",
                description: "Service that automatically extracts text, handwriting, and data from scanned documents, forms, and tables",
                features: ["Document Text Extraction", "Form Extraction", "Table Extraction", "Identity Document Analysis", "Query-based Extraction"],
                featureDetails: {
                    "Document Text Extraction": {
                        subFeatures: [
                            { title: "OCR (Optical Character Recognition)", desc: "Extracts printed text from any document" },
                            { title: "Handwriting Detection", desc: "Detects and extracts handwritten text" },
                            { title: "Layout Analysis", desc: "Preserves the layout of the document, including lines, words, and text blocks" }
                        ],
                        navigation: "Textract Console -> Analyze document -> Upload document (or API calls: DetectDocumentText)",
                        options: [
                            "Specify input document (image or PDF)"
                        ]
                    },
                    "Form Extraction": {
                        subFeatures: [
                            { title: "Key-value Pair Extraction", desc: "Identifies and extracts form data as key-value pairs (e.g., 'Name: John Doe')" },
                            { title: "Structured Data Output", desc: "Provides extracted data in a structured JSON format" }
                        ],
                        navigation: "Textract Console -> Analyze document -> Upload document -> Use forms (or API calls: AnalyzeDocument with 'FORMS')",
                        options: [
                            "Specify input document (image or PDF)",
                            "Textract automatically detects and extracts key-value pairs"
                        ]
                    },
                    "Table Extraction": {
                        subFeatures: [
                            { title: "Table Detection", desc: "Automatically detects tables and their structure in documents" },
                            { title: "Cell-level Extraction", desc: "Extracts content from individual cells, rows, and columns" },
                            { title: "Structured Data Output", desc: "Provides extracted table data in a structured JSON format" }
                        ],
                        navigation: "Textract Console -> Analyze document -> Upload document -> Use tables (or API calls: AnalyzeDocument with 'TABLES')",
                        options: [
                            "Specify input document (image or PDF)",
                            "Textract automatically detects and extracts tables"
                        ]
                    },
                    "Identity Document Analysis": {
                        subFeatures: [
                            { title: "Automated ID Extraction", desc: "Extracts data from identity documents like passports and driver's licenses" },
                            { title: "Key Data Fields", desc: "Automatically identifies and extracts common fields (e.g., name, DOB, ID number)" },
                            { title: "Fraud Detection", desc: "Flags potential tampering or inconsistencies in documents" }
                        ],
                        navigation: "Textract Console -> Analyze identity documents -> Upload identity document (or API calls: AnalyzeID)",
                        options: [
                            "Specify input image of an identity document"
                        ]
                    },
                    "Query-based Extraction": {
                        subFeatures: [
                            { title: "Natural Language Queries", desc: "Extracts specific information by asking natural language questions" },
                            { title: "Contextual Understanding", desc: "Understands the context of the document to answer questions accurately" },
                            { title: "Any Document Layout", desc: "Works across different document layouts without templates" }
                        ],
                        navigation: "Textract Console -> Analyze document -> Upload document -> Use queries (or API calls: AnalyzeDocument with 'QUERIES')",
                        options: [
                            "Specify input document (image or PDF)",
                            "Provide a list of natural language queries (e.g., 'What is the total amount?', 'What is the customer name?')"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input documents (images, PDFs) and output JSON/text results.",
                    "**Lambda**: To trigger Textract processing on new document uploads.",
                    "**DynamoDB**: To store extracted data for downstream applications.",
                    "**Comprehend**: For further NLP on extracted text (e.g., sentiment analysis on customer feedback forms).",
                    "**SNS / SQS**: For notifications on asynchronous document processing jobs.",
                    "**CloudWatch**: For monitoring Textract usage and job status."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Document formats (JPEG, PNG, PDF)", "JSON output"],
                pricing: "Pay-per-page for text detection, form extraction, table extraction, and query-based extraction. Identity document analysis has separate pricing.",
                scenarios: [
                    "Automating invoice processing and data entry",
                    "Digitizing medical records for easy search and analysis",
                    "Extracting data from government forms for regulatory compliance",
                    "Building a searchable archive of scanned historical documents"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Incomplete/Incorrect Data Extraction",
                            desc: "Textract might miss fields or extract incorrect values if documents are low quality, have unusual layouts, or if the wrong analysis type is chosen.",
                            solutionSteps: [
                                "Ensure high-resolution scans of documents. Blurry or skewed images can lead to errors.",
                                "For forms and tables, ensure you are using `AnalyzeDocument` with the `FORMS` and/or `TABLES` feature types.",
                                "For highly variable documents, consider using `QUERIES` for targeted extraction. For identity documents, use `AnalyzeID`.",
                                "Review the `Confidence` scores in the Textract output and manually verify low-confidence extractions."
                            ]
                        },
                        {
                            title: "Long Processing Times for Large Documents",
                            desc: "Synchronous API calls have size limits and can timeout for very large documents.",
                            solutionSteps: [
                                "For large documents (multi-page PDFs), use asynchronous API operations (e.g., `StartDocumentTextDetection`, `StartDocumentAnalysis`) which process in the background and notify via SNS."
                            ]
                        }
                    ]
                }
            },
            'lookout-vision': {
                name: "Amazon Lookout for Vision",
                description: "Machine learning service that uses computer vision to spot defects and anomalies in industrial products",
                features: ["Image Anomaly Detection", "Model Training", "Real-time Inference", "Batch Inference"],
                featureDetails: {
                    "Image Anomaly Detection": {
                        subFeatures: [
                            { title: "Unsupervised Learning", desc: "Detects anomalies without requiring labeled defect images for training" },
                            { title: "Pixel-level Localization", desc: "Identifies the exact location of defects within an image" },
                            { title: "High Accuracy", desc: "Designed for high-precision detection of subtle manufacturing defects" }
                        ],
                        navigation: "Lookout for Vision Console -> Projects -> Models -> Start model (or API calls: DetectAnomalies)",
                        options: [
                            "Specify input image (JPEG, PNG)",
                            "Get anomaly score and pixel-level anomaly map"
                        ]
                    },
                    "Model Training": {
                        subFeatures: [
                            { title: "Low-code Training", desc: "Train custom models with a minimal amount of 'good' images and no coding required" },
                            { title: "Automated Data Augmentation", desc: "Automatically generates variations of your training images to improve model robustness" },
                            { title: "Model Versioning", desc: "Manage different versions of your trained models" }
                        ],
                        navigation: "Lookout for Vision Console -> Projects -> Models -> Train new model",
                        options: [
                            "Upload a dataset of 'normal' (non-defective) images (S3)",
                            "Optionally upload a small set of 'anomalous' images for improved detection"
                        ]
                    },
                    "Real-time Inference": {
                        subFeatures: [
                            { title: "Low-latency Endpoints", desc: "Deploy models as real-time endpoints for immediate defect detection on production lines" },
                            { title: "Edge Deployment", desc: "Deploy models to edge devices for on-premises inference" },
                            { title: "API Integration", desc: "Integrate defect detection into manufacturing systems via API" }
                        ],
                        navigation: "Lookout for Vision Console -> Projects -> Models -> Deploy model (or API calls: StartModel)",
                        options: [
                            "Choose instance type for real-time endpoint",
                            "Monitor endpoint status and performance"
                        ]
                    },
                    "Batch Inference": {
                        subFeatures: [
                            { title: "Offline Processing", desc: "Analyze large batches of images for defects offline" },
                            { title: "S3 Integration", desc: "Process images directly from S3 buckets" },
                            { title: "Asynchronous Jobs", desc: "Run long-running defect detection jobs without real-time constraints" }
                        ],
                        navigation: "Lookout for Vision Console -> Projects -> Models -> Create inference scheduling job (or API calls: StartAnomaliesDetection)",
                        options: [
                            "Specify S3 input and output locations for batch images",
                            "Choose the trained model version for inference"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing training images and inference results.",
                    "**Kinesis Video Streams**: For real-time image capture from industrial cameras.",
                    "**Lambda**: To trigger inference on new images or process detection results.",
                    "**CloudWatch**: For monitoring model performance and service usage.",
                    "**Greengrass**: For deploying models to edge devices for local inference."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Image formats (JPEG, PNG)"],
                pricing: "Pay-per-hour for model training and per-image for inference (real-time and batch). Edge deployment has separate pricing.",
                scenarios: [
                    "Automated quality inspection on manufacturing assembly lines (e.g., checking for scratches, dents, misalignments)",
                    "Detecting anomalies in electronic components and circuit boards",
                    "Inspecting textiles for fabric defects",
                    "Monitoring food production for quality control"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Poor Anomaly Detection Accuracy",
                            desc: "Models might not accurately detect defects if the training data (normal images) is not representative or if anomalous examples are too subtle/varied.",
                            solutionSteps: [
                                "Ensure your training dataset for 'normal' images is comprehensive and covers all variations of good products.",
                                "If possible, provide a small set of anomalous images during training to help the model learn defect characteristics.",
                                "Review the anomaly scores and pixel-level maps for false positives/negatives and refine your model or inspection process."
                            ]
                        },
                        {
                            title: "Model Training Failures",
                            desc: "Training can fail if image formats are incorrect, S3 permissions are missing, or the dataset is too small.",
                            solutionSteps: [
                                "Verify all training images are in supported formats (JPEG, PNG) and are accessible by Lookout for Vision's service role.",
                                "Ensure sufficient number of 'normal' images (at least 30 recommended for unsupervised mode)."
                            ]
                        }
                    ]
                }
            },
            comprehend: {
                name: "Amazon Comprehend",
                description: "Natural-language processing (NLP) service that uses machine learning to find insights and relationships in text",
                features: ["Sentiment Analysis", "Entity Recognition", "Keyphrase Extraction", "Language Detection", "Topic Modeling", "Targeted Sentiment", "Events Detection", "Custom NLP"],
                featureDetails: {
                    "Entity Recognition": {
                        subFeatures: [
                            { title: "Named Entity Recognition (NER)", desc: "Identifies people, places, organizations, dates, and other named entities" },
                            { title: "Protected Health Information (PHI) Detection", desc: "Specifically identifies and redacts PHI in medical text" },
                            { title: "Personal Identifiable Information (PII) Detection", desc: "Detects and redacts PII like names, addresses, and credit card numbers" },
                            { title: "Custom Entity Recognition", desc: "Train custom models to identify entities specific to your domain" }
                        ],
                        navigation: "Comprehend Console -> Analyze (Entities) / Customization -> Custom entity recognizers (or API calls)",
                        options: [
                            "Choose language for analysis",
                            "Specify entity types to detect",
                            "For custom entities, provide training documents and entity lists (S3)"
                        ]
                    },
                    "Sentiment Analysis": {
                        subFeatures: [
                            { title: "Positive, Negative, Neutral, Mixed", desc: "Determines the overall sentiment of a text" },
                            { title: "Sentiment Scores", desc: "Provides confidence scores for each sentiment type" },
                            { title: "Asynchronous Analysis", desc: "Process large batches of documents for sentiment" }
                        ],
                        navigation: "Comprehend Console -> Analyze (Sentiment) (or API calls: DetectSentiment)",
                        options: [
                            "Choose language for analysis",
                            "Select output format (JSON)"
                        ]
                    },
                    "Keyphrase Extraction": {
                        subFeatures: [
                            { title: "Important Phrases", desc: "Identifies the main topics and key phrases in a text" },
                            { title: "Confidence Scores", desc: "Returns confidence scores for each keyphrase" }
                        ],
                        navigation: "Comprehend Console -> Analyze (Key phrases) (or API calls: DetectKeyPhrases)",
                        options: [
                            "Choose language for analysis",
                            "Select output format (JSON)"
                        ]
                    },
                    "Language Detection": {
                        subFeatures: [
                            { title: "Automatic Language Identification", desc: "Automatically detects the language of a text" },
                            { title: "Language Codes", desc: "Returns standard language codes (e.g., 'en' for English)" }
                        ],
                        navigation: "Comprehend Console -> Analyze (Language) (or API calls: DetectDominantLanguage)",
                        options: [
                            "Provide input text"
                        ]
                    },
                    "Topic Modeling": {
                        subFeatures: [
                            { title: "Document Clustering", desc: "Automatically identifies the main topics in a collection of documents" },
                            { title: "Topic Assignments", desc: "Assigns documents to specific topics with confidence scores" }
                        ],
                        navigation: "Comprehend Console -> Analysis jobs -> Topic modeling (or API calls: StartTopicsDetectionJob)",
                        options: [
                            "Upload input documents (S3)",
                            "Specify output S3 bucket for results",
                            "Define the number of topics to detect"
                        ]
                    },
                    "Targeted Sentiment": {
                        subFeatures: [
                            { title: "Aspect-level Sentiment", desc: "Identifies sentiment towards specific entities or aspects within text" },
                            { title: "Granular Insights", desc: "Provides more detailed sentiment analysis beyond overall document sentiment" }
                        ],
                        navigation: "Comprehend Console -> Analyze (Targeted sentiment) (or API calls: DetectTargetedSentiment)",
                        options: [
                            "Choose language for analysis",
                            "Provide input text for targeted sentiment analysis"
                        ]
                    },
                    "Events Detection": {
                        subFeatures: [
                            { title: "Real-world Event Extraction", desc: "Identifies real-world events and their attributes (e.g., date, location, participants)" },
                            { title: "Domain-specific Events", desc: "Supports domains like Crisis, Sports, and Financial events" }
                        ],
                        navigation: "Comprehend Console -> Events (or API calls: DetectEvents)",
                        options: [
                            "Choose event type (e.g., Crisis, Sports)",
                            "Provide input text for event detection"
                        ]
                    },
                    "Custom NLP": {
                        subFeatures: [
                            { title: "Custom Classifiers", desc: "Train custom models to classify documents into categories specific to your business" },
                            { title: "Custom Entity Recognizers", desc: "Train custom models to identify unique entities in your domain" }
                        ],
                        navigation: "Comprehend Console -> Customization -> Custom classifiers / Custom entity recognizers",
                        options: [
                            "Upload training data (S3) for classification or entity recognition",
                            "Train and evaluate your custom models"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input documents for analysis and output results.",
                    "**Lambda**: To trigger Comprehend analysis on new data uploads (e.g., customer reviews, articles).",
                    "**DynamoDB**: To store extracted entities, sentiment scores, or other NLP insights.",
                    "**Kinesis**: For real-time sentiment analysis of streaming text data (e.g., social media feeds).",
                    "**CloudWatch**: For monitoring API usage and job status.",
                    "**SageMaker**: For more advanced custom NLP model development."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Text formats (UTF-8)", "JSON output"],
                pricing: "Pay-per-unit (100 characters) for analysis. Custom models, targeted sentiment, and events detection have separate pricing.",
                scenarios: [
                    "Analyzing customer feedback for sentiment and key insights",
                    "Automating content categorization and tagging",
                    "Extracting critical information from legal documents or research papers",
                    "Redacting sensitive information (PII/PHI) from text data",
                    "Building intelligent search and recommendation engines based on text content"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Inaccurate NLP Results",
                            desc: "Sentiment, entity, or keyphrase results might be inaccurate if the text is ambiguous, highly specialized, or non-standard.",
                            solutionSteps: [
                                "Ensure input text is well-formed and clearly expresses sentiment or contains recognizable entities.",
                                "For domain-specific terminology, consider training a custom entity recognizer or custom classifier.",
                                "Review the confidence scores of the analysis results and implement thresholds for your application."
                            ]
                        },
                        {
                            title: "Language Detection Issues",
                            desc: "Comprehend might misidentify languages if the text is very short or contains mixed languages.",
                            solutionSteps: [
                                "Provide longer text inputs for more reliable language detection.",
                                "Explicitly specify the language if known, to bypass auto-detection."
                            ]
                        }
                    ]
                }
            },
            translate: {
                name: "Amazon Translate",
                description: "Neural machine translation service that delivers fast, high-quality, and affordable language translation",
                features: ["Real-time Translation", "Batch Translation", "Custom Terminology", "Active Custom Translation"],
                featureDetails: {
                    "Real-time Translation": {
                        subFeatures: [
                            { title: "Instant Translation", desc: "Translates text in real time for interactive applications" },
                            { title: "Source Language Auto-detection", desc: "Automatically detects the source language of the input text" }
                        ],
                        navigation: "Translate Console -> Real-time translation (or API calls: TranslateText)",
                        options: [
                            "Enter text, choose target language",
                            "Optionally specify source language if known"
                        ]
                    },
                    "Batch Translation": {
                        subFeatures: [
                            { title: "Asynchronous Processing", desc: "Translates large volumes of text or documents offline" },
                            { title: "Document Translation", desc: "Supports translation of entire documents (e.g., HTML, Word, Plain Text)" }
                        ],
                        navigation: "Translate Console -> Batch translation jobs -> Create job (or API calls: StartTextTranslationJob)",
                        options: [
                            "Specify S3 input bucket for source documents",
                            "Choose target language(s) and output S3 bucket"
                        ]
                    },
                    "Custom Terminology": {
                        subFeatures: [
                            { title: "Domain-specific Translation", desc: "Ensures consistent translation of specific terms (e.g., product names, brand names)" },
                            { title: "Glossary Management", desc: "Create and manage custom glossaries for your translation needs" }
                        ],
                        navigation: "Translate Console -> Custom terminology -> Create terminology (or API calls: CreateTerminology)",
                        options: [
                            "Upload a CSV or TMX file with your custom terminology",
                            "Apply terminology to real-time or batch translation jobs"
                        ]
                    },
                    "Active Custom Translation": {
                        subFeatures: [
                            { title: "Custom Model Training", desc: "Train custom translation models using your parallel data" },
                            { title: "Improved Quality", desc: "Achieve higher translation quality for your specific domain" }
                        ],
                        navigation: "Translate Console -> Active Custom Translation -> Training jobs -> Create job",
                        options: [
                            "Upload parallel data (source and target language pairs in S3)",
                            "Train and evaluate your custom translation model"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input documents and output translated documents for batch translation.",
                    "**Lambda**: To trigger Translate for serverless translation workflows.",
                    "**API Gateway**: To expose real-time translation as a web service.",
                    "**Comprehend**: Can be used to detect the dominant language before translation.",
                    "**CloudWatch**: For monitoring API calls and job status."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Supported languages", "Document formats (HTML, TXT, DOCX, PPTX, XLSX)"],
                pricing: "Pay-per-character for text translated. Custom terminology usage is free, but training Active Custom Translation models has a cost.",
                scenarios: [
                    "Translating real-time chat conversations for global customer support",
                    "Localizing website content and documents for international markets",
                    "Enabling multi-language communication in applications",
                    "Translating product catalogs and legal documents"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Translation Quality Issues",
                            desc: "Translations might be literal, miss context, or incorrectly translate domain-specific terms.",
                            solutionSteps: [
                                "Use Custom Terminology to ensure specific terms (e.g., brand names, product names) are translated consistently.",
                                "For highly specialized domains, consider using Active Custom Translation to fine-tune the translation model with your own parallel data.",
                                "Review and refine source text for clarity before translation."
                            ]
                        },
                        {
                            title: "Unsupported Language Combinations",
                            desc: "Translate supports a wide range but not all language pairs.",
                            solutionSteps: [
                                "Check the official Amazon Translate documentation for the list of supported languages and language pairs."
                            ]
                        }
                    ]
                }
            },
            lex: {
                name: "Amazon Lex",
                description: "Service for building conversational interfaces (chatbots and voice bots) using voice and text",
                features: ["Speech Recognition (ASR)", "Natural Language Understanding (NLU)", "Context Management", "Multi-turn Conversations", "Integration with Lambda"],
                featureDetails: {
                    "Speech Recognition (ASR)": {
                        subFeatures: [
                            { title: "Automatic Speech Recognition", desc: "Converts spoken language into text" },
                            { title: "High Accuracy", desc: "Powered by the same technology as Amazon Alexa" }
                        ],
                        navigation: "Lex Console -> Bots -> Create bot -> Test (or API calls: RecognizeUtterance)",
                        options: [
                            "Define sample utterances for intents",
                            "Test voice input directly in the console"
                        ]
                    },
                    "Natural Language Understanding (NLU)": {
                        subFeatures: [
                            { title: "Intent Recognition", desc: "Identifies the user's goal or intent (e.g., 'BookFlight', 'OrderPizza')" },
                            { title: "Slot Extraction", desc: "Extracts specific pieces of information (slots) from the user's utterance (e.g., 'destination', 'pizza type')" },
                        ],
                        navigation: "Lex Console -> Bots -> Create bot -> Intents / Slot types",
                        options: [
                            "Define intents with sample utterances",
                            "Create custom slot types for specific data values"
                        ]
                    },
                    "Context Management": {
                        subFeatures: [
                            { title: "Contexts for Intents", desc: "Maintain conversation context across multiple turns" },
                            { title: "Follow-up Prompts", desc: "Guide the user through multi-step conversations" }
                        ],
                        navigation: "Lex Console -> Bots -> Intents -> Contexts",
                        options: [
                            "Define input and output contexts for intents",
                            "Configure follow-up prompts to collect necessary slot values",
                            "Choose context expiration (time-based or turn-based)"
                        ]
                    },
                    "Multi-turn Conversations": {
                        subFeatures: [
                            { title: "Dialogue Management", desc: "Manages the flow of conversation to achieve a user's goal" },
                            { title: "Clarification Prompts", desc: "Prompts the user for clarification when needed" }
                        ],
                        navigation: "Lex Console -> Bots -> Intents -> Fulfilment",
                        options: [
                            "Design the dialogue flow for each intent",
                            "Configure validation rules for slots"
                        ]
                    },
                    "Integration with Lambda": {
                        subFeatures: [
                            { title: "Backend Fulfillment", desc: "Use Lambda functions to fulfill user requests (e.g., retrieve data, book appointments)" },
                            { title: "Input Validation", desc: "Validate user input using Lambda functions" }
                        ],
                        navigation: "Lex Console -> Bots -> Intents -> Fulfillment -> AWS Lambda function",
                        options: [
                            "Create a Lambda function to handle the business logic of your intents",
                            "Grant Lex permissions to invoke the Lambda function"
                        ]
                    }
                },
                interdependencies: [
                    "**Lambda**: Essential for backend logic, data validation, and fulfilling user requests.",
                    "**DynamoDB**: For storing session data, user profiles, or other conversational state.",
                    "**Connect**: For integrating Lex chatbots with Amazon Connect for contact center solutions.",
                    "**Polly**: For text-to-speech conversion in voice bots.",
                    "**CloudWatch**: For monitoring bot performance and user interactions.",
                    "**KMS**: For encrypting conversational data."
                ],
                techStack: ["Voice/Text Input", "JSON Output", "Lambda (Python, Node.js)", "APIs"],
                pricing: "Pay-per-request for speech or text input. Pricing varies by input type (voice or text).",
                scenarios: [
                    "Building customer service chatbots for FAQs and order status",
                    "Creating interactive voice response (IVR) systems for phone support",
                    "Developing virtual assistants for internal employee support",
                    "Enabling voice commands in mobile applications"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Incorrect Intent Recognition",
                            desc: "Lex might misinterpret user utterances, leading to the wrong intent being triggered or slots not being filled.",
                            solutionSteps: [
                                "Add a wide variety of diverse sample utterances for each intent.",
                                "Use slot types effectively to guide NLU. Consider custom slot types for unique values.",
                                "Implement clarification prompts to ask users for more information when ambiguity is detected."
                            ]
                        },
                        {
                            title: "Lambda Fulfillment Errors",
                            desc: "Issues often arise when the Lex bot invokes a Lambda function for fulfillment, but the Lambda encounters an error.",
                            solutionSteps: [
                                "Check CloudWatch logs for the invoked Lambda function for runtime errors or permission issues.",
                                "Ensure the Lex bot's IAM role has `lambda:InvokeFunction` permissions for your fulfillment Lambda.",
                                "Verify that the Lambda function returns a valid Lex response format."
                            ]
                        }
                    ]
                }
            },
            polly: {
                name: "Amazon Polly",
                description: "Text-to-speech (TTS) service that turns text into lifelike speech",
                features: ["Standard Voices", "Neural Voices", "SSML Support", "Long-Form Synthesis", "Pronunciation Lexicons"],
                featureDetails: {
                    "Standard Voices": {
                        subFeatures: [
                            { title: "Variety of Languages", desc: "Supports dozens of languages and multiple voices within each language" },
                            { title: "Cost-Effective", desc: "Lower cost compared to neural voices" }
                        ],
                        navigation: "Polly Console -> Text-to-Speech (or API calls: SynthesizeSpeech)",
                        options: [
                            "Enter text, choose language and voice",
                            "Select output format (MP3, OGG, PCM)"
                        ]
                    },
                    "Neural Voices": {
                        subFeatures: [
                            { title: "Lifelike Speech", desc: "Deliver highly natural and expressive speech using deep learning" },
                            { title: "Newscaster Style", desc: "Specific voices designed for newscaster-like delivery" }
                        ],
                        navigation: "Polly Console -> Text-to-Speech (or API calls: SynthesizeSpeech)",
                        options: [
                            "Select a neural voice (indicated by 'Newscaster' or 'Neural' tag)",
                            "Experiment with different voice styles"
                        ]
                    },
                    "SSML Support": {
                        subFeatures: [
                            { title: "Speech Synthesis Markup Language", desc: "Control aspects of speech like pronunciation, volume, pitch, and speaking rate" },
                            { title: "Enhance Expressiveness", desc: "Add pauses, emphasis, and whispers for more natural-sounding speech" }
                        ],
                        navigation: "Polly Console -> Text-to-Speech (use SSML tab)",
                        options: [
                            "Embed SSML tags within your text to customize speech output",
                            "Refer to SSML documentation for available tags"
                        ]
                    },
                    "Long-Form Synthesis": {
                        subFeatures: [
                            { title: "Asynchronous Generation", desc: "Synthesize large volumes of text (up to millions of characters) into audio files" },
                            { title: "Chapter Markers", desc: "Generate markers for easy navigation within long audio files" }
                        ],
                        navigation: "Polly Console -> Long-form synthesis -> Create new task (or API calls: StartSpeechSynthesisTask)",
                        options: [
                            "Specify S3 input for text and S3 output for audio",
                            "Choose voice, format, and optional lexicon"
                        ]
                    },
                    "Pronunciation Lexicons": {
                        subFeatures: [
                            { title: "Custom Pronunciation", desc: "Customize the pronunciation of specific words, acronyms, or foreign phrases" },
                            { title: "XML-based Lexicons", desc: "Define pronunciations using the Pronunciation Lexicon Specification (PLS) format" }
                        ],
                        navigation: "Polly Console -> Lexicons -> Create lexicon (or API calls: PutLexicon)",
                        options: [
                            "Upload an XML file containing your custom pronunciations",
                            "Apply lexicons to your synthesis requests"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing output audio files, especially for long-form synthesis.",
                    "**Lambda**: To trigger Polly synthesis from other applications or events.",
                    "**Lex**: For providing voice output in conversational AI applications.",
                    "**Transcribe**: Can be used to generate text from audio that is then passed to Polly for re-synthesis.",
                    "**CloudWatch**: For monitoring API calls and service usage.",
                    "**SNS**: For receiving notifications on long-form synthesis job completion."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "SSML (Speech Synthesis Markup Language)", "Audio formats (MP3, OGG, PCM)"],
                pricing: "Pay-per-character for speech generated. Neural voices are more expensive than Standard voices. Long-form synthesis has separate pricing.",
                scenarios: [
                    "Creating audio versions of articles, blogs, and documents (audiobooks)",
                    "Developing voice user interfaces for mobile and web applications",
                    "Generating natural-sounding responses for chatbots and virtual assistants",
                    "Producing voiceovers for videos and presentations"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Unnatural or Incorrect Pronunciation",
                            desc: "Polly might mispronounce specific words, acronyms, or foreign names.",
                            solutionSteps: [
                                "Use SSML (Speech Synthesis Markup Language) tags to control pronunciation, emphasis, or add pauses.",
                                "Create custom pronunciation lexicons to define how specific words should be pronounced, especially for domain-specific terms."
                            ]
                        },
                        {
                            title: "Output Audio Quality",
                            desc: "Audio might sound robotic or have artifacts if voice/settings are suboptimal.",
                            solutionSteps: [
                                "Experiment with Neural Voices for more lifelike and natural-sounding speech.",
                                "Adjust the speaking rate, pitch, and volume using SSML to fine-tune the output."
                            ]
                        }
                    ]
                }
            },
            transcribe: {
                name: "Amazon Transcribe",
                description: "Automatic speech recognition (ASR) service that converts speech to text",
                features: ["Standard Transcription", "Medical Transcription", "Custom Vocabularies", "Custom Language Models", "Channel Identification", "Speaker Diarization"],
                featureDetails: {
                    "Standard Transcription": {
                        subFeatures: [
                            { title: "Batch Transcription", desc: "Transcribes audio files stored in S3 for offline processing" },
                            { title: "Streaming Transcription", desc: "Provides real-time transcription for live audio streams" },
                            { title: "Speaker Diarization", desc: "Identifies and separates individual speakers in audio" }
                        ],
                        navigation: "Transcribe Console -> Transcription jobs -> Create job (or API calls: StartTranscriptionJob)",
                        options: [
                            "Upload audio file (S3) or specify streaming source",
                            "Choose language, output format (JSON, VTT, SRT)",
                            "Enable speaker diarization or channel identification"
                        ]
                    },
                    "Medical Transcription": {
                        subFeatures: [
                            { title: "Specialized Medical Vocabulary", desc: "Highly accurate transcription for medical terminology and jargon" },
                            { title: "Clinical Documentation", desc: "Ideal for transcribing doctor-patient conversations, clinical notes" }
                        ],
                        navigation: "Transcribe Console -> Medical transcription jobs -> Create job (or API calls: StartMedicalTranscriptionJob)",
                        options: [
                            "Specify input medical audio (S3)",
                            "Choose medical specialty (e.g., Radiology, Cardiology)"
                        ]
                    },
                    "Custom Vocabularies": {
                        subFeatures: [
                            { title: "Improved Accuracy for Specific Terms", desc: "Boosts transcription accuracy for domain-specific words (e.g., product names, unique spellings)" },
                            { title: "Custom Word Lists", desc: "Provide a list of words and phrases with their pronunciations" }
                        ],
                        navigation: "Transcribe Console -> Custom vocabularies -> Create vocabulary (or API calls: CreateVocabulary)",
                        options: [
                            "Upload a text file with your custom words and phrases",
                            "Specify language and apply to transcription jobs"
                        ]
                    },
                    "Custom Language Models": {
                        subFeatures: [
                            { title: "Adapt to Your Domain", desc: "Train custom language models using your domain-specific text data" },
                            { title: "Enhanced Accuracy", desc: "Achieve higher transcription accuracy for specific accents, noisy environments, or specialized content" }
                        ],
                        navigation: "Transcribe Console -> Custom language models -> Create model (or API calls: CreateLanguageModel)",
                        options: [
                            "Upload training text data (S3)",
                            "Choose a base language model and train your custom model"
                        ]
                    },
                    "Channel Identification": {
                        subFeatures: [
                            { title: "Separate Audio Channels", desc: "Transcribes audio from multiple channels (e.g., left and right) separately" },
                            { title: "Call Center Analytics", desc: "Useful for analyzing customer and agent speech in call recordings" }
                        ],
                        navigation: "Transcribe Console -> Transcription jobs (enable channel identification)",
                        options: [
                            "Ensure your audio file has multiple channels",
                            "Enable channel identification when creating a transcription job"
                        ]
                    },
                    "Speaker Diarization": {
                        subFeatures: [
                            { title: "Identify Multiple Speakers", desc: "Determines when different speakers are talking in an audio file" },
                            { title: "Timestamped Speaker Labels", desc: "Provides timestamps for each speaker's turn" }
                        ],
                        navigation: "Transcribe Console -> Transcription jobs (enable speaker diarization)",
                        options: [
                            "Specify the number of speakers if known, or let Transcribe detect",
                            "Review the transcribed output with speaker labels"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input audio files and output transcription results.",
                    "**Lambda**: To trigger Transcribe jobs on new audio uploads or process transcription outputs.",
                    "**Comprehend**: For further NLP on transcribed text (e.g., sentiment analysis of call recordings).",
                    "**Kinesis Video Streams**: For real-time transcription of live audio/video streams.",
                    "**SNS / SQS**: For receiving notifications on transcription job completion."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Audio formats (MP3, WAV, FLAC, AMR, OGG, WebM)", "JSON output"],
                pricing: "Pay-per-second for audio processed. Medical transcription, custom vocabularies, and custom language models have separate pricing. Real-time streaming is also priced per second.",
                scenarios: [
                    "Transcribing customer service calls for quality assurance and analytics",
                    "Converting meeting recordings into searchable text documents",
                    "Generating subtitles and captions for video content",
                    "Enabling voice search in applications",
                    "Automating medical dictation for healthcare providers"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Transcription Inaccuracies",
                            desc: "Transcription might be inaccurate due to poor audio quality, heavy accents, background noise, or specialized vocabulary.",
                            solutionSteps: [
                                "Ensure high-quality, clear audio inputs. Reduce background noise if possible.",
                                "Use Custom Vocabularies for domain-specific terms (e.g., product names, medical jargon).",
                                "Consider Custom Language Models trained on your own domain-specific audio/text data for significant accuracy improvements."
                            ]
                        },
                        {
                            title: "Speaker Diarization/Channel Identification Errors",
                            desc: "Transcribe might incorrectly identify speakers or channels.",
                            solutionSteps: [
                                "Verify that multi-channel audio is correctly configured if using channel identification.",
                                "For diarization, ensure distinct voice patterns for different speakers in the audio. The quality of audio impacts diarization accuracy."
                            ]
                        }
                    ]
                }
            },
            forecast: {
                name: "Amazon Forecast",
                description: "Fully managed service that uses machine learning to deliver highly accurate forecasts",
                features: ["Automatic ML Models", "Hierarchical Forecasting", "What-if Analysis", "Cold Start Forecasting"],
                featureDetails: {
                    "Automatic ML Models": {
                        subFeatures: [
                            { title: "Automated Model Selection", desc: "Automatically selects the best forecasting algorithm based on your data" },
                            { title: "Hyperparameter Optimization", desc: "Tunes model parameters for optimal performance" },
                            { title: "Ensemble Models", desc: "Combines multiple models for improved accuracy" }
                        ],
                        navigation: "Forecast Console -> Datasets -> Create dataset group -> Create predictor",
                        options: [
                            "Choose 'AutoML' for automatic model selection or select specific algorithms (e.g., ARIMA, DeepAR+)",
                            "Define forecast horizon (e.g., next 7 days, 3 months)"
                        ]
                    },
                    "Hierarchical Forecasting": {
                        subFeatures: [
                            { title: "Multi-level Aggregation", desc: "Forecasts at different granularities (e.g., product, store, region)" },
                            { title: "Consistency Across Levels", desc: "Ensures forecasts are consistent from top to bottom" },
                            { title: "Group Forecasts", desc: "Generate forecasts for specific groups or categories" }
                        ],
                        navigation: "Forecast Console -> Datasets -> Create dataset group -> Create predictor -> Hierarchical Forecasting",
                        options: [
                            "Define hierarchy levels in your dataset (e.g., Item, Store, Region)",
                            "Specify the aggregation method for each level"
                        ]
                    },
                    "What-if Analysis": {
                        subFeatures: [
                            { title: "Scenario Planning", desc: "Simulate the impact of different business decisions or external events on your forecasts" },
                            { title: "Demand Planning", desc: "Evaluate scenarios like promotions, price changes, or supply chain disruptions" }
                        ],
                        navigation: "Forecast Console -> Forecasts -> Create what-if forecast",
                        options: [
                            "Choose an existing forecast as a baseline",
                            "Define perturbations or changes to your input data (e.g., increase price by 10%)"
                        ]
                    },
                    "Cold Start Forecasting": {
                        subFeatures: [
                            { title: "New Item Forecasting", desc: "Generate accurate forecasts for new products or locations with limited historical data" },
                            { title: "Similar Item Grouping", desc: "Uses data from similar items to create initial forecasts" }
                        ],
                        navigation: "Forecast Console (implicitly handled by the service)",
                        options: [
                            "Ensure your dataset includes relevant item metadata for grouping similar items."
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input datasets (historical demand, related time series, item metadata) and output forecasts.",
                    "**Lambda**: To trigger Forecast jobs or process forecast results for downstream applications.",
                    "**CloudWatch**: For monitoring Forecast job status and service usage.",
                    "**IAM**: For managing permissions for Forecast to access S3 and other resources."
                ],
                techStack: ["Time-series Algorithms (DeepAR+, ARIMA, Prophet)", "REST APIs", "SDKs (Python, Java)", "CSV/JSON input for datasets"],
                pricing: "Pay-per-GB for data stored, per-hour for training, and per-forecast for inference. What-if analysis has separate pricing.",
                scenarios: [
                    "Predicting product demand for inventory optimization in retail",
                    "Forecasting resource utilization for cloud infrastructure planning",
                    "Estimating electricity consumption for energy management",
                    "Predicting patient flow in healthcare facilities",
                    "Financial forecasting for stock prices or revenue"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Inaccurate Forecasts",
                            desc: "Forecast accuracy can suffer from insufficient or noisy historical data, missing related time series, or incorrect feature engineering.",
                            solutionSteps: [
                                "Ensure your historical dataset is clean, complete, and covers a sufficient time period.",
                                "Include relevant related time series data (e.g., promotions, holidays, weather) to improve accuracy.",
                                "Experiment with different predictors and algorithms, including AutoML to let Forecast choose the best one.",
                                "Review forecast error metrics (e.g., WAPE, RMSE) to understand model performance and identify areas for improvement."
                            ]
                        },
                        {
                            title: "Dataset Import/Training Errors",
                            desc: "Issues during dataset import or predictor training often relate to data format, missing columns, or S3 access.",
                            solutionSteps: [
                                "Verify CSV data adheres to the schema defined for your dataset (e.g., `timestamp`, `item_id`, `demand`).",
                                "Check IAM permissions for Forecast to read from your S3 input bucket and write to your S3 output bucket."
                            ]
                        }
                    ]
                }
            },
            personalize: {
                name: "Amazon Personalize",
                description: "Machine learning service that makes it easy for developers to create personalized recommendations for their customers using the same technology used by Amazon.com",
                features: ["User Segmentation", "Item Recommendations", "Personalized Ranking", "Real-time Personalization", "Cold Start Recommendations"],
                featureDetails: {
                    "User Segmentation": {
                        subFeatures: [
                            { title: "Dynamic User Segments", desc: "Automatically groups users into segments based on their behavior and preferences" },
                            { title: "Targeted Campaigns", desc: "Enables tailored marketing campaigns and content delivery" }
                        ],
                        navigation: "Personalize Console -> Campaigns -> Create campaign (using user segmentation recipes)",
                        options: [
                            "Choose a user segmentation recipe",
                            "Provide user interaction data and user metadata"
                        ]
                    },
                    "Item Recommendations": {
                        subFeatures: [
                            { title: "Personalized Item Lists", desc: "Generates recommendations for products, articles, videos, or other items" },
                            { title: "User-Item Interaction Data", desc: "Uses clickstream data, purchases, views, and ratings to build models" }
                        ],
                        navigation: "Personalize Console -> Solutions -> Create solution -> Choose recipe (e.g., 'Popularity', 'User-Personalization')",
                        options: [
                            "Upload interaction data (S3) and item metadata (S3)",
                            "Train a recommendation model and create a campaign"
                        ]
                    },
                    "Personalized Ranking": {
                        subFeatures: [
                            { title: "Re-rank Item Lists", desc: "Personalizes the order of a given list of items for a specific user" },
                            { title: "Search Results Personalization", desc: "Optimizes the display order of search results or product listings" }
                        ],
                        navigation: "Personalize Console -> Solutions -> Create solution -> Choose recipe ('Personalized-Ranking')",
                        options: [
                            "Provide user interaction data and item metadata",
                            "Integrate the personalized ranking campaign into your application"
                        ]
                    },
                    "Real-time Personalization": {
                        subFeatures: [
                            { title: "Low-latency Recommendations", desc: "Provides immediate recommendations as user behavior changes" },
                            { title: "Event Tracking", desc: "Captures user events (clicks, views, purchases) in real time" }
                        ],
                        navigation: "Personalize Console -> Event trackers -> Create event tracker (or API calls: PutEvents)",
                        options: [
                            "Set up an event tracker in your application to send real-time user events to Personalize",
                            "Retrieve real-time recommendations using the GetRecommendations API"
                        ]
                    },
                    "Cold Start Recommendations": {
                        subFeatures: [
                            { title: "New User Recommendations", desc: "Generates initial recommendations for new users with no history" },
                            { title: "New Item Recommendations", desc: "Recommends new items with limited interaction data" }
                        ],
                        navigation: "Personalize Console (implicitly handled by the service and specific recipes)",
                        options: [
                            "Use recipes like 'User-Personalization' which handle cold start scenarios",
                            "Ensure your item metadata is rich to help with new item recommendations"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing input datasets (user-item interactions, user metadata, item metadata) and model artifacts.",
                    "**Lambda**: To trigger Personalize updates or retrieve recommendations serverlessly.",
                    "**API Gateway**: To expose Personalize recommendation endpoints as web services.",
                    "**DynamoDB**: To store user profiles or item catalogs for quick lookup."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "CSV/JSON input for datasets"],
                pricing: "Pay-per-GB for data stored, per-hour for training, and per-recommendation for real-time inference (TPS-based for campaigns). Batch inference is priced per recommendation.",
                scenarios: [
                    "Personalized product recommendations on e-commerce websites",
                    "Tailored content suggestions for streaming services",
                    "Customized news feeds for media companies",
                    "Dynamic pricing based on user segments"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Irrelevant/Non-Diverse Recommendations",
                            desc: "Recommendations might not be accurate or diverse if the input data (interactions, user/item metadata) is sparse, biased, or lacks variety.",
                            solutionSteps: [
                                "Ensure a rich and diverse dataset of user-item interactions and metadata.",
                                "Use appropriate recipes (e.g., User-Personalization for diversity, HRNN for relevance).",
                                "Implement exploration strategies to introduce new items or cater to cold start users/items."
                            ]
                        },
                        {
                            title: "Real-time Event Tracking Issues",
                            desc: "Recommendations might not update in real-time if user events are not correctly sent to Personalize.",
                            solutionSteps: [
                                "Verify that your application is correctly sending `PutEvents` calls to Personalize with the correct event tracker ID and event data.",
                                "Check CloudWatch logs for event tracking errors."
                            ]
                        }
                    ]
                }
            },
            'fraud-detector': {
                name: "Amazon Fraud Detector",
                description: "Fully managed service that uses machine learning to identify potentially fraudulent online activities",
                features: ["Fraud Model Training", "Real-time Fraud Predictions", "Rules Engine", "Event-based Detection"],
                featureDetails: {
                    "Fraud Model Training": {
                        subFeatures: [
                            { title: "Pre-built ML Models", desc: "Leverages Amazon's experience in fraud detection to build high-accuracy models" },
                            { title: "Custom Model Training", desc: "Train models using your own historical fraud data" }
                        ],
                        navigation: "Fraud Detector Console -> Models -> Create model (or API calls: CreateModel)",
                        options: [
                            "Upload historical event data with fraud/legit labels (S3)",
                            "Choose a model type (e.g., Online Fraud Insights, Transaction Fraud Insights)"
                        ]
                    },
                    "Real-time Fraud Predictions": {
                        subFeatures: [
                            { title: "Low-latency Inference", desc: "Get real-time fraud predictions at the point of interaction (e.g., login, payment)" },
                            { title: "Fraud Scores", desc: "Receives a fraud score indicating the likelihood of an event being fraudulent" }
                        ],
                        navigation: "Fraud Detector Console -> Demos / API calls: GetEventPrediction",
                        options: [
                            "Send event data (e.g., user ID, IP address, payment amount) to the GetEventPrediction API"
                        ]
                    },
                    "Rules Engine": {
                        subFeatures: [
                            { title: "Define Custom Rules", desc: "Create business rules to identify fraud based on specific patterns or thresholds" },
                            { title: "Combine with ML Scores", desc: "Integrate ML model scores into your decision logic" }
                        ],
                        navigation: "Fraud Detector Console -> Rules -> Create rule",
                        options: [
                            "Define conditions using variables and operators (e.g., 'ip_address = bad_list' OR 'payment_amount > 1000')",
                            "Specify outcomes for rules (e.g., 'Review', 'Approve', 'Deny')"
                        ]
                    },
                    "Event-based Detection": {
                        subFeatures: [
                            { title: "Flexible Event Types", desc: "Define custom event types (e.g., 'registration', 'login', 'payment')" },
                            { title: "Input Variables", desc: "Specify relevant data points for each event type (e.g., email, user agent, card details)" }
                        ],
                        navigation: "Fraud Detector Console -> Event types -> Create event type",
                        options: [
                            "Define event name and associated variables (e.g., 'email_address', 'billing_address')",
                            "Integrate your application to send these events to Fraud Detector"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing historical event data for model training and for batch fraud predictions.",
                    "**Lambda**: To invoke Fraud Detector for real-time predictions or process prediction results.",
                    "**API Gateway**: To expose Fraud Detector prediction as a web service.",
                    "**CloudWatch**: For monitoring API calls, model performance, and rule evaluation.",
                    "**IAM**: For managing permissions for Fraud Detector to access data and and other services."
                ],
                techStack: ["REST APIs", "SDKs (Python, Java)", "Event Data (JSON/CSV)"],
                pricing: "Pay-per-prediction for evaluating events. Model training is priced per-hour.",
                scenarios: [
                    "Detecting fraudulent online registrations and account creations",
                    "Identifying suspicious payment transactions and chargebacks",
                    "Preventing promotional abuse and bonus fraud",
                    "Flagging potential account takeovers or unauthorized access attempts"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "High False Positives/Negatives",
                            desc: "Fraud Detector might incorrectly flag legitimate transactions as fraudulent (false positives) or miss actual fraud (false negatives) due to model accuracy or rule configuration.",
                            solutionSteps: [
                                "Improve model accuracy by providing a balanced and representative historical dataset for training (fraudulent and legitimate events).",
                                "Refine your rules: adjust thresholds for model scores, and add/modify rules based on identified fraud patterns.",
                                "Regularly review and fine-tune your model and rules based on feedback from manual reviews or business outcomes."
                            ]
                        },
                        {
                            title: "Event Prediction Latency",
                            desc: "Real-time fraud predictions might introduce undesirable latency in your application.",
                            solutionSteps: [
                                "Optimize the number of variables sent in each `GetEventPrediction` call to only include necessary data.",
                                "Ensure network connectivity between your application and Fraud Detector is optimized (e.g., use VPC Endpoints).",
                                "Monitor the latency metrics in CloudWatch for the `GetEventPrediction` API."
                            ]
                        }
                    ]
                }
            },
            'ec2-ai': {
                name: "EC2 AI Instances",
                description: "Amazon Elastic Compute Cloud (EC2) provides scalable computing capacity in the AWS Cloud, offering specialized instances optimized for AI and machine learning workloads",
                features: ["GPU Instances", "Inferentia Instances", "Trainium Instances", "Elastic Inference"],
                featureDetails: {
                    "GPU Instances": {
                        subFeatures: [
                            { title: "P-series Instances", desc: "Optimized for deep learning training and high-performance computing (e.g., p4d, p3dn)" },
                            { title: "G-series Instances", desc: "Ideal for graphics-intensive applications and machine learning inference (e.g., g5, g4dn)" },
                            { title: "High-performance GPUs", desc: "Feature NVIDIA GPUs for parallel processing and acceleration of ML tasks" }
                        ],
                        navigation: "EC2 Console -> Instances -> Launch instances -> Choose AMI -> Instance Type (filter by 'GPU')",
                        options: [
                            "Choose appropriate P or G series instance sizes based on workload needs",
                            "Install necessary GPU drivers and ML frameworks (e.g., CUDA, cuDNN, TensorFlow, PyTorch)"
                        ]
                    },
                    "Inferentia Instances": {
                        subFeatures: [
                            { title: "Inf1 instances", desc: "Powered by AWS Inferentia chips for high-performance, low-cost ML inference" },
                            { title: "Cost Optimization", desc: "Designed to significantly reduce inference costs compared to GPUs" },
                            { title: "Framework Support", desc: "Supports popular ML frameworks like TensorFlow, PyTorch, and ONNX" }
                        ],
                        navigation: "EC2 Console -> Instances -> Launch instances -> Choose AMI -> Instance Type (filter by 'Inferentia')",
                        options: [
                            "Choose Inf1 instance sizes (e.g., inf1.xlarge, inf1.24xlarge)",
                            "Optimize models for Inferentia using SageMaker Neo or AWS Neuron SDK"
                        ]
                    },
                    "Trainium Instances": {
                        subFeatures: [
                            { title: "Trn1 instances", desc: "Powered by AWS Trainium chips for high-performance, low-cost deep learning training" },
                            { title: "Massive Scale", desc: "Designed for petabyte-scale datasets and trillion-parameter models" },
                            { title: "Distributed Training", desc: "Optimized for distributed training with high-bandwidth networking" }
                        ],
                        navigation: "EC2 Console -> Instances -> Launch instances -> Choose AMI -> Instance Type (filter by 'Trainium')",
                        options: [
                            "Choose Trn1 instance sizes (e.g., trn1.2xlarge, trn1.32xlarge)",
                            "Utilize AWS Neuron SDK for model compilation and training"
                        ]
                    },
                    "Elastic Inference": {
                        subFeatures: [
                            { title: "Attachable Accelerators", desc: "Add GPU-powered inference acceleration to any EC2 instance type" },
                            { title: "Cost-Effective Inference", desc: "Optimize costs by adding only the necessary amount of GPU power" },
                            { title: "Flexible Deployment", desc: "Decouple compute and acceleration resources" }
                        ],
                        navigation: "EC2 Console -> Instances -> Launch instances -> Configure instance details -> Elastic Inference",
                        options: [
                            "Choose the EI accelerator type (e.g., eia1.medium, eia2.large)",
                            "Attach EI accelerators to compatible EC2 instances (e.g., M5, C5, R5)"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: For storing training data, model artifacts, and checkpointing during training.",
                    "**EBS**: For high-performance storage attached to instances.",
                    "**ECR**: For storing custom Docker images for ML environments.",
                    "**VPC**: For network configuration and security of instances.",
                    "**IAM**: For managing permissions for instances to access other AWS services.",
                    "**SageMaker**: Often uses EC2 instances under the hood for managed training and hosting.",
                    "**CloudWatch**: For monitoring instance performance and resource utilization."
                ],
                techStack: ["Linux/Windows AMIs", "Deep Learning AMIs", "Docker", "NVIDIA CUDA/cuDNN", "AWS Neuron SDK"],
                pricing: "Pay-per-hour for instance usage. Pricing varies significantly by instance type, region, and whether On-Demand, Reserved Instances, or Spot Instances are used.",
                scenarios: [
                    "Training large deep learning models (e.g., for computer vision, NLP)",
                    "Running high-volume real-time inference endpoints",
                    "Developing and testing new ML algorithms",
                    "Processing large datasets with ML libraries"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Insufficient GPU Memory",
                            desc: "Deep learning models require substantial GPU memory. Running out of memory leads to crashes during training or inference.",
                            solutionSteps: [
                                "Choose a larger GPU instance type (e.g., from `g4dn` to `p3` or `p4`).",
                                "Reduce batch size during training/inference to lower memory consumption.",
                                "Optimize your model architecture for memory efficiency (e.g., quantization, pruning)."
                            ]
                        },
                        {
                            title: "Driver/Framework Compatibility",
                            desc: "Incorrect or incompatible GPU drivers or ML framework versions can prevent models from running.",
                            solutionSteps: [
                                "Use AWS Deep Learning AMIs which come pre-configured with drivers and popular frameworks.",
                                "Ensure your CUDA, cuDNN, TensorFlow, or PyTorch versions are compatible with your chosen instance type and GPU architecture.",
                                "Check instance logs for errors related to driver or framework loading."
                            ]
                        }
                    ]
                }
            },
            'lambda-ai': {
                name: "Lambda + AI",
                description: "Serverless compute service that lets you run code without provisioning or managing servers, ideal for event-driven AI applications",
                features: ["Event-driven Inference", "Pre/Post-processing", "Model Deployment", "Asynchronous Workflows"],
                featureDetails: {
                    "Event-driven Inference": {
                        subFeatures: [
                            { title: "Real-time Processing", desc: "Trigger AI inference on new data uploads (e.g., images to S3, messages to SQS)" },
                            { title: "Scalable Inference", desc: "Automatically scales to handle spikes in inference requests" },
                            { title: "Cost-Effective", desc: "Pay only for the compute time consumed when your code runs" }
                        ],
                        navigation: "Lambda Console -> Functions -> Create function -> Add triggers",
                        options: [
                            "Configure triggers (S3, SQS, Kinesis, API Gateway, DynamoDB Streams)",
                            "Specify runtime (Python, Node.js, Java, .NET, Go, Ruby)",
                            "Allocate memory and timeout settings"
                        ]
                    },
                    "Pre/Post-processing": {
                        subFeatures: [
                            { title: "Data Transformation", desc: "Prepare input data for AI models (e.g., resize images, tokenize text)" },
                            { title: "Result Formatting", desc: "Process and format AI model outputs for downstream applications" },
                            { title: "Feature Engineering", desc: "Create new features from raw data before inference" }
                        ],
                        navigation: "Lambda Console -> Functions -> Select function -> Code",
                        options: [
                            "Write custom code in your preferred runtime language",
                            "Utilize AWS SDKs to interact with AI services"
                        ]
                    },
                    "Model Deployment": {
                        subFeatures: [
                            { title: "Lightweight Models", desc: "Deploy small ML models (e.g., ONNX, TensorFlow Lite) directly within Lambda" },
                            { title: "Container Images", desc: "Package larger models within container images for Lambda deployment" },
                            { title: "Layer Support", desc: "Include ML libraries (e.g., NumPy, Scikit-learn, TensorFlow) as Lambda layers" },
                        ],
                        navigation: "Lambda Console -> Functions -> Create function -> Select 'Container image' or configure 'Layers'",
                        options: [
                            "For container images, specify ECR repository and tag",
                            "For layers, add necessary ML libraries or custom code dependencies"
                        ]
                    },
                    "Asynchronous Workflows": {
                        subFeatures: [
                            { title: "Queued Processing", desc: "Process events asynchronously using SQS or SNS for robust workflows" },
                            { title: "Step Functions Orchestration", desc: "Combine Lambda with Step Functions for complex, multi-step AI pipelines" },
                            { title: "Dead-letter Queues", desc: "Handle failed invocations gracefully" }
                        ],
                        navigation: "Lambda Console -> Functions -> Select function -> Configuration -> Asynchronous invocation",
                        options: [
                            "Configure destination for successful/failed invocations (e.g., SQS, SNS)",
                            "Set up retry attempts and maximum event age"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: Common trigger for Lambda functions, especially for new object uploads (e.g., images, documents).",
                    "**API Gateway**: To expose Lambda functions as RESTful APIs for real-time inference.",
                    "**SQS / SNS**: For queuing events and asynchronous processing, and for notifications.",
                    "**DynamoDB**: For storing application state or lightweight data related to AI inferences.",
                    "**SageMaker**: Lambda can invoke SageMaker endpoints for inference or trigger SageMaker jobs.",
                    "**All AWS AI Services**: Lambda acts as an orchestrator and integration point for almost all AWS AI services.",
                    "**CloudWatch**: For monitoring Lambda function invocations, errors, and logs."
                ],
                techStack: ["Python", "Node.js", "Java", ".NET", "Go", "Ruby", "Custom Runtimes", "Container Images"],
                pricing: "Pay-per-request and per-GB-second of compute time. Free tier available.",
                scenarios: [
                    "Image classification on new image uploads to S3",
                    "Real-time sentiment analysis of chat messages",
                    "Triggering document processing with Textract when a PDF is uploaded",
                    "Generating personalized content using Personalize upon user interaction events"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Lambda Timeout Errors",
                            desc: "Lambda functions may timeout if they take too long to execute, often due to complex AI inference or large data processing.",
                            solutionSteps: [
                                "Increase the Lambda function's timeout duration (up to 15 minutes).",
                                "Optimize your code for efficiency, offloading heavy processing to other services (e.g., SageMaker endpoints) if possible.",
                                "Increase allocated memory to speed up CPU-bound tasks."
                            ]
                        },
                        {
                            title: "Deployment Package Size Limits",
                            desc: "Lambda has limits on deployment package size, which can be an issue for large ML models or libraries.",
                            solutionSteps: [
                                "Use Lambda Layers to include large dependencies (like ML libraries).",
                                "Deploy functions as container images (up to 10GB) for larger models and runtime environments."
                            ]
                        },
                        {
                            title: "Cold Starts for Inference",
                            desc: "Infrequent Lambda invocations can experience 'cold starts' leading to higher latency for initial requests.",
                            solutionSteps: [
                                "Use Provisioned Concurrency for production workloads requiring low latency, which keeps functions initialized.",
                                "Optimize code and package size to reduce cold start duration."
                            ]
                        }
                    ]
                }
            },
            'iam-ai': {
                name: "IAM for AI Services",
                description: "AWS Identity and Access Management (IAM) controls who can access your AWS resources and what they can do with them, crucial for securing AI workloads",
                features: ["Role-based Access Control (RBAC)", "Fine-grained Permissions", "Service-linked Roles", "Identity Federation"],
                featureDetails: {
                    "Role-based Access Control (RBAC)": {
                        subFeatures: [
                            { title: "IAM Roles", desc: "Grant temporary permissions to entities (users, applications, services) without long-term credentials" },
                            { title: "Trust Policies", desc: "Define which entities can assume a role" },
                            { title: "Permissions Policies", desc: "Specify what actions can be performed on which resources" }
                        ],
                        navigation: "IAM Console -> Roles -> Create role",
                        options: [
                            "Choose trusted entity (e.g., 'AWS service', 'Web identity', 'SAML 2.0 federation')",
                            "Attach permission policies (e.g., AmazonS3ReadOnlyAccess, AmazonSageMakerFullAccess)"
                        ]
                    },
                    "Fine-grained Permissions": {
                        subFeatures: [
                            { title: "Resource-level Permissions", desc: "Control access to specific SageMaker models, S3 buckets, or Comprehend jobs" },
                            { title: "Condition Keys", desc: "Add conditions to policies (e.g., allow access only from specific IP addresses)" },
                            { title: "Tags for Access Control", desc: "Use resource tags to define access policies dynamically" }
                        ],
                        navigation: "IAM Console -> Policies -> Create policy (visual editor or JSON)",
                        options: [
                            "Specify ARN (Amazon Resource Name) for specific resources",
                            "Use 'Condition' block in JSON policies (e.g., `aws:SourceIp`)",
                            "Implement tag-based access control strategies"
                        ]
                    },
                    "Service-linked Roles": {
                        subFeatures: [
                            { title: "Predefined by AWS", desc: "Roles pre-configured with permissions required by an AWS service to call other AWS services on your behalf" },
                            { title: "Automated Creation", desc: "Automatically created when you enable or configure certain AWS services" },
                            { title: "Streamlined Setup", desc: "Simplifies granting necessary permissions without manual configuration" }
                        ],
                        navigation: "IAM Console -> Roles (filter by 'Service-linked roles')",
                        options: [
                            "Understand the permissions granted by service-linked roles (read-only access to policies)"
                        ]
                    },
                    "Identity Federation": {
                        subFeatures: [
                            { title: "SSO Integration", desc: "Integrate with corporate directories (e.g., Active Directory) or identity providers (e.g., Okta, PingOne)" },
                            { title: "SAML 2.0 Support", desc: "Use SAML for federated access to AWS accounts" },
                            { title: "Web Identity Federation", desc: "Enable users to sign in with public identity providers (e.g., Login with Amazon, Facebook, Google)" }
                        ],
                        navigation: "IAM Console -> Identity providers -> Add provider",
                        options: [
                            "Configure trust relationships with your IdP",
                            "Map IdP attributes to IAM roles"
                        ]
                    }
                },
                interdependencies: [
                    "**All AWS AI Services**: IAM is fundamental for securing access to every AWS service, including all AI/ML offerings.",
                    "**Organizations**: For centrally managing permissions across multiple AWS accounts.",
                    "**CloudTrail**: To log all API calls made to AWS services, including those governed by IAM policies, for auditing and compliance.",
                    "**Resource Access Manager (RAM)**: For sharing resources across AWS accounts, which also relies on IAM for permissions."
                ],
                techStack: ["IAM Policies (JSON)", "AWS CLI", "AWS SDKs", "SAML 2.0"],
                pricing: "No direct cost for IAM. You only pay for the AWS resources that your users and applications access.",
                scenarios: [
                    "Granting data scientists specific permissions to train models in SageMaker without access to production databases",
                    "Controlling which S3 buckets a Textract job can read from or write to",
                    "Federating access for enterprise users to the AWS console and specific AI services",
                    "Ensuring only authorized applications can call AI service APIs"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Access Denied Errors (General)",
                            desc: "This is the most common IAM issue. It means the principal (user, role, service) attempting an action lacks the necessary permissions.",
                            solutionSteps: [
                                "Check CloudTrail logs for the specific `errorCode` (`AccessDenied`) and the `eventSource` (e.g., `s3.amazonaws.com`).",
                                "Identify the `userIdentity` that made the failed call and inspect its attached policies.",
                                "Use the IAM Policy Simulator to test policy changes before applying them.",
                                "Ensure any service-linked roles required are present and have not been modified incorrectly."
                            ]
                        },
                        {
                            title: "iam:PassRole Permission Issues",
                            desc: "When an AWS service needs to assume another role (e.g., SageMaker training job assuming an execution role), the calling entity needs `iam:PassRole` permission for that specific role.",
                            solutionSteps: [
                                "Verify that the user or service initiating the operation has `iam:PassRole` for the execution role being passed to the target service."
                            ]
                        }
                    ]
                }
            },
            'vpc-security': {
                name: "VPC & Network Security",
                description: "Amazon Virtual Private Cloud (VPC) lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define, crucial for secure AI deployments",
                features: ["Private Subnets", "Security Groups", "Network ACLs", "VPC Endpoints", "Direct Connect/VPN"],
                featureDetails: {
                    "Private Subnets": {
                        subFeatures: [
                            { title: "Network Isolation", desc: "Isolate your AI resources (e.g., SageMaker endpoints, EC2 instances) from the public internet" },
                            { title: "Controlled Egress", desc: "Route outbound traffic through NAT gateways or proxy servers" },
                            { title: "Enhanced Security", desc: "Minimizes attack surface for sensitive AI workloads" }
                        ],
                        navigation: "VPC Console -> Subnets -> Create subnet",
                        options: [
                            "Define CIDR blocks for subnets",
                            "Associate with route tables for internet access or private routing",
                            "Place sensitive AI workloads (training, inference) in private subnets"
                        ]
                    },
                    "Security Groups": {
                        subFeatures: [
                            { title: "Virtual Firewalls", desc: "Act as stateful firewalls for EC2 instances and other resources at the instance level" },
                            { title: "Inbound/Outbound Rules", desc: "Control traffic based on IP address, port, and protocol" },
                            { title: "References", desc: "Reference other security groups for easier management" }
                        ],
                        navigation: "EC2 Console -> Security Groups -> Create security group",
                        options: [
                            "Define inbound rules (e.g., allow SSH from specific IPs, allow HTTPS from anywhere)",
                            "Define outbound rules (e.g., allow all outbound to internet, restrict to specific services)"
                        ]
                    },
                    "Network ACLs": {
                        subFeatures: [
                            { title: "Stateless Packet Filters", desc: "Optional layer of security at the subnet level, inspecting both inbound and outbound traffic" },
                            { title: "Numbered Rules", desc: "Rules are evaluated in order, and the first matching rule is applied" },
                            { title: "Deny Rules", desc: "Can explicitly deny traffic, unlike security groups" }
                        ],
                        navigation: "VPC Console -> Network ACLs -> Create network ACL",
                        options: [
                            "Define inbound and outbound rules with rule numbers (lower numbers are evaluated first)",
                            "Associate ACLs with specific subnets"
                        ]
                    },
                    "VPC Endpoints": {
                        subFeatures: [
                            { title: "Private Connectivity", desc: "Connect your VPC to AWS services (e.g., S3, SageMaker, Comprehend) privately without using the public internet" },
                            { title: "Interface Endpoints (Powered by PrivateLink)", desc: "Elastic Network Interfaces (ENIs) within your VPC for service access" },
                            { title: "Gateway Endpoints", desc: "Gateway to S3 and DynamoDB from your VPC" }
                        ],
                        navigation: "VPC Console -> Endpoints -> Create endpoint",
                        options: [
                            "Choose service name (e.g., com.amazonaws.region.sagemaker.api)",
                            "Select VPC and subnets for the endpoint",
                            "Attach security groups and endpoint policies for granular control"
                        ]
                    },
                    "Direct Connect/VPN": {
                        subFeatures: [
                            { title: "On-premises Connectivity", desc: "Establish private connections from your on-premises network to your VPC" },
                            { title: "Direct Connect", desc: "Dedicated network connection for consistent network performance" },
                            { title: "Site-to-Site VPN", desc: "Secure connection over public internet" }
                        ],
                        navigation: "VPC Console -> Direct Connect / Site-to-Site VPN",
                        options: [
                            "Order a Direct Connect connection or configure a VPN connection",
                            "Set up routing to allow traffic between your on-premises network and VPC"
                        ]
                    }
                },
                interdependencies: [
                    "**EC2**: EC2 instances are launched within VPCs.",
                    "**S3**: S3 can be accessed via VPC Gateway Endpoints or private links.",
                    "**SageMaker**: SageMaker resources (notebooks, training jobs, endpoints) can be launched within your VPC.",
                    "**Lambda**: Lambda functions can access resources within your VPC.",
                    "**PrivateLink**: Powers Interface VPC Endpoints for many AWS services.",
                    "**Route 53**: For DNS resolution within your VPC."
                ],
                techStack: ["Networking Concepts (CIDR, Subnets)", "Security Groups", "Network ACLs", "VPC Endpoints", "AWS Direct Connect", "AWS Site-to-Site VPN"],
                pricing: "Pricing applies for NAT Gateways, VPC Endpoints, Direct Connect, and VPNs. Intra-VPC traffic and Security Groups/NACLs usually have no direct cost.",
                scenarios: [
                    "Securing SageMaker models and data within a private network",
                    "Ensuring compliance requirements by isolating AI workloads",
                    "Connecting on-premises data sources to AI services in the cloud securely",
                    "Controlling inbound and outbound network traffic for AI inference endpoints"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Network Connectivity Failures/Timeouts",
                            desc: "Resources in private subnets cannot access the internet or other AWS services without proper routing, NAT gateways, or VPC endpoints.",
                            solutionSteps: [
                                "Check Route Tables: Ensure subnets have correct routes to NAT Gateway (for internet-bound traffic from private subnets) or VPC Endpoints (for private AWS service access).",
                                "Verify Security Groups: Make sure ingress/egress rules allow necessary traffic (e.g., SSH, HTTPS, specific ports for database connections).",
                                "Confirm Network ACLs: Ensure explicit allow rules for required traffic. Remember NACLs are stateless.",
                                "Utilize VPC Flow Logs: Analyze traffic to see if connections are being rejected or dropped at the subnet or ENI level."
                            ]
                        },
                        {
                            title: "Inability to Access Public Endpoints from Private Subnet",
                            desc: "Lambda functions or EC2 instances in a private subnet cannot reach public internet endpoints unless a NAT Gateway is configured.",
                            solutionSteps: [
                                "Deploy a NAT Gateway in a public subnet and associate it with the route table of your private subnet."
                            ]
                        }
                    ]
                }
            },
            encryption: {
                name: "Data Encryption",
                description: "AWS provides multiple services and features to encrypt data at rest and in transit, ensuring the security and privacy of sensitive AI/ML data",
                features: ["Encryption at Rest (S3, EBS, RDS)", "Encryption in Transit (SSL/TLS)", "AWS Key Management Service (KMS)", "Client-Side Encryption"],
                featureDetails: {
                    "Encryption at Rest (S3, EBS, RDS)": {
                        subFeatures: [
                            { title: "S3 Encryption", desc: "Encrypts data stored in S3 buckets (SSE-S3, SSE-KMS, SSE-C)" },
                            { title: "EBS Encryption", desc: "Encrypts data volumes attached to EC2 instances" },
                            { title: "RDS Encryption", desc: "Encrypts databases instances and snapshots" }
                        ],
                        navigation: "S3 Console -> Bucket properties / EC2 Console -> EBS Volumes / RDS Console -> Databases",
                        options: [
                            "Enable default encryption for S3 buckets",
                            "Create encrypted EBS volumes",
                            "Enable encryption for RDS instances during creation"
                        ]
                    },
                    "Encryption in Transit (SSL/TLS)": {
                        subFeatures: [
                            { title: "HTTPS Endpoints", desc: "All AWS service APIs use HTTPS/SSL for secure communication" },
                            { title: "Client-Server Encryption", desc: "Encrypts data moving between your applications and AWS services" }
                        ],
                        navigation: "Implicitly handled by AWS service APIs, configure client applications for SSL/TLS",
                        options: [
                            "Ensure your application uses HTTPS for all communication with AWS endpoints",
                            "Utilize AWS SDKs which handle secure communication automatically"
                        ]
                    },
                    "AWS Key Management Service (KMS)": {
                        subFeatures: [
                            { title: "Managed Encryption Keys", desc: "Create and control encryption keys used across AWS services" },
                            { title: "Customer Managed Keys (CMKs)", desc: "You have full control over the lifecycle of your keys" },
                            { title: "AWS Managed Keys", desc: "Keys managed by AWS for AWS services" }
                        ],
                        navigation: "KMS Console -> Customer managed keys -> Create key",
                        options: [
                            "Choose key type (Symmetric, Asymmetric)",
                            "Define key usage (Encrypt and decrypt, Sign and verify)",
                            "Set key policy to control access"
                        ]
                    },
                    "Client-Side Encryption": {
                        subFeatures: [
                            { title: "Encrypt Data Before Upload", desc: "Encrypt data on your client-side application before sending to AWS" },
                            { title: "Enhanced Security", desc: "You control the encryption process and keys entirely" }
                        ],
                        navigation: "Implement in your application code using AWS SDKs or open-source libraries",
                        options: [
                            "Use the S3 Encryption Client in AWS SDKs for transparent client-side encryption and decryption",
                            "Manage your own encryption keys or integrate with KMS"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: Commonly used with S3 for data at rest encryption.",
                    "**EBS**: For encrypting EC2 instance storage.",
                    "**RDS**: For encrypting database instances.",
                    "**DynamoDB**: Supports encryption at rest.",
                    "**CloudTrail**: Logs all API calls to KMS for auditing key usage.",
                    "**IAM**: For controlling access to KMS keys."
                ],
                techStack: ["AES-256", "RSA", "PKCS#7", "SSL/TLS", "AWS KMS", "AWS SDKs"],
                pricing: "KMS is priced per key and per API request for cryptographic operations. Other encryption features may have implicit costs as part of the service pricing.",
                scenarios: [
                    "Storing sensitive training data (e.g., PII, medical records) securely in S3 with encryption at rest",
                    "Ensuring secure communication between an AI application and its backend services using SSL/TLS",
                    "Meeting compliance requirements (e.g., HIPAA, GDPR) for data encryption in AI workloads",
                    "Protecting AI model artifacts and inference results from unauthorized access"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "KMS Key Access Denied",
                            desc: "Applications or services fail to access encrypted data because the IAM role/user lacks permissions for the associated KMS key.",
                            solutionSteps: [
                                "Verify the KMS Key Policy allows the IAM role/user (`kms:Decrypt`, `kms:GenerateDataKey`) to use the key.",
                                "Check that the IAM policy attached to the role/user also grants permission to the KMS key."
                            ]
                        },
                        {
                            title: "Data Not Encrypted at Rest",
                            desc: "Sensitive data is stored unencrypted due to misconfiguration.",
                            solutionSteps: [
                                "For S3, enable default encryption on the bucket (`SSE-S3` or `SSE-KMS`).",
                                "For EBS, ensure volumes are created with encryption enabled.",
                                "For RDS, enable encryption during database instance creation. Encrypt snapshots for existing unencrypted databases."
                            ]
                        }
                    ]
                }
            },
            compliance: {
                name: "Compliance & Governance",
                description: "AWS provides a secure and compliant environment for AI workloads, adhering to various global and industry-specific compliance standards and offering tools for governance",
                features: ["Certifications & Attestations", "AWS Config", "AWS CloudTrail", "AWS Audit Manager"],
                featureDetails: {
                    "Certifications & Attestations": {
                        subFeatures: [
                            { title: "Global Compliance Programs", desc: "Adherence to standards like ISO, SOC, PCI DSS, GDPR, HIPAA, FedRAMP" },
                            { title: "Industry-specific Compliance", desc: "Meeting requirements for healthcare, finance, government, etc." }
                        ],
                        navigation: "AWS Artifact Console -> Compliance reports",
                        options: [
                            "Download compliance reports and certifications relevant to your industry",
                            "Understand shared responsibility model for compliance"
                        ]
                    },
                    "AWS Config": {
                        subFeatures: [
                            { title: "Configuration Management", desc: "Continuously monitors and records your AWS resource configurations" },
                            { title: "Compliance Rules", desc: "Evaluates configurations against predefined or custom compliance rules" },
                            { title: "Remediation Actions", desc: "Automate remediation for non-compliant resources" }
                        ],
                        navigation: "AWS Config Console -> Rules / Resources",
                        options: [
                            "Enable AWS Config for relevant resource types (e.g., S3 buckets, SageMaker endpoints)",
                            "Deploy AWS Config rules to check for desired configurations (e.g., S3 bucket encryption enabled)"
                        ]
                    },
                    "AWS CloudTrail": {
                        subFeatures: [
                            { title: "API Activity Logging", desc: "Records API calls made across your AWS account, providing an audit trail" },
                            { title: "Security Analysis", desc: "Helps with security analysis, resource change tracking, and troubleshooting" }
                        ],
                        navigation: "CloudTrail Console -> Event history / Trails",
                        options: [
                            "Enable CloudTrail for all regions and configure S3 bucket for log storage",
                            "Use CloudTrail Lake for advanced event queries and analysis"
                        ]
                    },
                    "AWS Audit Manager": {
                        subFeatures: [
                            { title: "Automated Evidence Collection", desc: "Continuously collects evidence for audits (e.g., from Config, CloudTrail, Security Hub)" },
                            { title: "Pre-built Frameworks", desc: "Supports industry-standard frameworks like CIS, GDPR, HIPAA" }
                        ],
                        navigation: "Audit Manager Console -> Assessments -> Create assessment",
                        options: [
                            "Choose an assessment framework (e.g., PCI DSS, HIPAA)",
                            "Define the scope of your audit and collect evidence automatically"
                        ]
                    }
                },
                interdependencies: [
                    "**All AWS Services**: Compliance applies to all services. Config, CloudTrail, and Audit Manager collect data from across AWS.",
                    "**IAM**: For controlling access to audit logs and compliance tools.",
                    "**S3**: For storing CloudTrail logs and Audit Manager evidence.",
                    "**Security Hub**: Integrates with Config to provide security and compliance posture."
                ],
                techStack: ["AWS Config Rules", "CloudTrail Event History", "Audit Manager Frameworks", "Compliance Standards"],
                pricing: "AWS Config is priced per configuration item recorded and per rule evaluation. CloudTrail is priced per management event logged. Audit Manager is priced per evidence collected.",
                scenarios: [
                    "Maintaining GDPR compliance for AI models processing personal data",
                    "Ensuring HIPAA compliance for healthcare AI applications using patient data",
                    "Automating evidence collection for SOC 2 audits of your AI infrastructure",
                    "Tracking configuration changes to AI resources for governance and troubleshooting"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Non-compliant Resources",
                            desc: "AWS Config rules flag resources as non-compliant, indicating security or operational deviations.",
                            solutionSteps: [
                                "Review the specific AWS Config rule and its remediation guidance.",
                                "Identify the non-compliant resource and adjust its configuration to meet the rule's requirements.",
                                "Automate remediation actions using AWS Config remediations where appropriate."
                            ]
                        },
                        {
                            title: "Missing Audit Trails/Logs",
                            desc: "Critical activities or resource changes are not being logged, hindering auditing and incident response.",
                            solutionSteps: [
                                "Ensure AWS CloudTrail is enabled for all regions and logging to an S3 bucket.",
                                "Verify S3 bucket policies allow CloudTrail to write logs.",
                                "Check CloudWatch Logs integration for relevant service logs to ensure they are being captured."
                            ]
                        }
                    ]
                }
            },
            monitoring: {
                name: "Security Monitoring",
                description: "AWS provides services to continuously monitor your AI workloads for security threats, anomalies, and operational issues, enabling rapid detection and response",
                features: ["Amazon GuardDuty", "AWS Security Hub", "Amazon Macie", "AWS Config"],
                featureDetails: {
                    "Amazon GuardDuty": {
                        subFeatures: [
                            { title: "Intelligent Threat Detection", desc: "Continuously monitors for malicious activity and unauthorized behavior" },
                            { title: "Anomaly Detection", desc: "Uses machine learning to identify unusual API calls or network activity" },
                            { title: "Integrated Threat Intelligence", desc: "Leverages AWS and third-party threat intelligence feeds" }
                        ],
                        navigation: "GuardDuty Console -> Enable GuardDuty",
                        options: [
                            "Enable GuardDuty in all relevant regions",
                            "Review findings and integrate with SIEM/SOAR systems"
                        ]
                    },
                    "AWS Security Hub": {
                        subFeatures: [
                            { title: "Centralized Security Posture", desc: "Aggregates security findings from various AWS services (e.g., GuardDuty, Config, Macie)" },
                            { title: "Automated Security Checks", desc: "Conducts automated security best practice checks" },
                            { title: "Integrated Remediation", desc: "Provides actionable insights and automates remediation workflows" }
                        ],
                        navigation: "Security Hub Console -> Enable Security Hub",
                        options: [
                            "Enable Security Hub and link relevant AWS accounts",
                            "Configure integration with other security services",
                            "Prioritize and investigate findings"
                        ]
                    },
                    "Amazon Macie": {
                        subFeatures: [
                            { title: "Sensitive Data Discovery", desc: "Uses machine learning to discover and protect sensitive data in S3 (e.g., PII, PHI)" },
                            { title: "Data Security Monitoring", desc: "Continuously monitors S3 buckets for data access anomalies and risks" },
                            { title: "Automated Classification", desc: "Automates the classification of sensitive data" }
                        ],
                        navigation: "Macie Console -> Enable Macie",
                        options: [
                            "Enable Macie and select S3 buckets for analysis",
                            "Review sensitive data findings and access policies"
                        ]
                    },
                    "AWS Config": {
                        subFeatures: [
                            { title: "Configuration Compliance", desc: "Ensures your AI resources (e.g., S3 buckets, EC2 instances) comply with security standards" },
                            { title: "Change Tracking", desc: "Logs all configuration changes for auditing and troubleshooting security incidents" }
                        ],
                        navigation: "AWS Config Console -> Rules",
                        options: [
                            "Deploy Config rules to enforce security best practices (e.g., encryption enabled for S3, public access blocked)",
                            "Integrate Config findings with Security Hub"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: GuardDuty monitors S3 data events. Macie scans S3 for sensitive data. Config monitors S3 bucket configurations.",
                    "**CloudTrail**: GuardDuty analyzes CloudTrail logs for suspicious API activity.",
                    "**VPC Flow Logs**: GuardDuty analyzes VPC Flow Logs for network anomalies.",
                    "**Lambda**: Can be used to automate responses to security findings from these services.",
                    "**SNS**: For sending notifications on critical security alerts.",
                    "**IAM**: For controlling access to these security monitoring services."
                ],
                techStack: ["ML-based Threat Detection", "Automated Security Checks", "Configuration Monitoring", "Log Analysis"],
                pricing: "GuardDuty is priced per GB of VPC Flow Logs, DNS logs, and CloudTrail management events analyzed. Security Hub is priced per security check and per finding ingested. Macie is priced per GB of data scanned.",
                scenarios: [
                    "Detecting unauthorized access attempts to SageMaker notebooks or S3 data buckets",
                    "Monitoring for unusual data exfiltration patterns from AI storage",
                    "Automating the identification of unencrypted sensitive data in S3 buckets used by AI services",
                    "Aggregating and prioritizing security findings from various AI-related services in one dashboard"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Excessive Security Findings (Alert Fatigue)",
                            desc: "Too many low-priority or false-positive findings from GuardDuty, Macie, or Security Hub can overwhelm security teams.",
                            solutionSteps: [
                                "Prioritize findings by severity and impact in Security Hub.",
                                "Filter out known benign activities or misconfigurations.",
                                "Refine GuardDuty exclusion lists for trusted activities.",
                                "Tune Macie to focus on specific S3 buckets or data types with higher sensitivity."
                            ]
                        },
                        {
                            title: "Missed Threats",
                            desc: "Security services might fail to detect actual threats due to misconfiguration or lack of coverage.",
                            solutionSteps: [
                                "Ensure GuardDuty is enabled in all regions and covers all relevant data sources (CloudTrail, VPC Flow Logs, DNS Logs, S3 Data Events).",
                                "Verify Macie is enabled for all S3 buckets containing sensitive data.",
                                "Regularly review Security Hub standards (e.g., AWS Foundational Security Best Practices) and ensure high compliance scores."
                            ]
                        }
                    ]
                }
            },
            'data-protection': {
                name: "Data Protection & Privacy",
                description: "AWS offers services and best practices to help protect sensitive data used in AI/ML workloads and ensure privacy compliance",
                features: ["Amazon Macie", "AWS PrivateLink", "AWS Config", "Data Anonymization Techniques"],
                featureDetails: {
                    "Amazon Macie": {
                        subFeatures: [
                            { title: "Automated Sensitive Data Discovery", desc: "Uses machine learning to identify PII, PHI, and other sensitive data in S3" },
                            { title: "Data Security Monitoring", desc: "Monitors S3 access patterns and generates alerts for anomalous activity" },
                            { title: "Compliance Reporting", desc: "Helps identify compliance risks related to sensitive data storage" }
                        ],
                        navigation: "Macie Console -> Overview / S3 buckets",
                        options: [
                            "Enable Macie and select S3 buckets containing AI training/inference data",
                            "Review findings and remediate data exposure risks"
                        ]
                    },
                    "AWS PrivateLink": {
                        subFeatures: [
                            { title: "Private Connectivity to Services", desc: "Access AWS services (e.g., S3, SageMaker, Comprehend) directly from your VPC without traversing the public internet" },
                            { title: "Enhanced Data Privacy", desc: "Reduces exposure of sensitive data by keeping network traffic within the AWS network" }
                        ],
                        navigation: "VPC Console -> Endpoints -> Create endpoint",
                        options: [
                            "Create VPC Interface Endpoints for relevant AWS AI services",
                            "Ensure your applications are configured to use these private endpoints"
                        ]
                    },
                    "AWS Config": {
                        subFeatures: [
                            { title: "Configuration Monitoring for Data Protection", desc: "Monitors configurations of data storage and processing services for compliance with data protection policies" },
                            { title: "Audit Trails for Data Access", desc: "Complements CloudTrail by recording configuration changes related to data access" }
                        ],
                        navigation: "AWS Config Console -> Rules",
                        options: [
                            "Deploy Config rules that check for encryption, public access settings, and logging on S3 buckets, RDS, DynamoDB",
                            "Use conformance packs to manage a collection of rules for data protection standards"
                        ]
                    },
                    "Data Anonymization Techniques": {
                        subFeatures: [
                            { title: "De-identification", desc: "Removing or masking direct identifiers (e.g., names, SSN) from data" },
                            { title: "Pseudonymization", desc: "Replacing sensitive identifiers with artificial identifiers" },
                            { title: "Differential Privacy", desc: "Adding noise to data to protect individual privacy while allowing for aggregate analysis" }
                        ],
                        navigation: "Implemented in data preprocessing pipelines using custom code or specialized libraries/tools",
                        options: [
                            "Apply techniques like K-anonymity, L-diversity, T-closeness",
                            "Use services like AWS Glue to implement data transformations for anonymization"
                        ]
                    }
                },
                interdependencies: [
                    "**S3**: Primary storage for sensitive data often processed by AI services.",
                    "**KMS**: For managing encryption keys used to protect data.",
                    "**IAM**: For granular access control to sensitive data.",
                    "**CloudTrail**: For auditing all data access and management API calls.",
                    "**AWS Well-Architected Framework**: Provides guidelines for data protection in the cloud."
                ],
                techStack: ["Encryption (KMS, SSL/TLS)", "VPC PrivateLink", "Data Masking/Anonymization", "AWS Macie", "AWS Config"],
                pricing: "Macie and PrivateLink have specific pricing. Other data protection costs are integrated into the underlying service pricing.",
                scenarios: [
                    "Ensuring patient privacy in a healthcare AI application by identifying and redacting PHI",
                    "Securing communication channels between a web application and an AI inference endpoint using PrivateLink",
                    "Implementing data anonymization for training AI models on sensitive customer data",
                    "Monitoring S3 buckets for accidental exposure of PII due to misconfigurations"
                ],
                troubleshooting: {
                    commonIssues: [
                        {
                            title: "Sensitive Data Exposure",
                            desc: "Unintentional exposure of PII/PHI in S3 buckets or other storage.",
                            solutionSteps: [
                                "Use Amazon Macie to continuously discover and report on sensitive data in your S3 buckets.",
                                "Regularly review S3 bucket policies and ACLs to ensure public access is blocked.",
                                "Implement AWS Config rules to automatically detect and remediate S3 buckets with public access."
                            ]
                        },
                        {
                            title: "Compliance Audit Failures",
                            desc: "Failing to meet regulatory requirements (e.g., GDPR, HIPAA) for data handling in AI workloads.",
                            solutionSteps: [
                                "Leverage AWS Audit Manager to continuously collect evidence for compliance assessments.",
                                "Ensure data encryption (at rest and in transit) is enabled for all sensitive data stores.",
                                "Apply the principle of least privilege using IAM to restrict access to sensitive data."
                            ]
                        }
                    ]
                }
            }
        };

        const serviceFeatureMapping = {};
        for (const serviceKey in awsServices) {
            const service = awsServices[serviceKey];
            for (const featureName of service.features) {
                const featureDetails = service.featureDetails[featureName];
                if (featureDetails) {
                    serviceFeatureMapping[`${serviceKey}-${featureName.replace(/\s+/g, '-').toLowerCase()}`] = featureDetails;
                }
            }
        }

        function toggleBranch(branchId) {
            const subServices = document.getElementById(branchId);
            if (subServices) {
                subServices.classList.toggle('active');
            }
        }

        /**
         * Shows details for a selected item in the modal.
         * @param {string} key - The key for the specific service (e.g., 'sagemaker').
         */
        function showServiceDetails(key) {
            // Hide all conditional content sections first
            document.getElementById('serviceDetailsContent').style.display = 'block'; // Always show for service details
            document.getElementById('llm-service-output').style.display = 'none'; // Hide LLM output area

            const itemData = awsServices[key];
            if (!itemData) return;

            currentServiceName = itemData.name;
            currentServiceDescription = itemData.description;

            document.getElementById('modalTitle').innerText = itemData.name;
            document.getElementById('modalDescription').innerText = itemData.description;

            document.getElementById('modalTechStack').innerText = itemData.techStack.join(', ');

            const interdependenciesList = document.getElementById('modalInterdependencies');
            interdependenciesList.innerHTML = '';
            itemData.interdependencies.forEach(dep => {
                const li = document.createElement('li');
                li.innerHTML = dep;
                interdependenciesList.appendChild(li);
            });

            document.getElementById('modalPricing').innerText = itemData.pricing;
            
            // --- UPDATED LOGIC FOR CONFIG OPTIONS ---
            const configOptionsList = document.getElementById('modalConfigOptions');
            configOptionsList.innerHTML = '';
            const defaultFeatureDetails = itemData.features.length > 0 && itemData.featureDetails[itemData.features[0]] ? itemData.featureDetails[itemData.features[0]] : null;
            
            document.getElementById('modalNavigation').innerText = defaultFeatureDetails?.navigation || 'N/A';

            if (defaultFeatureDetails && defaultFeatureDetails.options) {
                defaultFeatureDetails.options.forEach(option => {
                    const li = document.createElement('li');
                    if (typeof option === 'object' && option.parameter) {
                        // Enhanced parameter display
                        li.innerHTML = `<strong>${option.parameter}:</strong> ${option.purpose}`;
                        if (option.values && option.values.length > 0) {
                            li.innerHTML += `<ul>${option.values.map(val => `<li><em>Value:</em> ${val}</li>`).join('')}</ul>`;
                        }
                    } else {
                        // Basic string option
                        li.innerText = option;
                    }
                    configOptionsList.appendChild(li);
                });
            } else {
                const li = document.createElement('li');
                li.innerText = 'No specific configuration options listed for this service.';
                configOptionsList.appendChild(li);
            }
            // --- END UPDATED LOGIC FOR CONFIG OPTIONS ---


            const scenariosList = document.getElementById('modalScenarios');
            scenariosList.innerHTML = '';
            itemData.scenarios.forEach(scenario => {
                const li = document.createElement('li');
                li.innerText = scenario;
                scenariosList.appendChild(li);
            });

            const featureTagsDiv = document.getElementById('featureTags');
            featureTagsDiv.innerHTML = '';
            itemData.features.forEach(feature => {
                const tag = document.createElement('span');
                tag.className = 'feature-tag';
                tag.innerText = feature;
                tag.onclick = (event) => {
                    event.stopPropagation();
                    toggleFeatureDetails(key, feature.replace(/\s+/g, '-').toLowerCase());
                };
                featureTagsDiv.appendChild(tag);
            });
            document.getElementById('featureDetailsContainer').innerHTML = ''; // Clear previous feature details

            // Populate Troubleshooting section
            const troubleshootingSection = document.getElementById('serviceTroubleshootingSection');
            const troubleshootingDetailsDiv = document.getElementById('serviceTroubleshootingDetails');
            troubleshootingDetailsDiv.innerHTML = ''; // Clear previous troubleshooting content

            if (itemData.troubleshooting && itemData.troubleshooting.commonIssues.length > 0) {
                troubleshootingSection.style.display = 'block';
                itemData.troubleshooting.commonIssues.forEach(issue => {
                    const issueDiv = document.createElement('div');
                    issueDiv.className = 'sub-feature'; // Reuse styling
                    issueDiv.innerHTML = `
                        <div class="sub-feature-title">${issue.title}</div>
                        <div class="sub-feature-desc">${issue.desc}</div>
                        ${issue.solutionSteps && issue.solutionSteps.length > 0 ? `
                            <div class="feature-nav"><strong>Solution Steps:</strong>
                                <ul class="troubleshooting-details">
                                    ${issue.solutionSteps.map(step => `<li>${step}</li>`).join('')}
                                </ul>
                            </div>
                        ` : ''}
                    `;
                    troubleshootingDetailsDiv.appendChild(issueDiv);
                });
            } else {
                troubleshootingSection.style.display = 'none'; // Hide if no troubleshooting data
            }

            document.getElementById('serviceModal').style.display = 'block';
        }


        function toggleFeatureDetails(serviceKey, featureId) {
            const container = document.getElementById('featureDetailsContainer');
            const fullFeatureId = `${serviceKey}-${featureId}`;
            const featureDetails = serviceFeatureMapping[fullFeatureId];

            // If the clicked feature's details are already active, remove them.
            const existingDetails = document.getElementById(`details-${fullFeatureId}`);
            if (existingDetails) {
                existingDetails.remove();
                return;
            }

            // Remove any other active feature details within the same container
            const activeDetails = container.querySelector('.feature-details.active');
            if (activeDetails) {
                activeDetails.remove();
            }

            if (!featureDetails) {
                const noDetailsDiv = document.createElement('div');
                noDetailsDiv.className = 'feature-details active';
                noDetailsDiv.innerText = 'No detailed information available for this feature.';
                container.appendChild(noDetailsDiv);
                return;
            }

            const detailsDiv = document.createElement('div');
            detailsDiv.id = `details-${fullFeatureId}`;
            detailsDiv.className = 'feature-details active';

            // --- UPDATED LOGIC FOR FEATURE-SPECIFIC CONFIG OPTIONS ---
            let optionsHtml = '';
            if (featureDetails.options && featureDetails.options.length > 0) {
                optionsHtml = `
                    <div class="feature-nav"><strong>Key Configuration Options:</strong>
                        <ul class="config-options">
                            ${featureDetails.options.map(option => {
                                if (typeof option === 'object' && option.parameter) {
                                    let valuesList = '';
                                    if (option.values && option.values.length > 0) {
                                        valuesList = `<ul>${option.values.map(val => `<li><em>Value:</em> ${val}</li>`).join('')}</ul>`;
                                    }
                                    return `<li><strong>${option.parameter}:</strong> ${option.purpose}${valuesList}</li>`;
                                } else {
                                    return `<li>${option}</li>`;
                                }
                            }).join('')}
                        </ul>
                    </div>
                `;
            } else {
                optionsHtml = '<div class="feature-nav"><strong>Key Configuration Options:</strong> <ul><li>No specific configuration options listed for this feature.</li></ul></div>';
            }
            // --- END UPDATED LOGIC FOR FEATURE-SPECIFIC CONFIG OPTIONS ---

            detailsDiv.innerHTML = `
                <h4>${featureId.replace(/-/g, ' ').replace(/\b\w/g, c => c.toUpperCase())} Sub-features:</h4>
                <ul>
                    ${featureDetails.subFeatures.map(sf => `
                        <li class="sub-feature">
                            <div class="sub-feature-title">${sf.title}</div>
                            <div class="sub-feature-desc">${sf.desc}</div>
                        </li>
                    `).join('')}
                </ul>
                <div class="feature-nav"><strong>Navigation:</strong> ${featureDetails.navigation}</div>
                ${optionsHtml}
            `;
            container.appendChild(detailsDiv);
        }

        function closeModal() {
            document.getElementById('serviceModal').style.display = 'none';
            // Clear any LLM output area when closing the modal
            document.getElementById('llm-service-output').innerHTML = '';
            document.getElementById('llm-service-output').style.display = 'none';
        }

        // Close modal when clicking outside of it
        window.onclick = function(event) {
            const modal = document.getElementById('serviceModal');
            if (event.target == modal) {
                closeModal(); // Use the existing closeModal function
            }
        }

        // LLM specific functions
        /**
         * Summarizes the given service description using the Gemini API.
         * @param {string} description - The service description to summarize.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function summarizeServiceDescription(description, buttonElement) {
            const prompt = `Summarize the following AWS AI service description concisely in 2-3 sentences:\n\n"${description}"`;
            await callGeminiAPI(prompt, 'llm-service-output', buttonElement);
        }

        /**
         * Generates new use cases for a given AWS AI service using the Gemini API.
         * @param {string} serviceName - The name of the AWS AI service.
         * @param {string} serviceDescription - The description of the AWS AI service.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function generateUseCasesIdea(serviceName, serviceDescription, buttonElement) {
            const prompt = `Given the AWS AI service "${serviceName}" with the description "${serviceDescription}", suggest 3-4 creative and distinct real-world use cases or applications not already mentioned, in bullet point format.`;
            await callGeminiAPI(prompt, 'llm-service-output', buttonElement);
        }

        /**
         * Generates a detailed explanation for a given AI/ML technology using the Gemini API.
         * @param {string} techName - The name of the AI/ML technology.
         * @param {string} techDescription - The brief description of the technology.
         * @param {string} outputElementId - The ID of the HTML element where the response should be displayed.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function generateTechExplanation(techName, techDescription, outputElementId, buttonElement) {
            const prompt = `Provide a detailed explanation of "${techName}" (${techDescription}), including its core concepts, how it works, and its significance in modern AI/ML. Focus on clarity and comprehensive information.`;
            await callGeminiAPI(prompt, outputElementId, buttonElement);
        }

        /**
         * Generic function to call Gemini API and display response.
         * @param {string} prompt - The prompt to send to the Gemini API.
         * @param {string} outputElementId - The ID of the HTML element where the response should be displayed.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function callGeminiAPI(prompt, outputElementId, buttonElement) {
            const outputElement = document.getElementById(outputElementId);
            const originalButtonText = buttonElement.innerText;
            
            outputElement.style.display = 'block';
            outputElement.innerHTML = '<div class="loading-indicator"></div> Generating response...';
            buttonElement.disabled = true;
            buttonElement.innerText = 'Generating...';

            try {
                // In a real application, you'd make an actual API call to your backend
                // which would then interact with the Gemini API.
                // This is a placeholder for demonstration.
                const simulatedResponse = await new Promise(resolve => {
                    setTimeout(() => {
                        let responseText = "";
                        if (prompt.includes("Summarize the following AWS AI service description")) {
                            responseText = "Amazon Bedrock is a fully managed service offering access to various foundation models from leading AI companies. It simplifies generative AI application development by providing powerful text and image generation capabilities, alongside features like fine-tuning and RAG for enhanced relevance.";
                        } else if (prompt.includes("suggest 3-4 creative and distinct real-world use cases")) {
                            responseText = `
                                <ul>
                                    <li>Automated legal document summarization and clause extraction for law firms.</li>
                                    <li>Personalized educational content generation for e-learning platforms.</li>
                                    <li>Real-time foreign language translation for international e-commerce customer support.</li>
                                    <li>Dynamic script generation for video content creators based on trending topics.</li>
                                </ul>
                            `;
                        } else if (prompt.includes("Provide a detailed explanation of \"Agentic AI Models\"")) {
                            responseText = `Agentic AI Models are advanced artificial intelligence systems designed to operate autonomously, capable of perceiving their environment, making decisions, and taking actions to achieve specific goals without constant human intervention. They work by integrating various AI components, such as large language models for reasoning, planning modules for strategizing, and tools/APIs for interacting with external systems. The significance of agentic AI lies in its potential to automate complex, multi-step tasks across diverse domains, from autonomous driving and personalized digital assistants to intelligent business process automation. They move beyond simple task execution, exhibiting emergent behaviors that can adapt to dynamic situations, marking a significant step towards more generalized and capable AI systems.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"Multimodal AI Systems\"")) {
                            responseText = `Multimodal AI Systems are intelligent systems that can process and understand information from multiple modalities simultaneously, such as text, images, audio, and video, leading to more intuitive understanding. Unlike traditional AI models that specialize in one data type, multimodal AI aims to mimic human-like perception and comprehension by integrating insights from diverse inputs. For example, a multimodal system could analyze a video by processing the spoken words (audio), the visual content (image/video), and any on-screen text. This holistic understanding allows for more robust and nuanced interpretations, leading to advancements in areas like virtual assistants that can understand voice commands and gestures, improved content moderation that considers both visual and textual context, and more intuitive human-computer interaction.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"Generative AI Evolution\"")) {
                            responseText = `Generative AI, characterized by models like Large Language Models (LLMs), Text-to-Image, and Text-to-Video models, has seen rapid evolution, enabling the creation of novel and realistic content across various data types. These models learn patterns and structures from vast datasets to generate new data that resembles the training data. The evolution involves improvements in model architecture (e.g., Transformers, diffusion models), scale (trillions of parameters), and fine-tuning techniques, leading to increasingly coherent, creative, and contextually relevant outputs. The significance lies in automating content creation (marketing, art, code), enabling rapid prototyping, and fostering new forms of human-AI collaboration. Ethical considerations, such as bias and misinformation, are also a growing focus in this evolution.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"Privacy-Preserving AI\"")) {
                            responseText = `Privacy-Preserving AI refers to the development and application of artificial intelligence techniques that protect sensitive data and individual privacy throughout the AI lifecycle, from data collection and model training to deployment and inference. Key methods include federated learning, where models are trained locally on decentralized data without sharing the raw data itself; differential privacy, which adds controlled noise to datasets or model outputs to obscure individual data points while retaining statistical properties; and homomorphic encryption, allowing computations on encrypted data. The significance of this field is profound as it addresses critical concerns around data security, regulatory compliance (e.g., GDPR, HIPAA), and public trust, enabling the responsible deployment of AI in sensitive domains like healthcare and finance where data privacy is paramount.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"Quantum Computing & AI\"")) {
                            responseText = `The convergence of Quantum Computing and AI, often termed "Quantum AI," explores how quantum mechanics principles can enhance AI capabilities, particularly for complex computational problems intractable for classical computers. Quantum computers can process information using qubits, which can exist in multiple states simultaneously (superposition) and be entangled, allowing them to perform certain calculations exponentially faster. In AI, this could revolutionize areas like machine learning model training, optimization problems (e.g., for logistics, drug discovery), and cryptography. While still in its early stages, Quantum AI holds the promise of developing more powerful algorithms, enabling the analysis of much larger and complex datasets, and opening up new frontiers in AI research and application, potentially leading to breakthroughs in areas like materials science and financial modeling.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"Edge AI\"")) {
                            responseText = `Edge AI involves deploying artificial intelligence models and performing AI inference directly on edge devices, such as IoT devices, smartphones, cameras, and industrial sensors, rather than relying solely on cloud-based processing. The core concept is to bring AI closer to the data source. This approach significantly reduces latency, as data doesn't need to travel to a centralized cloud for processing. It also enhances privacy and security by minimizing the transfer of sensitive data and can reduce bandwidth consumption. Edge AI is particularly significant for applications requiring real-time decision-making (e.g., autonomous vehicles, industrial automation) and in environments with limited or intermittent network connectivity, enabling more robust, efficient, and private intelligent systems.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"AI in Cybersecurity\"")) {
                            responseText = `AI in Cybersecurity refers to the application of artificial intelligence and machine learning techniques to enhance the detection, prevention, and response to cyber threats. AI models can analyze vast amounts of network traffic, logs, and behavioral data to identify anomalous patterns that may indicate a security breach, far more rapidly and accurately than traditional rule-based systems. This includes detecting malware, phishing attempts, insider threats, and zero-day attacks. Its significance lies in automating threat intelligence, predicting vulnerabilities, and accelerating incident response, thereby strengthening an organization's defense against increasingly sophisticated cyberattacks. AI-driven cybersecurity helps security teams to prioritize threats, reduce false positives, and adapt to evolving threat landscapes with greater agility.`;
                        } else if (prompt.includes("Provide a detailed explanation of \"Personalized Medicine\"")) {
                            responseText = `Personalized medicine, also known as precision medicine, leverages artificial intelligence to tailor medical treatments and healthcare decisions to the individual characteristics of each patient. This approach moves beyond a "one-size-fits-all" model by considering a patient's unique genetic makeup, lifestyle, environment, and clinical data. AI algorithms analyze complex datasets, including genomic sequences, electronic health records, and lifestyle information, to predict disease risks, identify the most effective therapies, and even discover new drugs with higher precision. The significance of personalized medicine lies in its potential to revolutionize healthcare by improving treatment efficacy, minimizing adverse drug reactions, enabling earlier disease detection, and ultimately leading to better patient outcomes and more efficient healthcare systems.`;
                        }
                        resolve(responseText);
                    }, 1000); // Simulate network delay
                });

                outputElement.innerHTML = simulatedResponse;
            } catch (error) {
                console.error("Error calling Gemini API:", error);
                outputElement.innerHTML = '<p>An error occurred while generating the response. Please try again.</p>';
            } finally {
                buttonElement.disabled = false;
                buttonElement.innerText = originalButtonText;
            }
        }

        // Remove onclick from central node as showOverview() is not defined
        document.querySelector('.central-node').onclick = null;
    </script>
</body>
</html>
