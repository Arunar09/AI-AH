<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DevOps Mindmap with AWS Focus</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        /* General Reset */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Inter', sans-serif; /* Using Inter font */
            border-radius: 8px; /* Applying rounded corners to all elements */
        }

        /* Body Styles */
        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 50%, #4a77b8 100%); /* Blueish gradient for DevOps */
            min-height: 100vh;
            padding: 20px;
            color: white;
            display: flex;
            flex-direction: column;
            gap: 30px;
            align-items: center;
        }

        /* Container for overall layout */
        .container {
            max-width: 1400px;
            margin: 0 auto;
            width: 100%;
        }

        /* Main Heading */
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.8rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            color: #FF9900; /* AWS Orange accent */
        }

        /* Mindmap Layout */
        .mindmap {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 30px;
            width: 100%;
        }

        /* Central Node */
        .central-node {
            background: linear-gradient(45deg, #FF9900, #FFA726); /* AWS Orange gradient */
            padding: 20px 40px;
            border-radius: 50px;
            font-size: 1.5rem;
            font-weight: bold;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            cursor: pointer;
            transform: scale(1);
            transition: all 0.3s ease;
        }

        .central-node:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(0,0,0,0.4);
        }

        /* Main Branches Grid Layout */
        .main-branches {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            width: 100%;
        }

        /* Individual Branch Styles */
        .branch {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
            padding: 25px;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .branch:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.15);
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        .branch-header {
            font-size: 1.3rem;
            font-weight: bold;
            margin-bottom: 15px;
            color: #66CCFF; /* Light blue accent for DevOps */
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .branch-icon {
            font-size: 1.5rem;
        }

        /* Sub-services (initially hidden) */
        .sub-services {
            display: none;
            animation: fadeIn 0.3s ease;
        }

        .sub-services.active {
            display: block;
        }

        /* Fade-in animation for sub-services */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Individual Service Item Styles (now category-item) */
        .category-item {
            background: rgba(0,0,0,0.2);
            margin: 10px 0;
            padding: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .category-item:hover {
            background: rgba(0,0,0,0.3);
            transform: translateX(10px);
        }

        .category-name {
            font-weight: bold;
            color: #90EE90; /* Light green accent */
            margin-bottom: 5px;
        }

        .category-desc {
            font-size: 0.9rem;
            color: #e0e0e0;
            margin-bottom: 10px;
        }

        /* Feature Tag Styles within modal */
        .feature-tag {
            display: inline-block;
            background: #FF9900; /* AWS Orange accent */
            color: white;
            padding: 3px 8px;
            margin: 2px;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .feature-tag:hover {
            background: #e68a00;
            transform: scale(1.05);
        }

        /* Feature Details (initially hidden, expands on click) */
        .feature-details {
            display: none;
            margin-top: 15px;
            padding: 15px;
            background: rgba(0,0,0,0.4);
            border-left: 4px solid #FF9900; /* AWS Orange accent */
        }

        .feature-details.active {
            display: block;
            animation: slideDown 0.3s ease;
        }

        /* Slide-down animation for feature details */
        @keyframes slideDown {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Sub-feature styles within details */
        .sub-feature {
            background: rgba(255,255,255,0.1);
            margin: 8px 0;
            padding: 10px;
            border-left: 3px solid #66CCFF; /* Light blue accent */
        }

        .sub-feature-title {
            font-weight: bold;
            color: #66CCFF; /* Light blue accent */
            margin-bottom: 5px;
        }

        .sub-feature-desc {
            font-size: 0.9rem;
            color: #e0e0e0;
            line-height: 1.4;
        }

        /* How-to Steps specific styling */
        .how-to-steps {
            background: rgba(0,0,0,0.2);
            padding: 15px;
            margin-top: 15px;
            border-radius: 8px;
        }
        .how-to-steps ol {
            list-style-type: decimal;
            margin-left: 20px;
        }
        .how-to-steps li {
            margin-bottom: 8px;
            font-size: 0.9rem;
            color: #e0e0e0;
            line-height: 1.5;
        }
        .how-to-steps li strong {
            color: #FFD700; /* Gold accent for emphasis in steps */
        }


        .feature-nav {
            text-align: center; /* Center the navigation links */
            margin: 15px 0 0; /* Add margin to the top, none to bottom */
            font-size: 0.9rem;
            color: #fff; /* White for better contrast */
            display: flex; /* Use flexbox for spacing */
            justify-content: space-between; /* Space out the next/previous buttons */
            align-items: center;
        }
        .feature-nav strong {
            color: #a78bfa; /* Purple accent for strong text */
        }
        .feature-nav button {
            background-color: #66CCFF; /* Light blue accent */
            color: white;
            border: none;
            padding: 5px 10px;
            cursor: pointer;
            border-radius: 4px;
            transition: background-color 0.2s ease;
        }
        .feature-nav button:hover {
            background-color: #33aaff;
        }
        .feature-nav button:disabled {
            background-color: #555;
            cursor: not-allowed;
            opacity: 0.7;
        }

        .use-cases-list { /* Renamed for clarity */
            margin-top: 10px;
            font-size: 0.85rem;
            color: #FFD700; /* Gold accent */
            list-style: disc;
            margin-left: 20px;
        }
        .use-cases-list li {
            margin-bottom: 5px;
        }


        /* Modal Overlay */
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.8);
            animation: fadeIn 0.3s ease;
            overflow-y: auto; /* Allow scrolling for modal content */
        }

        /* Modal Content Box */
        .modal-content {
            background: linear-gradient(135deg, #1f283e 0%, #3a4b6c 100%); /* Consistent with body background */
            margin: 5% auto;
            padding: 30px;
            width: 90%;
            max-width: 800px;
            max-height: 90vh; /* Max height to prevent overflow */
            overflow-y: auto; /* Ensure scrollability within modal */
            box-shadow: 0 20px 60px rgba(0,0,0,0.5);
            border-radius: 12px;
        }

        /* Close Button for Modal */
        .close {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
        }

        .close:hover {
            color: white;
        }

        /* Sections within the modal */
        .tech-stack-list, .interdependencies-list, .config-options { /* Renamed for clarity */
            background: rgba(0,0,0,0.2);
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
        }
        .tech-stack-list ul, .interdependencies-list ul, .config-options ul {
            list-style: disc;
            margin-left: 20px;
            padding-left: 0;
        }

        .pricing-info-box { /* Renamed for clarity */
            background: rgba(52, 152, 219, 0.2);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.9rem;
            border-radius: 8px;
        }

        .scenario-box {
            background: rgba(46, 204, 113, 0.2);
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
        }
        
        .config-options li {
            margin-bottom: 5px;
        }

        .llm-action-button {
            background-color: #FF9900; /* AWS Orange accent */
            color: white;
            border: none;
            padding: 8px 12px;
            cursor: pointer;
            font-size: 0.9rem;
            margin-top: 10px;
            margin-right: 10px;
            transition: background-color 0.3s ease;
            border-radius: 6px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }

        .llm-action-button:hover {
            background-color: #e68a00;
            transform: translateY(-1px);
        }

        .llm-output-area {
            background: rgba(0,0,0,0.3);
            padding: 15px;
            margin-top: 20px;
            border: 1px solid rgba(255,255,255,0.2);
            min-height: 50px;
            font-size: 0.95rem;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
            display: none; /* Hidden by default */
            border-radius: 8px;
        }

        .loading-indicator {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: #FF9900; /* AWS Orange accent */
            animation: spin 1s ease-in-out infinite;
            -webkit-animation: spin 1s ease-in-out infinite;
            margin-left: 10px;
            vertical-align: middle;
        }

        @keyframes spin {
            to { -webkit-transform: rotate(360deg); }
        }
        @-webkit-animation {
            to { -webkit-transform: rotate(360deg); }
        }

        /* News Section */
        .news-section {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
            padding: 25px;
            color: white;
            width: 100%;
            margin-top: 30px;
            border-radius: 12px;
        }

        .news-section h2 {
            font-size: 1.8rem;
            font-weight: bold;
            margin-bottom: 20px;
            color: #66CCFF; /* Light blue accent for DevOps */
            text-align: center;
        }

        .news-item {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }

        .news-item:last-child {
            border-bottom: none;
        }

        .news-item h3 {
            font-size: 1.2rem;
            color: #90EE90; /* Light green accent */
            margin-bottom: 5px;
        }

        .news-item p {
            font-size: 0.9rem;
            color: #e0e0e0;
        }

        .news-item a {
            color: #FFD700; /* Gold accent */
            text-decoration: underline;
            font-size: 0.85rem;
        }

        /* Floating Search Bar Styles - Hexagon Shape */
        .floating-search-container {
            position: fixed;
            bottom: 20px;
            right: 20px; /* Default position */
            z-index: 1001;
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            padding: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.5);
            transition: all 0.3s ease-in-out;
            opacity: 0.8; /* Slightly more opaque */
            width: 80px; /* Larger for hexagon */
            height: 80px; /* Larger for hexagon */
            display: flex;
            justify-content: center;
            align-items: center;
            border: 1px solid rgba(255,255,255,0.2);
            cursor: grab;
            clip-path: polygon(50% 0%, 100% 25%, 100% 75%, 50% 100%, 0% 75%, 0% 25%); /* Hexagon shape */
            -webkit-clip-path: polygon(50% 0%, 100% 25%, 100% 75%, 50% 100%, 0% 75%, 0% 25%);
            border-radius: 0; /* No border-radius for polygon shape */
        }

        .floating-search-container:hover {
            opacity: 1;
        }

        .floating-search-container.expanded {
            width: 350px;
            height: auto;
            opacity: 1;
            flex-direction: column;
            align-items: flex-start;
            padding: 20px;
            cursor: auto;
            border-radius: 8px; /* Square when expanded */
            clip-path: none; /* Remove clip-path when expanded */
            -webkit-clip-path: none;
        }

        .search-toggle-button {
            background-color: #FF9900; /* AWS Orange accent */
            color: white;
            border: none;
            width: 60px; /* Larger button for hexagon */
            height: 60px; /* Larger button for hexagon */
            font-size: 2rem; /* Larger icon */
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            transition: background-color 0.3s ease;
            clip-path: polygon(50% 0%, 100% 25%, 100% 75%, 50% 100%, 0% 75%, 0% 25%); /* Hexagon shape */
            -webkit-clip-path: polygon(50% 0%, 100% 25%, 100% 75%, 50% 100%, 0% 75%, 0% 25%);
            border-radius: 0; /* No border-radius for polygon shape */
        }

        .floating-search-container.expanded .search-toggle-button {
            clip-path: none; /* Remove clip-path when expanded */
            -webkit-clip-path: none;
            border-radius: 50%; /* Make it round again when expanded */
            width: 40px; /* Smaller icon when expanded */
            height: 40px; /* Smaller icon when expanded */
            font-size: 1.5rem; /* Smaller icon when expanded */
            margin-bottom: 10px; /* Space between close and input */
        }


        .search-toggle-button:hover {
            background-color: #e68a00;
        }

        .floating-search-content {
            display: none;
            width: 100%;
        }

        .floating-search-container.expanded .floating-search-content {
            display: block;
        }

        .floating-search-content .search-bar-container {
            display: flex;
            gap: 10px;
            margin-bottom: 10px;
            flex-direction: column;
        }
        
        .floating-search-content .search-bar-container input[type="text"] {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid rgba(255,255,255,0.3);
            background-color: rgba(0,0,0,0.3);
            color: white;
            font-size: 1rem;
            width: 100%;
            border-radius: 6px;
        }

        .floating-search-content .search-bar-container button {
            padding: 10px 20px;
            background-color: #66CCFF; /* Light blue accent */
            color: white;
            border: none;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s ease;
            width: 100%;
            border-radius: 6px;
        }

        .floating-search-content .search-bar-container button:hover {
            background-color: #33aaff;
        }

        /* Close button for expanded search */
        .floating-search-close {
            color: #aaa;
            align-self: flex-end;
            font-size: 24px;
            font-weight: bold;
            cursor: pointer;
            margin-bottom: 10px;
            display: none;
        }

        .floating-search-container.expanded .floating-search-close {
            display: block;
        }

        .floating-search-close:hover {
            color: white;
        }

        /* Responsive Adjustments */
        @media (max-width: 768px) {
            .main-branches {
                grid-template-columns: 1fr;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .modal-content {
                width: 95%;
                margin: 10% auto;
                padding: 20px;
            }
            .floating-search-container.expanded {
                width: 90%;
                right: 5%;
                bottom: 10%;
            }
            .floating-search-content .search-bar-container {
                flex-direction: column;
            }
            .news-section {
                padding: 15px;
            }
            .central-node {
                font-size: 1.2rem;
                padding: 15px 30px;
            }
            .branch-header {
                font-size: 1.1rem;
            }
            .floating-search-container {
                width: 60px;
                height: 60px;
            }
            .search-toggle-button {
                width: 40px;
                height: 40px;
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🚀 DevOps Mindmap with AWS Focus</h1>
        
        <div class="mindmap">
            <div class="central-node">
                Continuous Everything
            </div>
            	 
	<!-- Back to Landing Page Button -->
    <a href="./index.html" class="fixed top-4 left-4 z-50 bg-purple-700 text-white py-2 px-4 rounded-lg shadow-lg hover:bg-purple-800 transition duration-300 ease-in-out text-lg font-bold">
        &larr; Back to Hub
    </a>
	
            <div class="main-branches">
                <!-- Plan & Code -->
                <div class="branch" onclick="toggleBranch('plan-code')">
                    <div class="branch-header">
                        <span class="branch-icon">📋</span>
                        Plan & Code
                    </div>
                    <div id="plan-code" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('version-control')">
                            <div class="category-name">Version Control</div>
                            <div class="category-desc">Manage code changes collaboratively.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('ide')">
                            <div class="category-name">Integrated Development Environments (IDE)</div>
                            <div class="category-desc">Tools for writing and debugging code.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('code-review')">
                            <div class="category-name">Code Review</div>
                            <div class="category-desc">Peer review for code quality and security.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-sdk')">
                            <div class="category-name">AWS SDKs & CLI</div>
                            <div class="category-desc">Interact with AWS services programmatically.</div>
                        </div>
                    </div>
                </div>

                <!-- Build -->
                <div class="branch" onclick="toggleBranch('build')">
                    <div class="branch-header">
                        <span class="branch-icon">🔨</span>
                        Build
                    </div>
                    <div id="build" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('ci')">
                            <div class="category-name">Continuous Integration (CI)</div>
                            <div class="category-desc">Automate code integration and testing.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('artifact-management')">
                            <div class="category-name">Artifact Management</div>
                            <div class="category-desc">Store and manage build artifacts.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('static-analysis')">
                            <div class="category-name">Static Code Analysis</div>
                            <div class="category-desc">Automated analysis for code quality/security.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('containerization')">
                            <div class="category-name">Containerization</div>
                            <div class="category-desc">Package applications and dependencies.</div>
                        </div>
                    </div>
                </div>

                <!-- Test -->
                <div class="branch" onclick="toggleBranch('test')">
                    <div class="branch-header">
                        <span class="branch-icon">🧪</span>
                        Test
                    </div>
                    <div id="test" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('unit-testing')">
                            <div class="category-name">Unit Testing</div>
                            <div class="category-desc">Test individual code components.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('integration-testing')">
                            <div class="category-name">Integration Testing</div>
                            <div class="category-desc">Test interactions between components.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('performance-testing')">
                            <div class="category-name">Performance Testing</div>
                            <div class="category-desc">Evaluate system responsiveness and stability.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('security-testing')">
                            <div class="category-name">Security Testing</div>
                            <div class="category-desc">Identify vulnerabilities in applications.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-device-farm')">
                            <div class="category-name">AWS Device Farm</div>
                            <div class="category-desc">Test mobile/web apps on real devices.</div>
                        </div>
                    </div>
                </div>

                <!-- Release -->
                <div class="branch" onclick="toggleBranch('release')">
                    <div class="branch-header">
                        <span class="branch-icon">📦</span>
                        Release
                    </div>
                    <div id="release" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('cd')">
                            <div class="category-name">Continuous Delivery (CD)</div>
                            <div class="category-desc">Automate release to testing/staging environments.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('release-orchestration')">
                            <div class="category-name">Release Orchestration</div>
                            <div class="category-desc">Coordinate releases across environments.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('change-management')">
                            <div class="category-name">Change Management</div>
                            <div class="category-desc">Control changes to IT infrastructure.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-codepipeline')">
                            <div class="category-name">AWS CodePipeline</div>
                            <div class="category-desc">Automated release pipelines.</div>
                        </div>
                    </div>
                </div>

                <!-- Deploy -->
                <div class="branch" onclick="toggleBranch('deploy')">
                    <div class="branch-header">
                        <span class="branch-icon">🚀</span>
                        Deploy
                    </div>
                    <div id="deploy" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('continuous-deployment')">
                            <div class="category-name">Continuous Deployment</div>
                            <div class="category-desc">Automate deployment to production.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('iac')">
                            <div class="category-name">Infrastructure as Code (IaC)</div>
                            <div class="category-desc">Manage infrastructure using code.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('configuration-management')">
                            <div class="category-name">Configuration Management</div>
                            <div class="category-desc">Automate system configuration.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-cdk')">
                            <div class="category-name">AWS CDK & CloudFormation</div>
                            <div class="category-desc">Define and provision AWS infrastructure as code.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-codedeploy')">
                            <div class="category-name">AWS CodeDeploy</div>
                            <div class="category-desc">Automated code deployments to instances.</div>
                        </div>
                    </div>
                </div>

                <!-- Operate -->
                <div class="branch" onclick="toggleBranch('operate')">
                    <div class="branch-header">
                        <span class="branch-icon">⚙️</span>
                        Operate
                    </div>
                    <div id="operate" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('monitoring-logging')">
                            <div class="category-name">Monitoring & Logging</div>
                            <div class="category-desc">Collect and analyze system data.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('incident-management')">
                            <div class="category-name">Incident Management</div>
                            <div class="category-desc">Respond to operational issues.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('on-call')">
                            <div class="category-name">On-Call & Alerting</div>
                            <div class="category-desc">Notify personnel of critical events.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-cloudwatch')">
                            <div class="category-name">AWS CloudWatch</div>
                            <div class="category-desc">Monitor resources and applications.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-systems-manager')">
                            <div class="category-name">AWS Systems Manager</div>
                            <div class="category-desc">Automate operational tasks.</div>
                        </div>
                    </div>
                </div>

                <!-- Monitor -->
                <div class="branch" onclick="toggleBranch('monitor')">
                    <div class="branch-header">
                        <span class="branch-icon">📊</span>
                        Monitor
                    </div>
                    <div id="monitor" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('performance-monitoring')">
                            <div class="category-name">Performance Monitoring</div>
                            <div class="category-desc">Track system performance metrics.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('application-monitoring')">
                            <div class="category-name">Application Monitoring</div>
                            <div class="category-desc">Monitor application health and performance.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('log-analysis')">
                            <div class="category-name">Log Analysis</div>
                            <div class="category-desc">Analyze logs for insights and issues.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-xray')">
                            <div class="category-name">AWS X-Ray</div>
                            <div class="category-desc">Trace requests through distributed apps.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-cloudtrail')">
                            <div class="category-name">AWS CloudTrail</div>
                            <div class="category-desc">Log AWS API calls and activity.</div>
                        </div>
                    </div>
                </div>

                <!-- Security & Governance -->
                <div class="branch" onclick="toggleBranch('security-governance')">
                    <div class="branch-header">
                        <span class="branch-icon">🔒</span>
                        Security & Governance
                    </div>
                    <div id="security-governance" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('iam')">
                            <div class="category-name">Identity and Access Management (IAM)</div>
                            <div class="category-desc">Manage access to resources.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('compliance')">
                            <div class="category-name">Compliance & Auditing</div>
                            <div class="category-desc">Ensure adherence to regulations and standards.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('security-automation')">
                            <div class="category-name">Security Automation</div>
                            <div class="category-desc">Automate security tasks and responses.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-security-hub')">
                            <div class="category-name">AWS Security Hub</div>
                            <div class="category-desc">Centralized security posture management.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('aws-config')">
                            <div class="category-name">AWS Config</div>
                            <div class="category-desc">Assess, audit, and evaluate configurations.</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- News Letter Section -->
            <div class="news-section">
                <h2>Recent DevOps & AWS News</h2>
                <ul id="news-list" style="list-style: none; padding: 0;">
                    <!-- News items will be loaded here by JavaScript -->
                    <li><div class="loading-indicator"></div> Loading latest DevOps & AWS news...</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Category Details Modal -->
    <div id="categoryModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal()">&times;</span>
            <div id="modalContent"></div>
        </div>
    </div>

    <!-- Floating AI Search Bar -->
    <div id="floatingAISearch" class="floating-search-container">
        <button class="search-toggle-button" onclick="toggleFloatingSearch()">
            <span id="searchIcon">✨</span>
        </button>
        <div class="floating-search-content">
            <span class="floating-search-close" onclick="toggleFloatingSearch()">&times;</span>
            <div class="search-bar-container">
                <input type="text" id="ai-search-input" placeholder="Ask Gemini AI about DevOps/AWS...">
                <button id="ai-search-button" onclick="performAISearch()">Search with AI 🔍</button>
            </div>
            <div id="ai-search-output" class="llm-output-area">
                <!-- Search results will appear here -->
            </div>
        </div>
    </div>

    <script>
        // Data structure containing details for each DevOps category and AWS service
        const devOpsData = {
            'version-control': {
                name: "Version Control",
                purpose: "To manage and track changes to source code, configurations, and other digital assets collaboratively. It maintains a complete history of all changes, enables rollback to previous versions, and is fundamental for CI/CD.",
                features: [
                    {
                        title: "Git (Distributed)",
                        desc: "A distributed version control system (DVCS) that allows developers to have a complete copy of the repository locally, enabling offline work and fast operations. Popular for its powerful branching and merging capabilities, allowing isolated development streams. **AWS Relevance:** AWS CodeCommit is a fully managed, secure, and highly scalable Git repository service that seamlessly integrates with other AWS services like CodePipeline and CodeBuild.",
                        howToSteps: [
                            "**1. Create an AWS CodeCommit Repository:** Go to the AWS CodeCommit console, click 'Create repository', give it a name, and create.",
                            "**2. Configure Git Credentials:** Set up Git credentials for HTTPS (Git credentials for AWS CodeCommit) or SSH keys via IAM. For HTTPS, use the AWS CLI to configure a credential helper: `aws configure set credential_helper '!aws codecommit credential-helper $@'` and `aws configure set default.region YOUR_REGION`.",
                            "**3. Clone the Repository:** In your terminal, use `git clone <HTTPS or SSH URL from CodeCommit console>` to clone the empty repository to your local machine.",
                            "**4. Add and Commit Files:** Create your project files, then `git add .` to stage them, and `git commit -m \"Initial commit\"` to commit.",
                            "**5. Push to CodeCommit:** Use `git push origin main` (or your chosen branch name) to push your local commits to CodeCommit."
                        ]
                    },
                    { title: "Branching & Merging", desc: "The ability to create isolated lines of development (branches) to work on new features, bug fixes, or experiments without affecting the main codebase. Changes are later combined back (merged) into the main or release branches after review and testing." },
                    { title: "Commit History & Auditability", desc: "Maintains a complete, immutable historical record of every change made to the codebase, including who made the change, when, and a descriptive message. This is crucial for auditing, debugging, compliance, and understanding the evolution of the software." },
                    { title: "Conflict Resolution", desc: "Provides tools and mechanisms to detect and manage conflicts that arise when multiple developers make changes to the same parts of a file or code block simultaneously. Effective conflict resolution is key to collaborative development." },
                    { title: "Tagging & Releases", desc: "Ability to mark specific points in history with a human-readable tag (e.g., 'v1.0.0'). This is essential for marking release versions, specific build points, or important milestones, simplifying deployment and rollback." }
                ],
                examples: [
                    "A team collaborating on a microservice stores its code in AWS CodeCommit. Each developer creates a feature branch for new functionality, pushes changes, and then submits a pull request for code review before merging to the main branch.",
                    "An engineer needs to fix a critical bug in production. They quickly create a hotfix branch from the latest production tag, implement the fix, and merge it back, ensuring minimal disruption.",
                    "CloudFormation templates and Terraform configurations are version-controlled in Git, allowing infrastructure changes to be tracked, reviewed, and deployed with the same rigor as application code.",
                    "Using Git tags to denote successful production deployments, allowing for quick identification of the codebase version running in different environments."
                ],
                technicalDetails: "Git relies on a directed acyclic graph (DAG) data structure to store commits and their relationships efficiently. Core concepts include repositories (local and remote), commits, branches, and the staging area. AWS CodeCommit provides standard Git functionality with AWS IAM integration for access control, encryption at rest and in transit, and scalability.",
                tools: "Git, GitHub, GitLab, Bitbucket, AWS CodeCommit, Azure Repos."
            },
            'ide': {
                name: "Integrated Development Environments (IDE)",
                purpose: "To provide a comprehensive software application that offers facilities to computer programmers for software development. An IDE normally consists of a source code editor, build automation tools, and a debugger, streamlining the entire development process.",
                features: [
                    { title: "Code Editor", desc: "A sophisticated text editor specifically designed for writing source code, offering features like syntax highlighting for various languages, intelligent code completion (IntelliSense), code snippets, and automatic formatting to improve developer productivity and code consistency." },
                    { title: "Debugger", desc: "A powerful tool that allows developers to inspect the execution of their code, set breakpoints at specific lines, step through code line by line, examine variable values, and modify program state during runtime to efficiently identify and fix bugs." },
                    { title: "Build Automation & Integration", desc: "Integrates directly with build systems (e.g., Maven, Gradle, npm, CMake) for compiling source code, resolving dependencies, running tests, and packaging applications, often with a single click or command within the IDE." },
                    { title: "Version Control Integration", desc: "Direct and seamless integration with popular version control systems like Git, allowing developers to perform common VCS operations (commit, push, pull, branch, merge) directly from the IDE's interface, reducing context switching." },
                    { title: "AWS Toolkit & Extensions", desc: "Many popular IDEs offer official AWS Toolkits or third-party extensions that provide direct integration with AWS services, enabling developers to browse AWS resources, deploy serverless functions, manage containers, and view logs directly from their development environment." }
                ],
                examples: [
                    "Developers using VS Code with the AWS Toolkit extension to write Python Lambda functions, debug them locally using SAM CLI integration, and deploy updates directly to AWS Lambda.",
                    "An engineer leveraging IntelliJ IDEA's deep integration with Maven and Git for developing a Java microservice, using its built-in debugger to resolve complex issues.",
                    "Utilizing AWS Cloud9, a cloud-based IDE, for collaborative development of a Node.js application, with pre-configured AWS SDKs and direct access to EC2 instances."
                ],
                technicalDetails: "IDEs streamline the development workflow by providing a unified environment for coding, testing, and debugging. They leverage language servers for intelligent features and often interact with external tools via command-line interfaces or APIs. AWS Cloud9 is a browser-based IDE that automatically configures an AWS development environment and shares it securely for pair programming.",
                tools: "Visual Studio Code (VS Code), IntelliJ IDEA, Eclipse, AWS Cloud9 (cloud-based IDE), PyCharm, WebStorm."
            },
            'code-review': {
                name: "Code Review",
                purpose: "To systematically examine source code, typically by peers or automated tools, to find mistakes, improve code quality, ensure adherence to coding standards, and enhance security by identifying vulnerabilities early in the development lifecycle.",
                features: [
                    { title: "Peer Review Workflows", desc: "Developers review each other's code changes, often through pull requests (Git) or merge requests (GitLab). Reviewers provide feedback, suggest improvements, and catch potential bugs or logic errors before code is integrated." },
                    { title: "Automated Static Analysis Checks", desc: "Integration with SAST (Static Application Security Testing) tools and linters that automatically scan code for common quality issues, coding style violations, potential bugs, and security anti-patterns (e.g., SQL injection, XSS). These checks can be automated within the CI pipeline." },
                    { title: "Comment & Feedback Systems", desc: "Platforms provide mechanisms for reviewers to leave inline comments directly on specific lines of code, suggest changes, and engage in discussions, facilitating clear and contextual communication." },
                    { title: "Approval & Merge Workflows", desc: "Configurable workflows that require a certain number of approvals or successful automated checks before code can be merged into the main development branch, acting as a quality gate." },
                    { title: "Audit Trail of Reviews", desc: "Maintains a record of who reviewed which changes, when, and what feedback was given. This provides accountability and is important for compliance and post-mortem analysis." }
                ],
                examples: [
                    "A developer submits a pull request for a new feature in an AWS CodeCommit repository. Team members review the code, suggest improvements, and an automated CodeGuru Reviewer analysis flags a potential performance issue.",
                    "Integrating SonarQube with a Jenkins CI pipeline to automatically highlight code smells, bugs, and security vulnerabilities directly within the pull request, guiding reviewers' attention.",
                    "Reviewing infrastructure-as-code (CloudFormation, Terraform) changes in GitLab merge requests to ensure new resource deployments adhere to organizational security and naming conventions."
                ],
                technicalDetails: "Code review practices often leverage features inherent in modern version control platforms. Static analysis tools analyze code structure and patterns. AWS CodeGuru Reviewer uses machine learning to provide intelligent recommendations for code improvement, integrating directly with CodeCommit and GitHub.",
                tools: "GitHub Pull Requests, GitLab Merge Requests, Bitbucket Pull Requests, AWS CodeCommit (with pull requests), SonarQube, AWS CodeGuru Reviewer, Crucible, Gerrit."
            },
            'aws-sdk': {
                name: "AWS SDKs & CLI",
                purpose: "To provide a set of tools that allow developers and administrators to interact with AWS services programmatically using their preferred programming languages (Software Development Kits - SDKs) or through a unified command-line interface (CLI). This enables automation, scripting, application integration, and infrastructure management.",
                features: [
                    { title: "Language-Specific SDKs", desc: "AWS offers SDKs for popular programming languages such as Python (Boto3), Java, JavaScript (for Node.js and browser), .NET, Go, Ruby, PHP, and C++. These SDKs provide libraries, objects, and high-level APIs to easily call AWS services without needing to understand underlying RESTful API details." },
                    { title: "AWS Command Line Interface (CLI)", desc: "A unified command-line tool that allows users to manage AWS services directly from their terminal. It provides direct access to AWS APIs and is ideal for scripting, automating administrative tasks, and quick interactions with AWS resources." },
                    { title: "Simplified API Calls & Abstraction", desc: "SDKs abstract away the complexities of making direct HTTP requests to AWS APIs, handling low-level details such as authentication (signing requests), retrying failed requests, connection management, and data serialization/deserialization (marshalling)." },
                    { title: "Flexible Credential Management", desc: "Securely manage AWS credentials for authentication, supporting various methods including temporary credentials from IAM roles (recommended for EC2 instances and Lambda functions), environment variables, shared credential files, and AWS Single Sign-On (SSO)." },
                    { title: "Paginators & Waiters", desc: "Many SDKs include high-level abstractions like paginators (to retrieve large lists of resources automatically) and waiters (to pause execution until an AWS resource reaches a desired state), simplifying common automation patterns." }
                ],
                examples: [
                    "A Python script (using Boto3) that automatically stops all EC2 instances tagged 'dev-environment' at the end of the day and starts them in the morning to optimize cloud costs.",
                    "Using the AWS CLI to deploy a new Lambda function from a local ZIP file: `aws lambda update-function-code --function-name MyLambdaFunction --zip-file fileb://function.zip`.",
                    "A Go application that uploads files to Amazon S3, leverages the AWS SDK for Go to handle secure multipart uploads and object metadata.",
                    "An internal web dashboard that displays metrics from AWS CloudWatch, using the JavaScript SDK to fetch data directly from the browser."
                ],
                technicalDetails: "AWS SDKs and CLI communicate with AWS services over HTTPS using RESTful APIs. All requests are signed using AWS Signature Version 4 for authentication and integrity. Understanding how to securely manage credentials (e.g., using IAM roles for EC2 instances, environment variables in CI/CD) is critical for automation. The CLI is built on the Python SDK (Boto3).",
                tools: "AWS SDK for Python (Boto3), AWS SDK for Java, AWS SDK for JavaScript, AWS CLI (v2), AWS Tools for PowerShell."
            },
            'ci': {
                name: "Continuous Integration (CI)",
                purpose: "To frequently merge code changes from multiple developers into a central shared repository, followed by automated builds and comprehensive automated tests. The primary goal is to detect integration errors early and rapidly, ensuring a consistently working and stable codebase.",
                features: [
                    {
                        title: "Automated Builds",
                        desc: "Automatically compiles source code from the version control system, resolves all necessary dependencies (e.g., libraries, packages), and creates executable artifacts (e.g., JAR, WAR, Docker image, Lambda deployment package) whenever new code is committed or a pull request is opened.",
                        howToSteps: [
                            "**1. Define `buildspec.yml`:** Create a `buildspec.yml` file in your source repository. This YAML file specifies the commands and build phases for AWS CodeBuild (e.g., `install`, `pre_build`, `build`, `post_build`).",
                            "**2. Create a CodeBuild Project:** In the AWS CodeBuild console, create a new build project. Link it to your source repository (CodeCommit, S3, GitHub, Bitbucket).",
                            "**3. Configure Build Environment:** Select your build environment (managed image or custom Docker image), runtime, and compute type.",
                            "**4. Define Output Artifacts:** Specify where CodeBuild should store the output artifacts (e.g., an S3 bucket or push a Docker image to ECR).",
                            "**5. Trigger the Build:** Manually start a build from the console, or integrate it with AWS CodePipeline or a webhook from your source repository to trigger automatically on code commits."
                        ]
                    },
                    { title: "Automated Testing Suite", desc: "Runs a suite of automated tests on every build to quickly catch regressions, functional bugs, or security vulnerabilities introduced by new changes. This typically includes unit tests, integration tests, and often static code analysis." },
                    { title: "Version Control System (VCS) Integration", desc: "Tightly integrated with source control systems (like Git). New code commits or pull/merge requests automatically trigger the CI pipeline, ensuring that every change goes through the build and test process." },
                    { title: "Fast Feedback Loop", desc: "Provides rapid and immediate feedback to developers on the health of their code changes. If a build fails or tests break, developers are notified quickly, allowing them to fix issues while the context is fresh, making fixes cheaper and faster." },
                    { title: "Artifact Generation & Storage", desc: "Upon successful completion of builds and tests, the CI pipeline generates deployable artifacts and stores them in a centralized artifact repository, making them available for subsequent deployment stages." }
                ],
                examples: [
                    "A developer pushes code to an AWS CodeCommit repository, which triggers an AWS CodeBuild project. CodeBuild compiles the application, runs all unit and integration tests, and if successful, packages the application into a Docker image and pushes it to Amazon ECR.",
                    "Using Jenkins, a pull request to a GitHub repository automatically initiates a build job that checks code style with ESLint, runs Jest unit tests for a React application, and then reports results back to GitHub.",
                    "A GitLab CI/CD pipeline is configured to run end-to-end API tests using Cypress after a new microservice is built and deployed to a temporary testing environment."
                ],
                technicalDetails: "CI pipelines are typically defined as code (e.g., YAML files, Groovy scripts) within the version control system itself, promoting 'pipeline-as-code'. They leverage build tools (Maven, Gradle, npm, Go modules) and test frameworks (JUnit, Pytest, Jest). AWS CodeBuild is a fully managed CI service that scales automatically and integrates natively with other AWS developer tools.",
                tools: "Jenkins, GitLab CI/CD, GitHub Actions, CircleCI, Travis CI, Bamboo, AWS CodeBuild, Azure Pipelines."
            },
            'artifact-management': {
                name: "Artifact Management",
                purpose: "To store, version, and manage binary artifacts (e.g., compiled code, Docker images, libraries, packages, installers) generated during the build process. It ensures their integrity, traceability, and availability for deployment, and provides a single source of truth for software components.",
                features: [
                    { title: "Centralized Repository", desc: "Provides a single, secure, and highly available repository for all build artifacts across different projects and teams. This prevents 'dependency hell' and ensures consistency across development, testing, and production environments." },
                    { title: "Versioning & Immutability", desc: "Each artifact is assigned a unique, immutable version (e.g., build number, semantic version), allowing for precise control over which specific version is deployed. Once an artifact is stored, it cannot be changed, ensuring reproducibility and integrity." },
                    { title: "Access Control & Permissions", desc: "Manages fine-grained permissions to ensure only authorized users, roles, or CI/CD pipelines can upload, download, or delete artifacts, enforcing security policies." },
                    { title: "Support for Multiple Formats", desc: "Supports a wide variety of package and artifact formats (e.g., Maven, npm, Docker images, NuGet, PyPI, raw binaries), acting as a universal repository." },
                    { title: "Lifecycle Management & Retention", desc: "Allows defining policies for how long artifacts are retained, archiving older versions, and managing storage space. This helps with compliance and cost optimization." }
                ],
                examples: [
                    "After a successful build in AWS CodeBuild, the resulting Docker image is pushed to Amazon ECR (Elastic Container Registry), making it available for deployment to Amazon ECS or EKS.",
                    "An organization uses AWS CodeArtifact to host private npm packages for internal microservices, ensuring developers can securely consume these dependencies without relying on public registries.",
                    "Storing application installers and configuration bundles in an Amazon S3 bucket, with versioning enabled, to manage and distribute different releases.",
                    "Using Artifactory to host Java Maven artifacts and Docker images, providing a universal repository for all development assets."
                ],
                technicalDetails: "Artifact repositories often implement replication for high availability and disaster recovery. They integrate tightly with CI/CD tools to automate the publishing and consumption of artifacts. AWS services like ECR and CodeArtifact are fully managed, reducing operational overhead.",
                tools: "Artifactory, Nexus Repository Manager, GitLab Container Registry, GitHub Packages, Amazon ECR (Elastic Container Registry), AWS CodeArtifact, Amazon S3 (for general artifact storage)."
            },
            'static-analysis': {
                name: "Static Code Analysis",
                purpose: "To analyze source code, bytecode, or binary code for quality issues, coding standard violations, and security vulnerabilities *without* executing the program. It's a 'white-box' testing method that helps identify problems early in the software development lifecycle.",
                features: [
                    { title: "Code Quality & Maintainability Checks", desc: "Identifies bad coding practices (code smells), potential bugs (e.g., null pointer dereferences, resource leaks), unused code, and overly complex code structures that might hinder future maintainability and understanding." },
                    { title: "Security Vulnerability Detection (SAST)", desc: "Scans for common security flaws and anti-patterns such as SQL Injection, Cross-Site Scripting (XSS), insecure direct object references, hardcoded credentials, buffer overflows, and improper error handling. It's crucial for implementing 'shift-left' security." },
                    { title: "Coding Standard & Style Enforcement", desc: "Ensures that code adheres to predefined organizational or community coding style guides and best practices (e.g., PEP 8 for Python, ESLint rules for JavaScript, Checkstyle for Java), promoting consistency across the codebase." },
                    { title: "Early Feedback in Development", desc: "Integrates directly into Integrated Development Environments (IDEs) or Continuous Integration (CI) pipelines to provide immediate feedback to developers as they write or commit code. Catching issues early makes them significantly cheaper and faster to fix." },
                    { title: "Language & Framework Support", desc: "Most enterprise-grade SAST tools support a wide array of programming languages (Java, .NET, C++, Python, JavaScript, Go) and common frameworks, making them versatile for diverse development environments." }
                ],
                examples: [
                    "Integrating SonarQube into a Jenkins CI/CD pipeline to automatically scan new code commits and report on code quality metrics (e.g., cyclomatic complexity, duplication) and security vulnerabilities before merging to the main branch.",
                    "Using ESLint with a VS Code extension in a frontend JavaScript project to enforce consistent coding style and identify potential syntax errors or anti-patterns in real-time as the developer types.",
                    "AWS CodeGuru Reviewer automatically analyzing Java and Python application code in an AWS CodeCommit repository, flagging potential performance issues, security vulnerabilities, and adherence to best practices in pull requests.",
                    "A build pipeline failing automatically if a critical security vulnerability (e.g., a known injection flaw) is detected by a SAST tool, preventing insecure code from being deployed."
                ],
                technicalDetails: "Static analysis tools typically perform various analyses: lexical analysis (tokenizing code), parsing (building abstract syntax trees), control flow analysis (mapping execution paths), and data flow analysis (tracking data origins and transformations). They can employ different techniques like pattern matching, taint analysis (tracking untrusted input to sensitive sinks), and semantic analysis. A common challenge is managing false positives, which requires careful tool configuration and human review. AWS CodeGuru Reviewer uses machine learning and automated reasoning to identify common issues.",
                tools: "SonarQube (open source with security plugins), Checkmarx CxSAST, Fortify Static Code Analyzer (SCA), Veracode Static Analysis, GitLab SAST, Snyk Code, ESLint, Pylint, AWS CodeGuru Reviewer."
            },
            'containerization': {
                name: "Containerization",
                purpose: "To package applications and their dependencies into portable, lightweight, and self-sufficient units called containers. This ensures that software runs consistently across different computing environments (development, testing, production) by isolating the application from its environment.",
                features: [
                    { title: "Application Isolation", desc: "Containers provide strong isolation at the process and resource level. Applications running in one container do not interfere with applications in another, even when running on the same host, preventing dependency conflicts and ensuring predictable behavior." },
                    { title: "Portability & Consistency", desc: "A container image includes everything an application needs to run (code, runtime, system tools, libraries, settings, dependencies). This 'build once, run anywhere' capability ensures that software behaves identically from a developer's laptop to a production server in the cloud." },
                    { title: "Resource Efficiency", desc: "Containers share the host operating system's kernel, making them significantly more lightweight and efficient than traditional virtual machines. This allows for higher density, meaning more containers can run on a single host, leading to better resource utilization and reduced costs." },
                    { title: "Rapid Startup & Scalability", desc: "Containers start up much faster than virtual machines, enabling quicker deployments and more efficient scaling of applications in response to demand fluctuations. This is crucial for microservices architectures and serverless patterns." },
                    { title: "Simplified Deployment & Management", desc: "Standardized container images simplify the deployment process across different environments. Orchestration platforms (like Kubernetes) further automate the deployment, scaling, and management of containerized applications at scale." }
                ],
                examples: [
                    "Packaging a Node.js microservice into a Docker container image during a CodeBuild pipeline. This image is then pushed to Amazon ECR (Elastic Container Registry) and subsequently deployed to an Amazon ECS (Elastic Container Service) cluster for production hosting.",
                    "Using Docker Compose to define and run a multi-container local development environment for a web application, including the application service, a database, and a caching layer, all running in isolated containers.",
                    "An organization migrating legacy applications to the cloud by containerizing them and deploying them onto Amazon EKS (Elastic Kubernetes Service) clusters, leveraging Kubernetes' orchestration capabilities.",
                    "Creating a CI/CD pipeline that automatically builds a new Docker image whenever a code change is committed, runs automated tests against it, and then rolls out the new version using an Amazon ECS blue/green deployment strategy."
                ],
                technicalDetails: "Containerization is primarily enabled by technologies like Docker, which leverages Linux kernel features such as cgroups (for resource limiting) and namespaces (for isolation). Container images are built from Dockerfiles, which contain instructions for assembling the image layers. Container orchestration platforms (Kubernetes, Amazon ECS) manage the lifecycle, scaling, networking, and scheduling of containers. AWS Fargate is a serverless compute engine for containers, removing the need to manage EC2 instances.",
                tools: "Docker, Podman, containerd, Amazon ECS (Elastic Container Service), Amazon EKS (Elastic Kubernetes Service), AWS Fargate, Kubernetes, OpenShift."
            },
            'unit-testing': {
                name: "Unit Testing",
                purpose: "To test individual units or the smallest components of a software application (e.g., functions, methods, classes) in isolation to ensure they function correctly and meet their design specifications. It's the lowest level of testing, primarily performed by developers.",
                features: [
                    { title: "Isolation of Components", desc: "Tests are designed to run independently of external dependencies such as databases, external APIs, file systems, or other complex modules. This is achieved using 'test doubles' (mocks, stubs, fakes) to simulate the behavior of these dependencies, ensuring only the 'unit under test' is being evaluated." },
                    { title: "Automated & Fast Execution", desc: "Unit tests are typically automated and execute very quickly, often in milliseconds. This allows developers to run them frequently (e.g., after every code change or before every commit) for immediate feedback, accelerating the development cycle." },
                    { title: "Early Bug Detection", desc: "Catches bugs and regressions at the earliest possible stage of the software development lifecycle. Identifying issues during unit testing is significantly cheaper and easier to fix compared to finding them later in integration, system, or production environments." },
                    { title: "Code Quality & Refactoring Confidence", desc: "Well-written unit tests serve as executable documentation for the code's intended behavior. They provide developers with confidence when refactoring code, making changes, or adding new features, as they can immediately verify that existing functionality has not been broken." },
                    { title: "High Test Coverage", desc: "Aim for high unit test coverage to ensure that most of the codebase's logic is exercised by tests. While high coverage doesn't guarantee correctness, it reduces the likelihood of undetected bugs in individual units." }
                ],
                examples: [
                    "Writing a Python unit test (using `pytest`) for a `calculate_discount` function in an e-commerce application, asserting that `calculate_discount(100, 0.1)` correctly returns `10`, without needing a live database or external pricing API.",
                    "Using JUnit (for Java) to test a `UserService` class responsible for user registration, mocking the `UserRepository` to simulate database interactions without actually hitting a database.",
                    "Integrating unit test execution as a crucial stage within an AWS CodeBuild project. If any unit tests fail during a code commit, the build fails, preventing the faulty code from proceeding further in the CI/CD pipeline.",
                    "Developers utilizing Jest (for JavaScript) to run unit tests on their React components locally, receiving instant feedback on changes before pushing code to a shared repository."
                ],
                technicalDetails: "Unit tests are typically written using specific testing frameworks native to each programming language (e.g., JUnit for Java, Pytest for Python, Jest for JavaScript/Node.js, NUnit for .NET, PHPUnit for PHP). Test runners execute these tests and report success/failure. Concepts like 'test-driven development' (TDD) advocate writing tests before writing the production code. Mocking libraries (e.g., Mockito, unittest.mock, Sinon.js) are frequently used to manage dependencies.",
                tools: "JUnit (Java), Pytest (Python), Jest (JavaScript), NUnit (.NET), PHPUnit (PHP), Google Test (C++), AWS CodeBuild (for running tests in CI), AWS CodeCommit (for storing test code alongside application code)."
            },
            'integration-testing': {
                name: "Integration Testing",
                purpose: "To test the interactions and interfaces between different components or services of an application to ensure they work together correctly as a cohesive unit. It verifies that individual units, when combined, behave as expected, often involving real dependencies like databases or APIs.",
                features: [
                    { title: "Component Interaction Verification", desc: "Focuses on testing the flow of data and control between integrated modules, ensuring correct communication, data exchange, and adherence to contracts (APIs, data formats) at their boundaries." },
                    { title: "Real Dependency Handling (or realistic mocks)", desc: "Unlike unit tests, integration tests often involve actual dependencies like a test database, a messaging queue, or a mocked external API endpoint that behaves realistically. This ensures that the system behaves correctly when its components interact in a real-world scenario." },
                    { title: "API Testing", desc: "Verifies that the APIs (REST, SOAP, GraphQL) between services correctly handle requests and responses, including data formats, authentication mechanisms, authorization, and error handling. This is critical for microservices architectures." },
                    { title: "Automated Execution in Test Environments", desc: "Typically automated and integrated into CI/CD pipelines, often running in a dedicated, isolated test or staging environment that closely mimics production conditions. This ensures that the integration points are tested before deployment to production." },
                    { title: "End-to-End Workflow Validation (Limited Scope)", desc: "While not full end-to-end user journeys, integration tests often validate critical workflows that span multiple components or services, ensuring that data flows correctly and processes complete as expected." }
                ],
                examples: [
                    "Testing a web application's user registration flow: an integration test verifies that the frontend correctly sends user data to the backend API, the backend processes it, and the data is correctly stored in a test database.",
                    "Running integration tests in an AWS CodePipeline stage that deploys a new microservice to a temporary staging environment (e.g., on Amazon ECS) and then makes API calls to verify its interaction with other dependent services (e.g., a DynamoDB table, an SQS queue).",
                    "Using Postman or an automated API testing framework to send requests to an API Gateway endpoint and verify that the associated Lambda function processes the request correctly and returns the expected response.",
                    "A test suite that verifies the interaction between an application and an Amazon SQS queue, ensuring messages are sent, received, and processed as designed."
                ],
                technicalDetails: "Integration tests often require spinning up temporary test environments or using Docker containers to host necessary dependencies (e.g., `testcontainers`). Tools like Selenium or Cypress are used for UI-driven integration tests, while frameworks like Pytest with fixtures or specialized API testing tools are used for backend integrations. AWS services like CodeBuild can execute these tests, and AWS Step Functions can orchestrate complex test workflows involving multiple services.",
                tools: "Selenium, Cypress, Postman, SoapUI, Karate DSL, Pytest (with fixtures), TestContainers, AWS CodeBuild (for executing tests), AWS Step Functions (for orchestrating multi-service tests), LocalStack (for local AWS service emulation)."
            },
            'performance-testing': {
                name: "Performance Testing",
                purpose: "To evaluate the responsiveness, stability, scalability, and resource utilization of a system or application under various load conditions. It identifies performance bottlenecks, ensures the system can handle expected (and peak) user traffic, and helps plan for future capacity needs.",
                features: [
                    { title: "Load Testing", desc: "Simulates a typical or expected number of users or requests to verify the system's behavior and performance under normal operating conditions. It helps confirm that the application can handle its anticipated workload efficiently." },
                    { title: "Stress Testing", desc: "Pushes the system beyond its normal operational limits (e.g., by simulating extremely high loads or resource exhaustion) to determine its breaking point, identify failure modes, and understand how it recovers from extreme pressure." },
                    { title: "Scalability Testing", desc: "Evaluates how the system performs as it scales up or down (e.g., adding more EC2 instances, increasing database read replicas, or provisioning more Lambda concurrency) to handle increasing user loads or data volumes effectively without degradation." },
                    { title: "Concurrency Testing", desc: "Tests how the system handles multiple users or processes accessing the same functions or data simultaneously. It aims to identify issues like deadlocks, race conditions, or data corruption under concurrent access." },
                    { title: "Endurance (Soak) Testing", desc: "Tests the system's ability to sustain a continuous, prolonged load over an extended period (e.g., 24-72 hours) to detect issues like memory leaks, resource exhaustion, or graceful degradation that might only manifest over time." }
                ],
                examples: [
                    "Running a load test against an e-commerce website using Apache JMeter, simulating 10,000 concurrent users browsing products and adding items to their cart, while measuring response times, throughput, and error rates.",
                    "Utilizing AWS Elastic Load Balancing and Auto Scaling Groups in conjunction with a load testing tool to determine how an application automatically scales its EC2 instances horizontally in response to increasing traffic and measure its performance characteristics at scale.",
                    "Performing a stress test on an AWS API Gateway endpoint to determine its maximum requests per second (RPS) and latency before the service starts returning errors, identifying the bottleneck.",
                    "Using k6 or Artillery.io to run performance tests against a serverless application (Lambda, DynamoDB) to ensure it can handle peak traffic without significant cold starts or throttling."
                ],
                technicalDetails: "Performance testing tools generate synthetic load from distributed agents or cloud-based services. Key metrics collected include response time, throughput (requests/second), error rate, resource utilization (CPU, memory, network I/O), and database query performance. AWS provides services like Load Balancers, Auto Scaling, and CloudWatch that are essential for testing and monitoring scalable applications. AWS Lambda's provisioned concurrency and DynamoDB's on-demand capacity are specific AWS features relevant to performance.",
                tools: "Apache JMeter, LoadRunner, k6, Gatling, BlazeMeter, Artillery.io, Locust, AWS Elastic Load Balancing, AWS Auto Scaling, AWS CloudWatch (for monitoring during tests), AWS Lambda (for serverless load generation)."
            },
            'security-testing': {
                name: "Security Testing",
                purpose: "To identify vulnerabilities and weaknesses in applications and infrastructure that attackers could exploit. It aims to ensure that systems protect sensitive data, maintain confidentiality, integrity, and availability, and comply with security policies and regulatory requirements.",
                features: [
                    { title: "Vulnerability Scanning", desc: "Automated tools scan applications, networks, servers, and cloud environments for known security flaws (CVEs), common misconfigurations, outdated software versions, and insecure open ports. This provides a broad, automated assessment of potential weaknesses." },
                    { title: "Penetration Testing (Pen Test)", desc: "Manual, ethical hacking exercises conducted by security experts (internal or third-party) to simulate real-world attacks. Pen tests actively try to exploit identified vulnerabilities and weaknesses in defenses, demonstrating the actual impact of a compromise and often uncovering complex, chained vulnerabilities that automated scans might miss." },
                    { title: "Static Application Security Testing (SAST)", desc: "Analyzes source code, bytecode, or binary code for security vulnerabilities *without* executing the program. It identifies flaws like SQL Injection, Cross-Site Scripting (XSS), insecure direct object references, and hardcoded credentials directly at the code level, early in the SDLC." },
                    { title: "Dynamic Application Security Testing (DAST)", desc: "Tests *running* applications by simulating attacks from the outside (black-box testing), observing their runtime behavior and responses to malicious inputs. It's effective for finding vulnerabilities that manifest at runtime, such as broken authentication, session management flaws, or certain configuration issues." },
                    { title: "Interactive Application Security Testing (IAST)", desc: "Combines aspects of SAST and DAST. It operates within the running application (like DAST) but has internal visibility into code execution and data flow (like SAST), leading to highly accurate vulnerability detection with fewer false positives." },
                    { title: "AWS Native Security Services Integration", desc: "Leveraging AWS native security services like AWS WAF (Web Application Firewall), Amazon Inspector (for vulnerability management), AWS GuardDuty (for threat detection), and AWS Macie (for data discovery and protection) for continuous security monitoring, threat detection, and compliance." }
                ],
                examples: [
                    "Running an Amazon Inspector scan on newly deployed EC2 instances in a production environment to automatically identify common vulnerabilities and exposures (CVEs) and security best practice violations.",
                    "Integrating AWS WAF with an Application Load Balancer to protect a public-facing web application from common web exploits like SQL injection, cross-site scripting, and HTTP floods.",
                    "Conducting a manual penetration test on a new API Gateway endpoint to uncover business logic flaws or authorization bypass vulnerabilities that automated tools might miss.",
                    "Using AWS GuardDuty to continuously monitor for malicious activity and unauthorized behavior within an AWS account, such as unusual API calls or port scans.",
                    "Implementing SAST scans in AWS CodeBuild for every code commit, and DAST scans using OWASP ZAP in a staging environment during the CodePipeline's test stage."
                ],
                technicalDetails: "Security testing employs various tools and methodologies that can be integrated throughout the DevOps pipeline (DevSecOps). It's an iterative process that combines automated checks with manual expertise. AWS offers a comprehensive suite of security services that can be used to build a robust security posture, from network protection to identity management and threat detection. Compliance frameworks often dictate specific types of security testing.",
                tools: "OWASP ZAP, Burp Suite, Tenable Nessus, Qualys, SonarQube, Veracode, Contrast Security, AWS Inspector, AWS WAF, AWS GuardDuty, AWS Macie, Amazon Detective."
            },
            'aws-device-farm': {
                name: "AWS Device Farm",
                purpose: "To test mobile (Android, iOS) and web applications on a large fleet of real physical devices and browsers hosted in the AWS cloud. It provides automated testing capabilities, detailed results, and video recordings of test runs, accelerating mobile and web quality assurance.",
                features: [
                    { title: "Real Device & Browser Testing", desc: "Executes tests on actual Android and iOS smartphones, tablets, and a wide range of desktop web browsers (Chrome, Firefox, Safari, Edge). This provides more accurate results than emulators or simulators, covering real-world device fragmentation and environmental factors." },
                    { title: "Automated Test Execution", desc: "Supports popular automated testing frameworks for mobile and web, including Appium, Calabash, Espresso, XCUITest, Robot Framework, and standard browser automation frameworks. It also offers built-in fuzz testing to uncover crashes and issues by sending random inputs." },
                    { title: "Detailed Reports & Visual Feedback", desc: "Provides comprehensive reports for each test run, including logs (system, application, crash logs), screenshots at each step, performance data (CPU, memory, threads), and often video recordings of the test execution. This rich feedback helps developers quickly diagnose and fix issues." },
                    { title: "Concurrent Testing", desc: "Allows running tests on multiple devices and browsers in parallel (concurrency), significantly accelerating testing cycles and reducing the overall time required for release readiness." },
                    { title: "CI/CD Integration", desc: "Seamlessly integrates with CI/CD pipelines, including AWS CodePipeline and third-party CI systems, enabling automated testing of new mobile or web app builds as part of the continuous integration and delivery process." }
                ],
                examples: [
                    "A mobile development team using Device Farm to run automated UI tests (e.g., using Appium) on hundreds of different Android and iOS device models before releasing a new app version, ensuring a consistent user experience across diverse hardware.",
                    "Integrating Device Farm into an AWS CodePipeline: whenever a new mobile app build is committed, CodePipeline triggers a Device Farm test run, and the pipeline only proceeds to deployment if all tests pass.",
                    "A QA team using Device Farm's browser testing capabilities to verify the responsiveness and functionality of a newly developed web application across various desktop and mobile browsers (Chrome, Safari, Firefox, Edge) simultaneously.",
                    "Performing performance testing on a mobile game across a range of older and newer physical devices in Device Farm to identify frame rate drops, memory usage spikes, and other bottlenecks under load."
                ],
                technicalDetails: "AWS Device Farm manages a large pool of physical devices and browser instances. Users upload their application packages and test scripts. Device Farm executes the tests, collects data, and provides results through its console or APIs. It handles device provisioning, test environment setup, and cleaning up after tests. It's particularly valuable for addressing the challenges of mobile device fragmentation and cross-browser compatibility.",
                tools: "AWS Device Farm, Appium, Espresso, XCUITest, Robot Framework, Selenium WebDriver, Calabash."
            },
            'cd': {
                name: "Continuous Delivery (CD)",
                purpose: "To ensure that software can be released to production reliably and efficiently at any time. It extends Continuous Integration by ensuring that the software is always in a deployable state, often automatically deploying validated changes to a staging or pre-production environment.",
                features: [
                    { title: "Automated Deployments to Non-Production Environments", desc: "Automates the deployment of tested and validated artifacts (built during CI) to staging, UAT (User Acceptance Testing), QA, or other non-production environments. This ensures consistent deployment processes and faster feedback for testing teams." },
                    { title: "Release Readiness & Deployable State", desc: "Emphasizes that the software system is always in a state where it could be released to production. This means all necessary automated tests have passed, configurations are managed, and all dependencies are ready. The decision to go to production is a business decision, not a technical one." },
                    { title: "Manual Approval Gates", desc: "Often includes explicit manual approval steps, typically before deployment to a production environment. This allows business stakeholders, compliance teams, or senior engineers to review and approve the release based on business requirements, risk assessment, or regulatory needs." },
                    { title: "Full Pipeline Automation (excluding final prod push)", desc: "The entire software release pipeline, from code commit through automated builds, testing, and deployment to non-production environments, is fully automated. This minimizes manual intervention and potential human error." },
                    { title: "Consistent Deployment Process", desc: "The same automated process used to deploy to staging is used for production, reducing 'it worked in staging' issues. This ensures that the deployment mechanism itself is well-tested and reliable." }
                ],
                examples: [
                    "After a successful CI build in AWS CodeBuild, an AWS CodePipeline automatically triggers a deployment to a staging environment (e.g., an EC2 Auto Scaling Group or an ECS cluster). QA testers then perform UAT, and if all checks pass, a manual approval is requested before proceeding to production.",
                    "A Continuous Delivery pipeline configured in Jenkins automatically updates a development environment with the latest container image after every successful CI run and subsequent unit/integration tests.",
                    "Using Spinnaker to orchestrate complex deployments across multiple cloud environments, where new application versions are automatically delivered to a pre-production environment for extensive testing, and then promoted to production via a one-click manual approval."
                ],
                technicalDetails: "Continuous Delivery builds upon CI, it requires robust automated testing (unit, integration, end-to-end), comprehensive configuration management, and reliable deployment mechanisms. It focuses on maintaining a 'release-ready' state rather than forcing continuous production deployments. AWS CodePipeline is a fully managed continuous delivery service that allows you to model, visualize, and automate the steps required to release your software.",
                tools: "Jenkins, GitLab CI/CD, GitHub Actions, CircleCI, Travis CI, Spinnaker, Azure DevOps, AWS CodePipeline."
            },
            'release-orchestration': {
                name: "Release Orchestration",
                purpose: "To manage, coordinate, and automate complex software releases across multiple environments, teams, and technologies. It provides a centralized view of the release pipeline, ensuring consistency, reducing errors, accelerating delivery cycles, and improving collaboration.",
                features: [
                    { title: "Centralized Release Visibility & Control", desc: "Provides a single, unified dashboard or platform to visualize and track the status of all ongoing releases across different environments (dev, test, staging, production), application components, and teams. This offers a 'single source of truth' for release progress." },
                    { title: "Automated Workflow Management", desc: "Defines and executes automated workflows for complex release processes, encompassing various stages such as build, testing, approvals, deployments, and notifications. It automates handoffs between different tools and teams." },
                    { title: "Dependency Management & Sequencing", desc: "Understands and manages intricate dependencies between different application components, microservices, and infrastructure changes within a release. It ensures that components are deployed and configured in the correct order, preventing integration issues." },
                    { title: "Integrated Approvals & Gates", desc: "Integrates manual and automated approval gates at various stages of the release pipeline. This ensures that necessary quality checks, security scans, and business approvals are obtained before proceeding to the next stage, especially for production deployments." },
                    { title: "Rollback & Remediation Capabilities", desc: "Provides robust capabilities for automated or semi-automated rollback of releases in case of issues detected post-deployment. It also offers tools and processes for quick remediation and incident response." },
                    { title: "Auditing & Compliance Tracking", desc: "Maintains a complete audit trail of all release activities, approvals, and changes, which is crucial for compliance reporting and post-release analysis." }
                ],
                examples: [
                    "Using Spinnaker to orchestrate the deployment of a new microservices architecture across multiple Kubernetes clusters in different AWS regions, managing canary deployments, traffic shifting, and automatic rollbacks based on monitoring data.",
                    "An organization employing a release orchestration tool to manage the rollout of a large enterprise application update, coordinating deployments across development, testing, staging, and production environments, including database schema changes and configuration updates.",
                    "AWS CodePipeline orchestrating the entire release process for a complex application, from source code in CodeCommit, through multiple CodeBuild projects for different microservices, deploying via CodeDeploy to EC2/ECS, and integrating with manual approvals before production rollout.",
                    "Automating the creation of release notes and documentation updates based on successful deployments managed by the orchestration platform."
                ],
                technicalDetails: "Release orchestration platforms integrate with a wide array of existing CI/CD tools, artifact repositories, deployment tools, and ITSM systems via APIs. They often use declarative definitions for pipelines and support various deployment strategies (e.g., blue/green, canary, rolling updates). The goal is to provide enterprise-grade control and visibility over the entire software delivery lifecycle. AWS CodePipeline is a key AWS service for building and orchestrating release pipelines.",
                tools: "Spinnaker, XL Release (now Digital.ai Release), Harness, GitLab Release Orchestration, Azure DevOps Release Pipelines, AWS CodePipeline (for pipeline orchestration), Octopus Deploy."
            },
            'change-management': {
                name: "Change Management",
                purpose: "To control and standardize the processes for introducing, reviewing, approving, and implementing changes to IT services and infrastructure, minimizing risks, ensuring service stability, and maintaining compliance.",
                features: [
                    { title: "Formal Change Request (CR) Process", desc: "Establishes a structured process for submitting all proposed changes, including detailed descriptions, justification, scope, impact assessment (on services, users, and security), and required approvals from relevant stakeholders." },
                    { title: "Risk Assessment & Mitigation Planning", desc: "Evaluating the potential risks associated with a proposed change (e.g., service disruption, security vulnerabilities, compliance breaches). This includes developing mitigation plans and rollback strategies in case of unforeseen issues." },
                    { title: "Change Advisory Board (CAB) Review", desc: "For significant or high-risk changes, a Change Advisory Board (CAB) reviews and approves changes, ensuring all perspectives (IT operations, security, business, compliance) are considered before implementation." },
                    { title: "Change Schedule & Conflict Avoidance", desc: "Maintaining a centralized calendar or schedule of all planned changes across the IT landscape. This helps in coordinating changes, avoiding conflicts, managing capacity, and minimizing the risk of concurrent changes causing issues." },
                    { title: "Post-Implementation Review (PIR)", desc: "After a change is implemented, a review is conducted to verify that the change was successful, achieved its objectives, and had no unintended side effects. Lessons learned are documented to improve future change processes." },
                    { title: "Automated Change Tracking & Traceability", desc: "Integrating change management with CI/CD pipelines to automatically create change records (e.g., tickets in an ITSM system) when deployments occur. This ensures traceability from code commit to production change and aids in auditing." }
                ],
                examples: [
                    "Submitting a change request in ServiceNow to approve a critical security patch deployment to a production EC2 Auto Scaling Group. The CR includes the proposed date, expected downtime, a detailed rollback plan, and requires approval from the security team and application owner.",
                    "Automating the creation of Jira tickets for every successful deployment via an AWS CodePipeline, linking the specific CodePipeline execution ID to the Jira change record for full traceability and auditability.",
                    "Reviewing and approving a significant architectural change to a VPC network configuration in AWS (e.g., adding new subnets, modifying routing tables) through a formal change advisory board (CAB) process before applying it via CloudFormation.",
                    "Utilizing AWS Systems Manager Change Manager to manage operational changes across multiple AWS accounts, ensuring consistency and audit trails for infrastructure modifications."
                ],
                technicalDetails: "Change management often aligns with ITIL (Information Technology Infrastructure Library) principles and is typically supported by IT Service Management (ITSM) platforms. Integration with DevOps tools (CI/CD pipelines, IaC tools) is crucial to bridge the gap between rapid deployment and structured control. Configuration Management Databases (CMDBs) often serve as a source of truth for assets affected by changes. AWS Systems Manager Change Manager helps automate and audit operational changes.",
                tools: "ServiceNow, Jira Service Management, Freshservice, BMC Helix ITSM, AWS Systems Manager Change Manager, Configuration Management Database (CMDB)."
            },
            'aws-codepipeline': {
                name: "AWS CodePipeline",
                purpose: "A fully managed continuous delivery service that automates release pipelines for fast and reliable application and infrastructure updates. It orchestrates all stages of a software release process, from source code changes through build, test, and deployment.",
                features: [
                    { title: "End-to-End Release Automation", desc: "Allows you to define and automate the entire software release process as a series of stages (e.g., Source, Build, Test, Deploy). CodePipeline manages the flow of changes, ensuring each stage completes successfully before moving to the next." },
                    { title: "Seamless AWS Service Integration", desc: "Natively integrates with other AWS developer tools like AWS CodeCommit (source), AWS CodeBuild (build & test), AWS CodeDeploy (deployment to EC2/on-premises/ECS/Lambda), Amazon S3, and AWS Lambda. It also supports various third-party tools." },
                    { title: "Customizable Stages & Actions", desc: "Provides flexibility to define custom stages and actions within the pipeline, allowing users to incorporate any custom scripts, manual steps, or external tools needed to match specific workflow requirements." },
                    { title: "Manual Approval Gates", desc: "Supports incorporating manual approval actions at any stage of the pipeline. This enables human oversight and intervention before critical deployments (e.g., to production) or for compliance reasons." },
                    { title: "Automated Rollbacks & Notifications", desc: "Can be configured to automatically roll back to a previous successful deployment in case of failures. It also integrates with Amazon SNS to send notifications about pipeline status changes (success, failure, manual approval required)." },
                    { title: "Pipeline as Code", desc: "Pipeline definitions can be managed as code (JSON/YAML), version-controlled, and deployed via AWS CloudFormation, promoting consistency and reproducibility of release processes." }
                ],
                examples: [
                    "A CodePipeline triggered by a code commit to an AWS CodeCommit repository. It then uses AWS CodeBuild to compile the application and run unit tests, pushes the resulting Docker image to Amazon ECR, and finally deploys the new containerized application to an Amazon ECS cluster via AWS CodeDeploy.",
                    "Setting up a pipeline that automates the deployment of a serverless application defined by an AWS Serverless Application Model (SAM) template, including stages for static analysis, unit tests, integration tests, and production rollout with a manual approval step.",
                    "Building a continuous delivery pipeline for an Infrastructure as Code (IaC) project where a CodePipeline validates and linting CloudFormation templates in a CodeBuild stage, then deploys them to development and staging environments, with a manual approval for production deployments."
                ],
                technicalDetails: "AWS CodePipeline orchestrates a series of 'stages' (e.g., Source, Build, Test, Deploy), each containing one or more 'actions'. Actions are integrations with specific tools or services (AWS or third-party). It uses artifacts (input and output) to pass data between stages. CodePipeline polls source repositories for changes or can be triggered by webhooks. It relies heavily on AWS IAM for permissions.",
                tools: "AWS CodePipeline, AWS CodeCommit, AWS CodeBuild, AWS CodeDeploy, Amazon S3, AWS Lambda, Amazon ECR, Amazon ECS, AWS CloudFormation, GitHub, Bitbucket, Jenkins (integrations)."
            },
            'continuous-deployment': {
                name: "Continuous Deployment",
                purpose: "To automatically deploy every code change that passes all stages of the CI/CD pipeline directly to production, without any manual intervention. It's an extension of Continuous Delivery, aiming for the fastest possible feedback loop from code commit to customer value.",
                features: [
                    { title: "Automated Production Release", desc: "The defining characteristic: every code change that successfully passes all automated tests (unit, integration, performance, security) and quality gates within the pipeline is automatically released to the production environment without human approval." },
                    { title: "High Trust in Automation & Quality", desc: "Requires an extremely high level of confidence in the entire automated pipeline, including robust testing, comprehensive monitoring, and reliable automated rollback capabilities. It implies a strong culture of quality and automation." },
                    { title: "Rapid Feedback & Iteration", desc: "Enables immediate feedback on the impact of changes in a live production environment. Issues are detected quickly via robust monitoring, allowing for very fast iteration and remediation." },
                    { title: "Advanced Deployment Strategies", desc: "Often combined with sophisticated deployment strategies to minimize risk and downtime, such as canary deployments (gradually rolling out to a subset of users), blue/green deployments (deploying to a separate identical environment), and automated rollbacks triggered by monitoring alerts." },
                    { title: "Reduced Release Overhead", desc: "Eliminates the overhead associated with manual release processes, scheduling, and coordination, allowing teams to deliver value to users much more frequently." }
                ],
                examples: [
                    "A SaaS company deploying hundreds of times a day. Every successful code commit to the main branch triggers a CI/CD pipeline that automatically builds, tests, and deploys the new version to production using a canary deployment strategy. If monitoring detects any issues, an automated rollback is initiated.",
                    "Implementing a blue/green deployment for a critical web application using AWS CodeDeploy. A new version is deployed to an identical 'green' environment, traffic is shifted from 'blue' to 'green' after automated health checks pass, and the 'blue' environment is terminated if no issues arise.",
                    "A serverless application (AWS Lambda, API Gateway, DynamoDB) configured for continuous deployment. After passing all integration and performance tests, the AWS CodePipeline automatically updates the Lambda function code and API Gateway configuration in production, with CloudWatch alarms triggering an immediate rollback if error rates spike."
                ],
                technicalDetails: "Continuous Deployment relies heavily on a mature Continuous Delivery pipeline. It demands ultra-reliable automated testing (unit, integration, performance, security, acceptance), comprehensive real-time monitoring and alerting, and sophisticated deployment strategies. Feature flags are often used to decouple code deployment from feature release, allowing new functionality to be deployed to production but hidden until explicitly enabled. AWS CodeDeploy supports various deployment strategies, and CloudWatch can trigger automated rollbacks.",
                tools: "AWS CodeDeploy, AWS Elastic Beanstalk, Kubernetes (with native deployment strategies like Deployments, Rollouts, Helm), Spinnaker, AWS CodePipeline (orchestrating CD), Feature Flagging tools (e.g., LaunchDarkly)."
            },
            'iac': {
                name: "Infrastructure as Code (IaC)",
                purpose: "To manage and provision computing infrastructure (e.g., networks, virtual machines, containers, load balancers, databases, security groups) using machine-readable definition files, rather than manual configuration or interactive tools. It applies software engineering practices (version control, testing, automation) to infrastructure management.",
                features: [
                    {
                        title: "Automation & Repeatability",
                        desc: "Automates the provisioning and management of infrastructure, significantly reducing manual effort, eliminating human error, and ensuring that environments can be spun up or torn down quickly and repeatedly.",
                        howToSteps: [
                            "**1. Define Infrastructure in a Template:** Write your infrastructure as code using a CloudFormation template (YAML or JSON). For example, define an S3 bucket or an EC2 instance.",
                            "**2. Validate the Template:** Use the AWS CLI to validate your template syntax: `aws cloudformation validate-template --template-body file://my-template.yaml`.",
                            "**3. Deploy the Stack:** Use the AWS CLI to create or update a CloudFormation stack: `aws cloudformation deploy --template-file my-template.yaml --stack-name MyWebServerStack --capabilities CAPABILITY_IAM` (include capabilities if your template creates IAM roles).",
                            "**4. Monitor Stack Creation/Update:** Monitor the status of your stack in the CloudFormation console or using `aws cloudformation describe-stacks --stack-name MyWebServerStack`.",
                            "**5. Update or Delete:** To update, modify your template and redeploy. To delete, use `aws cloudformation delete-stack --stack-name MyWebServerStack`."
                        ]
                    },
                    { title: "Version Control & Collaboration", desc: "Infrastructure definitions are stored as code in version control systems (e.g., Git). This enables tracking of all infrastructure changes, collaboration among teams, code reviews, and the ability to easily revert to previous infrastructure states (rollback)." },
                    { title: "Idempotence", desc: "Applying the same IaC configuration multiple times produces the exact same desired state, without creating duplicate resources or unintended side effects. This ensures consistency and makes changes predictable and safe." },
                    { title: "Reproducibility & Consistency Across Environments", desc: "Allows environments (development, staging, production) to be rapidly and consistently spun up or replicated, ensuring that applications behave identically across different stages of the development lifecycle." },
                    { title: "Declarative vs. Imperative Approaches", desc: "IaC tools can be declarative (describing the *desired end state* of the infrastructure, and the tool figures out how to get there, e.g., CloudFormation, Terraform) or imperative (describing the *steps* to achieve the state, e.g., Ansible, Chef, Puppet)." },
                    { title: "State Management", desc: "Some IaC tools (like Terraform) manage a 'state file' that maps your desired configuration to the actual deployed resources, enabling them to understand existing infrastructure and intelligently apply changes." }
                ],
                examples: [
                    "Defining an entire AWS Virtual Private Cloud (VPC) with subnets, route tables, security groups, EC2 instances, RDS databases, and S3 buckets using a single AWS CloudFormation template (YAML or JSON).",
                    "Using HashiCorp Terraform to provision and manage infrastructure components across multiple cloud providers (AWS, Azure, GCP) from a single, unified codebase, enabling multi-cloud deployments.",
                    "An engineer uses AWS CDK (Cloud Development Kit) with Python to define a serverless application consisting of AWS Lambda functions, API Gateway endpoints, and DynamoDB tables, which is then synthesized into CloudFormation for deployment.",
                    "Managing Kubernetes cluster deployments (e.g., Amazon EKS clusters) and their configurations using IaC tools like Terraform or Pulumi."
                ],
                technicalDetails: "IaC tools parse definition files (JSON, YAML, HCL for Terraform, TypeScript/Python/etc. for CDK) and interact with cloud provider APIs to provision, update, and manage resources. Key principles include treating infrastructure like application code, promoting immutability of infrastructure where possible (e.g., replace, don't modify), and integrating IaC into CI/CD pipelines.",
                tools: "AWS CloudFormation, AWS CDK, HashiCorp Terraform, Pulumi, Ansible, Chef, Puppet, Crossplane."
            },
            'configuration-management': {
                name: "Configuration Management",
                purpose: "To maintain the consistent state of software and hardware systems across an IT environment. It automates the configuration, installation, updating, and ongoing enforcement of desired configurations for operating systems, applications, and services on servers and endpoints.",
                features: [
                    { title: "Automated Provisioning & Deployment", desc: "Automates the setup of new servers, installation of operating systems, and deployment of applications and their dependencies onto those servers. This ensures consistent starting points for all instances." },
                    { title: "Desired State Configuration (DSC) & Enforcement", desc: "Allows defining a 'desired state' for systems (e.g., specific software versions, security patches, file permissions). The configuration management system continuously monitors and automatically corrects any 'configuration drift' from this desired state, ensuring consistency." },
                    { title: "Idempotency", desc: "Running a configuration management script or policy multiple times yields the same result (the desired state) without causing unintended side effects or errors. This makes operations predictable and safe." },
                    { title: "Infrastructure Consistency & Standardization", desc: "Ensures that all servers and environments (development, test, production) have identical configurations, reducing 'it works on my machine but not in production' issues and standardizing environments across the organization." },
                    { title: "Patch Management Integration", desc: "Often integrates with patch management processes to automate the application of security patches and updates to operating systems and applications across a fleet of instances, ensuring systems are up-to-date and secure." },
                    { title: "Secret Management Integration", desc: "Integrates with secret management solutions (e.g., AWS Secrets Manager, HashiCorp Vault) to securely retrieve sensitive configuration data (database passwords, API keys) during configuration application, preventing hardcoded secrets." }
                ],
                examples: [
                    "Using Ansible to automate the installation and configuration of Nginx, deploy a new version of a web application, and set up SSL certificates on a fleet of Ubuntu EC2 instances.",
                    "Managing the security baselines, software installations, and patch levels of Windows and Linux servers using AWS Systems Manager State Manager and Patch Manager, ensuring consistent compliance across the fleet.",
                    "Automating the deployment of monitoring agents (e.g., CloudWatch Agent, Datadog Agent) and security tools (e.g., EDR agents) to newly provisioned virtual machines as part of their initial setup.",
                    "Using Chef or Puppet to ensure that all development workstations have a consistent set of tools and libraries installed, streamlining onboarding for new developers."
                ],
                technicalDetails: "Configuration management tools typically use an agent-based (Chef, Puppet, SaltStack) or agentless (Ansible via SSH) architecture. They use declarative (Ansible, Puppet, Chef) or imperative (Bash scripts) approaches. They often integrate with Infrastructure as Code (IaC) tools to provision the base infrastructure before applying configurations. AWS Systems Manager provides comprehensive capabilities for managing configuration, patching, and automating operational tasks across EC2 and on-premises instances.",
                tools: "Ansible, Chef, Puppet, SaltStack, AWS Systems Manager (State Manager, Run Command, Patch Manager), PowerShell DSC, Terraform (for provisioning, sometimes combined with CM for config)."
            },
            'aws-cdk': {
                name: "AWS CDK & CloudFormation",
                purpose: "AWS Cloud Development Kit (CDK) is an open-source software development framework for defining cloud infrastructure in familiar programming languages (e.g., TypeScript, Python, Java). It then synthesizes these definitions into AWS CloudFormation templates for deployment. AWS CloudFormation allows users to model, provision, and manage AWS and third-party resources using declarative templates (JSON or YAML).",
                features: [
                    { title: "CloudFormation (Declarative IaC)", desc: "Allows you to define AWS resources and their dependencies using declarative JSON or YAML templates. CloudFormation manages the creation, update, and deletion of these resources in an orderly, repeatable, and predictable way. It's the foundational Infrastructure as Code service for AWS." },
                    { title: "AWS CDK (Imperative IaC via Code)", desc: "Enables you to define your cloud infrastructure using general-purpose programming languages like TypeScript, Python, Java, .NET, or Go. CDK then generates (synthesizes) standard CloudFormation templates. This allows for more expressive logic, reusability of components (Constructs), and leveraging familiar programming language features for infrastructure definition." },
                    { title: "Infrastructure Versioning & Change Tracking", desc: "Both CloudFormation templates and CDK code are stored in version control systems (e.g., Git). This enables tracking of all infrastructure changes, facilitates code reviews, and allows for easy rollback to previous infrastructure states." },
                    { title: "Automated Deployment & Rollback", desc: "CloudFormation provides robust capabilities for automated deployment of infrastructure stacks. In case of deployment failures, CloudFormation automatically rolls back the stack to its previous stable state, ensuring infrastructure stability and preventing partial deployments." },
                    { title: "Cross-Account & Cross-Region Deployment", desc: "CloudFormation StackSets allow you to deploy a single CloudFormation template across multiple AWS accounts and regions from a single operation, ensuring consistent infrastructure baselines across your organization." },
                    { title: "Reusable Constructs (CDK)", desc: "CDK's core abstraction, 'Constructs,' are reusable cloud components that encapsulate AWS resources and their configurations. This promotes modularity, reduces boilerplate code, and allows teams to build higher-level abstractions for common patterns." }
                ],
                examples: [
                    "Defining a complete serverless application (including AWS Lambda functions, API Gateway endpoints, and DynamoDB tables) using AWS CDK in Python. The CDK code is then 'synthesized' to generate a CloudFormation template, which is deployed to an AWS account.",
                    "Creating a CloudFormation stack to provision a multi-Availability Zone VPC with public and private subnets, NAT Gateways, Internet Gateways, and security groups to support a highly available web application.",
                    "Using CloudFormation StackSets to deploy consistent IAM roles, S3 buckets, and CloudWatch alarms across all development, staging, and production AWS accounts in an enterprise, ensuring standardized security and monitoring.",
                    "An engineer defining a custom CDK Construct for a 'secure web application front-end' that automatically provisions an S3 bucket for static assets, a CloudFront distribution, and AWS WAF rules, making it easy for other teams to deploy secure frontends."
                ],
                technicalDetails: "AWS CDK acts as a higher-level abstraction layer over CloudFormation. CDK applications are written in supported programming languages, and when compiled (`cdk synth`), they produce CloudFormation JSON/YAML templates. CloudFormation then interacts with AWS APIs to provision and manage resources. CloudFormation manages the state of the deployed resources in 'stacks' and 'stack sets'. CDK's 'constructs' promote reusability and best practices, making complex infrastructure easier to define and manage.",
                tools: "AWS CloudFormation, AWS CDK, AWS CLI (for CDK commands), YAML/JSON editors, Git."
            },
            'aws-codedeploy': {
                name: "AWS CodeDeploy",
                purpose: "A fully managed deployment service that automates software deployments to a variety of compute services such as Amazon EC2, AWS Lambda, Amazon ECS, and on-premises servers. It supports various deployment strategies to minimize downtime and provide quick rollbacks.",
                features: [
                    { title: "Automated Application Deployments", desc: "Automates the entire process of deploying application revisions, handling the complexities of stopping/starting servers, copying files, updating configurations, and running scripts during the deployment lifecycle. This reduces manual effort and potential human errors." },
                    { title: "Flexible Deployment Strategies", desc: "Supports various deployment strategies to minimize downtime and risk: **In-Place Deployment** (updates instances directly in place), **Blue/Green Deployment** (deploys to a new set of instances, then shifts traffic, enabling zero-downtime updates and easy rollbacks), and **Canary Deployments** (gradually shifts traffic to the new version)." },
                    { title: "Automated Rollbacks", desc: "Can be configured to automatically roll back a deployment to a previous successful version if a deployment fails or if alarms from AWS CloudWatch trigger, ensuring rapid recovery from issues." },
                    { title: "Deployment Hooks & Lifecycle Events", desc: "Allows running custom scripts (defined in an `appspec.yml` file) at various stages of the deployment lifecycle (e.g., `BeforeInstall`, `AfterInstall`, `ApplicationStop`, `ApplicationStart`, `ValidateService`). This provides fine-grained control over the deployment process." },
                    { title: "Integration with AWS & Third-Party Tools", desc: "Seamlessly integrates with AWS services like AWS CodePipeline (for continuous delivery), Amazon EC2 Auto Scaling, Elastic Load Balancing, AWS Lambda, and Amazon ECS. It also supports deployments to on-premises servers." },
                    { title: "Centralized Management & Monitoring", desc: "Provides a centralized dashboard in the AWS Management Console to monitor the status of all deployments, view deployment history, and access detailed logs." }
                ],
                examples: [
                    "Deploying a new version of a Java web application to a fleet of EC2 instances managed by an Auto Scaling Group using an in-place deployment, with CodeDeploy handling the application restart and health checks.",
                    "Performing a blue/green deployment of a new containerized application to an Amazon ECS cluster. AWS CodeDeploy orchestrates the launch of new task sets, shifts traffic via an Application Load Balancer, and if all health checks pass, terminates the old task set.",
                    "Automating the update of an AWS Lambda function's code in production after a successful build in AWS CodeBuild, triggered as part of an AWS CodePipeline. CodeDeploy handles the safe deployment of the new Lambda version.",
                    "Using CodeDeploy to automate the deployment of configuration files or static website assets to S3 buckets, ensuring versioning and consistency."
                ],
                technicalDetails: "CodeDeploy relies on an agent (CodeDeploy agent) installed on EC2 or on-premises instances to execute deployment commands. For Lambda and ECS, it integrates directly with the respective service APIs. The `appspec.yml` file defines deployment parameters, hooks, and file locations. It works closely with Elastic Load Balancing for traffic shifting during blue/green and canary deployments. Alarms from CloudWatch can be configured to halt or roll back deployments.",
                tools: "AWS CodeDeploy, AWS CodePipeline, AWS CodeBuild, Amazon EC2, AWS Lambda, Amazon ECS, Elastic Load Balancing, Amazon CloudWatch."
            },
            'monitoring-logging': {
                name: "Monitoring & Logging",
                purpose: "To collect, aggregate, analyze, and visualize data (metrics, logs, traces) from applications and infrastructure. This provides critical visibility into system health, performance, and behavior, enabling proactive issue detection, faster troubleshooting, and improved operational efficiency.",
                features: [
                    {
                        title: "Metrics Collection & Analysis",
                        desc: "Gathering quantitative data about system performance (e.g., CPU utilization, memory usage, disk I/O, network throughput) and application-specific metrics (e.g., request latency, error rates, queue lengths). This data is typically stored in time-series databases for historical analysis and trending.",
                        howToSteps: [
                            "**1. Install CloudWatch Agent (for EC2/on-premises):** For custom metrics or detailed host-level metrics, install the CloudWatch Agent on your EC2 instances or on-premises servers. Configure `config.json` to specify what logs/metrics to collect (e.g., CPU, memory, disk usage).",
                            "**2. Send Custom Metrics (Code):** In your application code, use the AWS SDK (e.g., Boto3 for Python) to publish custom metrics to CloudWatch: `client.put_metric_data(Namespace='MyApp', MetricData=[{'MetricName': 'CheckoutCount', 'Value': 1}])`.",
                            "**3. View Metrics in CloudWatch Console:** Navigate to the CloudWatch console, go to 'Metrics', and browse by namespace (e.g., 'AWS/EC2', 'MyApp') to see your collected data.",
                            "**4. Create a Dashboard:** From the CloudWatch console, create a new dashboard and add widgets to visualize your key metrics over time."
                        ]
                    },
                    { title: "Log Aggregation & Centralization", desc: "Collecting and consolidating logs from all sources – applications, servers (EC2 instances, containers), network devices, operating systems, and various cloud services – into a single, centralized platform. This makes it easier to search, filter, and analyze vast amounts of log data for troubleshooting and security forensics." },
                    { title: "Dashboards & Visualization", desc: "Creating customizable graphical dashboards to provide real-time and historical insights into system health, application performance, and operational trends. Visualizations help identify anomalies, correlations, and the overall state of the environment at a glance." },
                    {
                        title: "Alerting & Notifications",
                        desc: "Setting up automated rules (alarms) that trigger notifications (email, SMS, PagerDuty, Slack) when predefined thresholds for metrics are breached (e.g., CPU exceeds 80%) or specific log patterns are detected (e.g., 'ERROR' count spikes). This ensures operations teams are immediately aware of critical issues.",
                        howToSteps: [
                            "**1. Create an SNS Topic:** In the Amazon SNS console, create a new topic (e.g., `DevOpsAlerts`) and subscribe email addresses or other endpoints to it.",
                            "**2. Create a CloudWatch Alarm:** In the CloudWatch console, go to 'Alarms' and click 'Create alarm'.",
                            "**3. Select Metric:** Choose the metric you want to monitor (e.g., `CPUUtilization` for an EC2 instance).",
                            "**4. Define Threshold:** Set the threshold (e.g., `> 80%`) and evaluation period (e.g., `5 minutes`).",
                            "**5. Configure Action:** For 'Notification', select your SNS topic. You can also add EC2 actions or Systems Manager Automation actions.",
                            "**6. Name and Create:** Give your alarm a name and description, then create it. You'll receive a notification if the metric crosses the threshold."
                        ]
                    },
                    { title: "Distributed Tracing", desc: "For microservices architectures, distributed tracing tracks a single request as it flows through multiple services and components. This provides an end-to-end view of latency, errors, and how different services interact, making it easier to pinpoint performance bottlenecks in complex systems." },
                    { title: "Operational Insights & Anomalies", desc: "Leveraging machine learning to automatically detect unusual patterns or anomalies in metrics and logs that might indicate a problem before it becomes critical, reducing the need for manual threshold setting." }
                ],
                examples: [
                    "Using AWS CloudWatch to collect CPU utilization metrics from Amazon EC2 instances and setting up a CloudWatch Alarm to notify the operations team via an SNS topic if CPU usage exceeds 80% for five consecutive minutes.",
                    "Sending all application logs from a fleet of Amazon ECS containers to Amazon CloudWatch Logs. An engineer then uses CloudWatch Logs Insights to query and analyze error patterns across all containers to diagnose a recurring application bug.",
                    "Creating a Grafana dashboard that visualizes key performance indicators (KPIs) of a serverless application, showing request rates, average Lambda duration, and DynamoDB read/write capacity usage in real-time.",
                    "Implementing AWS X-Ray to trace requests through a microservices architecture. When a user reports a slow transaction, X-Ray helps pinpoint which specific microservice or database query is causing the latency."
                ],
                technicalDetails: "Monitoring involves agents (e.g., CloudWatch Agent, Prometheus Exporters, Datadog Agent), standard protocols (SNMP, JMX), and direct API integrations. Logging typically uses syslog, application-specific logging frameworks, and cloud-native services (e.g., CloudWatch Logs, Amazon Kinesis Data Firehose). Open-source solutions like the ELK Stack (Elasticsearch, Logstash, Kibana), Prometheus, and Grafana are widely used. AWS CloudWatch is the core monitoring and observability service that integrates with almost all AWS resources and can ingest custom metrics/logs.",
                tools: "AWS CloudWatch (Metrics, Logs, Alarms, Dashboards), Amazon EventBridge (for event-driven actions), AWS X-Ray (for tracing), Amazon OpenSearch Service (formerly Elasticsearch Service), ELK Stack (Elasticsearch, Logstash, Kibana), Prometheus, Grafana, Splunk, Datadog, New Relic, AppDynamics, Dynatrace."
            },
            'incident-management': {
                name: "Incident Management",
                purpose: "To respond to and resolve unplanned disruptions to IT services, restoring normal operations as quickly as possible, minimizing business impact, and preventing recurrence through structured processes and continuous improvement.",
                features: [
                    { title: "Automated Incident Detection & Alerting", desc: "Systems (e.g., monitoring tools, SIEMs) are configured to automatically detect anomalies or issues and generate alerts when predefined thresholds are breached or specific log patterns are detected. These alerts initiate the incident response process." },
                    { title: "Incident Triage & Prioritization", desc: "A process to quickly categorize incidents based on their severity (e.g., critical, major, minor) and potential business impact. This determines the urgency of the response and the resources to be allocated." },
                    { title: "Communication & Collaboration", desc: "Establishing clear and efficient communication channels for internal teams (operations, development, security), business stakeholders, and external parties (e.g., customers, vendors, legal) during an incident. This ensures everyone is informed and aligned." },
                    { title: "Resolution & Root Cause Analysis", desc: "Implementing temporary fixes (workarounds) to restore service quickly, followed by identifying and implementing permanent solutions to eliminate the underlying cause of the incident. This often involves detailed investigations and data analysis." },
                    { title: "Post-Incident Review (PIR) / Blameless Post-Mortem", desc: "A critical step after an incident is resolved. A blameless review is conducted to document what happened, why it happened, what was done to resolve it, and what can be learned to improve systems, processes, and prevent recurrence. Focus is on learning, not blaming." },
                    { title: "Incident Tracking & Documentation", desc: "Using an ITSM or incident management platform to log all relevant information about an incident, track its progress, assign tasks, and document all actions taken. This provides a comprehensive audit trail and historical data for analysis." }
                ],
                examples: [
                    "When a CloudWatch alarm triggers for high error rates on an API Gateway, an automated incident is created in PagerDuty (or AWS Systems Manager Incident Manager), immediately alerting the on-call engineer via phone and SMS.",
                    "During a widespread production outage, the incident response team coordinates troubleshooting efforts in a dedicated Slack or Microsoft Teams channel, sharing findings from CloudWatch logs and X-Ray traces, and communicating regular status updates to stakeholders via email.",
                    "After resolving a database performance issue, a blameless post-mortem is conducted. The team discovers a recently deployed application change introduced an inefficient query, leading to a new task to optimize the query and add automated integration tests for database performance.",
                    "Using AWS Systems Manager Incident Manager to manage an incident, defining runbooks for common issues, automatically gathering diagnostic data, and coordinating with responders."
                ],
                technicalDetails: "Incident management often relies on IT Service Management (ITSM) platforms, on-call management tools, and integrates tightly with monitoring, alerting, and communication systems. Key metrics include Mean Time To Detect (MTTD), Mean Time To Acknowledge (MTTA), and Mean Time To Resolve (MTTR). AWS provides services like CloudWatch, EventBridge, and Systems Manager Incident Manager to support and automate various aspects of incident management.",
                tools: "PagerDuty, Opsgenie, VictorOps, ServiceNow, Jira Service Management, Freshservice, Slack, Microsoft Teams, AWS Systems Manager Incident Manager, Statuspage (for external communications)."
            },
            'on-call': {
                name: "On-Call & Alerting",
                purpose: "To ensure that designated personnel are automatically notified and available to respond to critical system issues outside of normal business hours, minimizing downtime and business impact. It defines who is responsible for what and how they are contacted.",
                features: [
                    { title: "Automated Alert Generation", desc: "Configuring monitoring systems (e.g., AWS CloudWatch, Prometheus) to automatically generate alerts when predefined thresholds are breached (e.g., service goes down, error rate spikes) or specific log patterns are detected." },
                    { title: "On-Call Schedules & Rotations", desc: "Defining rotation schedules for engineers (e.g., weekly, daily shifts) to ensure 24/7 coverage. This includes primary, secondary, and tertiary responders, ensuring that someone is always available to respond." },
                    { title: "Escalation Policies", desc: "Establishing clear escalation paths that define what happens if an alert is not acknowledged or resolved within a specified timeframe. This ensures critical issues are never dropped and are escalated to higher levels of management or other teams if necessary." },
                    { title: "Multi-Channel Notifications", desc: "Sending notifications through multiple channels (e.g., SMS, phone calls, push notifications to mobile apps, email, Slack/Teams messages) to maximize the chances of the on-call engineer being reached promptly." },
                    { title: "Incident Aggregation & Deduplication", desc: "Intelligently grouping related alerts together and suppressing duplicate notifications to reduce 'alert fatigue' for on-call teams, allowing them to focus on the core issue rather than being overwhelmed by redundant alerts." },
                    { title: "Post-Incident Automation (from alerts)", desc: "Integrating alerting systems with automation tools (e.g., AWS Lambda, SOAR platforms) to trigger automated diagnostic steps or remediation actions immediately after an alert is generated, before human intervention." }
                ],
                examples: [
                    "A PagerDuty schedule rotates on-call responsibilities weekly among the Site Reliability Engineering (SRE) team. If a critical AWS Lambda error alarm triggers at 3 AM, PagerDuty calls the current on-call engineer, and if unanswered after 5 minutes, escalates to the next person on the schedule.",
                    "An alert from an EC2 instance indicating disk space is nearly full triggers a notification to a specific Slack channel via Amazon SNS, allowing the operations team to collaboratively decide on the next steps.",
                    "Using Opsgenie to manage incident ownership and automatically create a Jira ticket when an alert for a critical service degradation is received from AWS CloudWatch, ensuring the issue is formally tracked.",
                    "An EventBridge rule reacts to a CloudWatch alarm, triggering a Lambda function to automatically collect diagnostic logs from the affected EC2 instance and attach them to the PagerDuty incident for the on-call engineer."
                ],
                technicalDetails: "On-call management platforms (like PagerDuty, Opsgenie) integrate deeply with monitoring systems (AWS CloudWatch, Prometheus, Datadog) and communication tools (Slack, Microsoft Teams). They manage user schedules, contact methods, and complex escalation rules. The effectiveness relies on accurate alerting (minimizing false positives) and well-defined incident response playbooks. AWS Systems Manager Incident Manager also provides basic on-call scheduling and incident response capabilities.",
                tools: "PagerDuty, Opsgenie, VictorOps, Splunk On-Call, AWS Systems Manager Incident Manager, Amazon CloudWatch (Alarms), Amazon SNS (Notifications)."
            },
            'aws-cloudwatch': {
                name: "AWS CloudWatch",
                purpose: "A monitoring and observability service that provides data and actionable insights to monitor your applications, respond to system-wide performance changes, and optimize resource utilization and operational health across your AWS and on-premises environments.",
                features: [
                    { title: "Metrics Collection & Analysis", desc: "Automatically collects detailed metrics from AWS resources (e.g., EC2, Lambda, S3, RDS, DynamoDB, VPC, ELB) and custom applications. It provides real-time visibility into performance and operational health, allowing you to track resource utilization, service latency, and application-specific KPIs." },
                    { title: "Logs Management & Insights", desc: "Centralizes logs from various AWS services (e.g., Lambda, VPC Flow Logs, CloudTrail, ECS) and custom applications in CloudWatch Logs. It enables powerful searching, filtering, analysis using CloudWatch Logs Insights, and setting up metric filters for specific log patterns." },
                    { title: "Alarms & Automated Actions", desc: "Allows you to set up alarms based on metric thresholds or specific log patterns. When an alarm's state changes (e.g., 'IN ALARM'), it can trigger notifications via Amazon SNS, or automated actions like Auto Scaling events, EC2 instance stop/terminate/reboot, or triggering Lambda functions." },
                    { title: "Custom Dashboards & Visualizations", desc: "Create customizable graphical dashboards to visualize metrics, logs, and alarms, providing a unified and real-time view of your operational health. This helps identify trends, correlations, and quickly pinpoint issues." },
                    { title: "Events & Rules (Amazon EventBridge)", desc: "CloudWatch Events (now Amazon EventBridge) allows you to react to changes in AWS resources (e.g., EC2 instance state changes, S3 object uploads) or custom application events. You can define rules to route these events to target services like Lambda functions, SQS queues, SNS topics, or Step Functions for automated actions." },
                    { title: "ServiceLens & Contributor Insights", desc: "CloudWatch ServiceLens integrates with AWS X-Ray to provide a comprehensive view of your application's health, allowing you to see metrics, logs, and traces in one place. Contributor Insights helps identify top contributors to a metric (e.g., top IPs by error count, top Lambda functions by duration)." }
                ],
                examples: [
                    "Monitoring the latency of an API Gateway endpoint and triggering a CloudWatch Alarm if it exceeds 500ms for three consecutive periods, which then sends an alert to the on-call team via SNS.",
                    "Collecting application logs from a fleet of Amazon EC2 instances and AWS Lambda functions into CloudWatch Logs. An operations engineer then uses CloudWatch Logs Insights to query and analyze error patterns across all microservices to diagnose a recurring application bug.",
                    "Setting up an Amazon EventBridge rule to trigger a specific AWS Lambda function whenever a new object is uploaded to an Amazon S3 bucket, initiating an automated data processing workflow.",
                    "Creating a CloudWatch dashboard that visualizes key performance indicators (KPIs) of a microservices architecture, showing request rates, average Lambda duration, DynamoDB read/write capacity usage, and network traffic in real-time."
                ],
                technicalDetails: "CloudWatch is a core AWS service for observability, deeply integrated with nearly all other AWS services. It uses agents (CloudWatch Agent) for collecting custom metrics and logs from EC2 instances and on-premises servers. Metrics are stored in a time-series database. EventBridge decouples event producers from event consumers, enabling highly scalable and flexible event-driven architectures. Understanding IAM permissions for CloudWatch is critical.",
                tools: "AWS CloudWatch (Metrics, Logs, Alarms, Dashboards, Events/EventBridge, ServiceLens, Contributor Insights), AWS CLI, AWS SDKs, Grafana (for integrating with CloudWatch metrics), Prometheus (can integrate with CloudWatch for some use cases)."
            },
            'aws-systems-manager': {
                name: "AWS Systems Manager",
                purpose: "A collection of capabilities that helps you automate operational tasks across your AWS resources and on-premises servers, making it easier to manage compute instances (EC2, on-premises VMs, virtual machines in other clouds) at scale, improve operational efficiency, and maintain security and compliance.",
                features: [
                    { title: "Run Command", desc: "Securely and remotely execute commands, scripts (Bash, PowerShell), or automation documents on fleets of EC2 instances and on-premises servers without needing to SSH or RDP into them directly. This is ideal for one-off operational tasks or quick remediations." },
                    { title: "State Manager", desc: "Automate the process of keeping your servers in a defined, consistent state by applying configuration baselines, installing software, and ensuring services are running. It helps prevent 'configuration drift' and ensures compliance over time." },
                    { title: "Patch Manager", desc: "Automates the patching of operating systems (Windows, Linux) and applications on EC2 instances and on-premises servers. It helps keep instances up-to-date with the latest security fixes, reducing vulnerability exposure." },
                    { title: "Automation", desc: "Build and execute automated workflows (runbooks) for common operational tasks, reducing manual effort and potential errors. These workflows can span multiple AWS services and can be triggered by events or on a schedule." },
                    { title: "Parameter Store", desc: "Securely store and manage configuration data and secrets (e.g., database connection strings, API keys, passwords) separate from code. It offers integration with KMS for encryption and allows for versioning and granular access control." },
                    { title: "Session Manager", desc: "Provides secure, auditable, and browser-based or CLI-based access to EC2 instances and on-premises servers. It eliminates the need to open inbound SSH/RDP ports or manage SSH keys, enhancing security posture and simplifying access management." },
                    { title: "Fleet Manager", desc: "A unified user interface in Systems Manager that allows you to view and interact with your server fleet, simplifying troubleshooting and daily management tasks." }
                ],
                examples: [
                    "Using Systems Manager Run Command to quickly apply an urgent security patch to a hundred EC2 instances across different AWS accounts in response to a newly discovered vulnerability.",
                    "Setting up Systems Manager State Manager to ensure that all development EC2 instances have specific monitoring agents installed, configuration files present, and security baselines applied automatically upon launch and regularly thereafter.",
                    "Automating the rotation of database credentials stored in Parameter Store using a Systems Manager Automation document triggered by an AWS Lambda function on a schedule.",
                    "An administrator securely connecting to an EC2 instance using Session Manager from their browser, without needing to open SSH ports or use a VPN, providing a fully auditable session."
                ],
                technicalDetails: "Systems Manager relies on the SSM Agent installed on EC2 instances and on-premises servers. It integrates deeply with AWS IAM for granular permissions, AWS CloudTrail for auditing all actions, and Amazon EventBridge for event-driven automation. It's a key service for implementing 'Ops as Code' and automating routine operational tasks.",
                tools: "AWS Systems Manager (Run Command, State Manager, Patch Manager, Automation, Parameter Store, Session Manager, Fleet Manager, Change Manager, Explorer), AWS CLI, AWS SDKs."
            },
            'performance-monitoring': {
                name: "Performance Monitoring",
                purpose: "To continuously track, collect, and analyze the performance metrics of systems, applications, and infrastructure components to identify bottlenecks, resource contention, and areas for optimization. It ensures systems meet performance requirements and helps in capacity planning.",
                features: [
                    { title: "Resource Utilization Metrics", desc: "Monitoring key performance indicators (KPIs) of underlying infrastructure components such as CPU utilization, memory usage, disk I/O operations per second (IOPS), network throughput, and latency for servers (EC2), containers (ECS, EKS), and databases (RDS, DynamoDB)." },
                    { title: "Application Performance Metrics", desc: "Tracking application-specific metrics like request latency (end-to-end and per-service), error rates, throughput (requests per second), concurrent users, and business transaction response times. This provides insight into the application's actual responsiveness." },
                    { title: "Custom Metrics & Business KPIs", desc: "Ability to define and collect custom metrics that are specific to your application's logic or business performance, such as 'items added to cart per minute', 'successful checkouts', or 'failed login attempts'." },
                    { title: "Trend Analysis & Capacity Planning", desc: "Analyzing historical performance data to identify long-term trends, anticipate future resource needs, and inform capacity planning decisions for scaling infrastructure proactively." },
                    { title: "Alerting on Performance Thresholds", desc: "Setting up alarms that automatically trigger notifications or automated actions when performance metrics exceed predefined thresholds (e.g., 'API latency > 500ms for 5 minutes', 'Database CPU > 90%')." },
                    { title: "Dashboarding & Visualization", desc: "Creating graphical dashboards to visualize real-time and historical performance data, allowing engineers and stakeholders to quickly assess system health, identify anomalies, and correlate performance issues with specific events." }
                ],
                examples: [
                    "Monitoring the latency of an Amazon RDS PostgreSQL database using CloudWatch metrics and setting up an Auto Scaling rule for read replicas if query times consistently exceed a threshold, to distribute read load.",
                    "Using AWS CloudWatch to track the number of invocations, average duration, and error rates of a critical AWS Lambda function, identifying slow functions for optimization or provisioning concurrency.",
                    "Implementing Prometheus and Grafana to collect and visualize Kubernetes cluster resource utilization (CPU, memory, network of nodes and pods) and individual application performance metrics, providing a comprehensive view of containerized workloads.",
                    "Running a load test against a web application and observing the response times and error rates in CloudWatch dashboards, while simultaneously checking EC2 CPU utilization and RDS database connections to pinpoint bottlenecks."
                ],
                technicalDetails: "Performance monitoring involves agents (e.g., CloudWatch Agent, Prometheus Exporters), instrumentation within application code, and specialized metrics databases (time-series databases). It often relies on dashboards (Grafana, CloudWatch Dashboards) for visualization and alerting engines. AWS CloudWatch is the primary service for collecting, analyzing, and visualizing metrics from AWS resources. Distributed tracing (like AWS X-Ray) complements performance monitoring by providing end-to-end request visibility.",
                tools: "AWS CloudWatch, Prometheus, Grafana, Datadog, New Relic, AppDynamics, Dynatrace, AWS Lambda (for serverless metric processing), AWS Kinesis (for real-time metric streams)."
            },
            'application-monitoring': {
                name: "Application Monitoring",
                purpose: "To gain deep visibility into the health, performance, and user experience of software applications. It focuses on application-specific metrics, distributed traces, and detailed logs to diagnose issues within the application's code, its dependencies, and external integrations.",
                features: [
                    { title: "Distributed Tracing (End-to-End Visibility)", desc: "Tracks a single request as it flows through all components of a distributed application (e.g., microservices, databases, queues, external APIs). This provides an end-to-end view of the request path, latency incurred at each step, and helps pinpoint performance bottlenecks or errors across complex systems." },
                    { title: "Code-Level Performance Monitoring", desc: "Monitors the execution of application code itself, identifying slow functions, inefficient database queries, or bottlenecks in specific parts of the business logic. This requires instrumentation within the application runtime." },
                    { title: "User Experience Monitoring (Real User Monitoring - RUM)", desc: "Collects data on actual user interactions and performance from the client-side (e.g., web browsers, mobile apps). This includes metrics like page load times, front-end errors, interactive response times, and geographic distribution of users, providing insights into the real user experience." },
                    { title: "Synthetic Monitoring (Proactive Testing)", desc: "Simulates user interactions (e.g., logging in, making a purchase, calling an API) from various geographic locations at regular intervals. This proactively detects performance and availability issues before real users are affected, providing early warnings." },
                    { title: "Dependency Mapping", desc: "Automatically discovers and visualizes the relationships and dependencies between different application services, databases, and external APIs. This helps in understanding the architecture and impact of changes or failures." },
                    { title: "Error Tracking & Alerting", desc: "Captures and aggregates application errors, providing stack traces and context. Alerts are triggered for spikes in error rates or specific error types, allowing development teams to react quickly." }
                ],
                examples: [
                    "Using AWS X-Ray to trace a user request from a mobile application through an API Gateway, multiple AWS Lambda functions, an Amazon SQS queue, and a DynamoDB database, quickly identifying which part of the workflow is introducing the most latency.",
                    "Implementing New Relic's APM agent in a Spring Boot application running on Amazon EC2. The agent provides code-level visibility into slow database queries and external API calls, helping developers optimize performance.",
                    "Setting up an Amazon CloudWatch Synthetics canary to regularly check the availability and load time of a critical website login page from different geographic regions, proactively alerting if the page becomes slow or unavailable.",
                    "Analyzing logs from a containerized application in Amazon CloudWatch Logs to identify and count specific application errors, then creating a CloudWatch metric filter and alarm for these errors."
                ],
                technicalDetails: "Application Performance Monitoring (APM) often uses agents that instrument application code at runtime or bytecode level. It relies on distributed tracing protocols (e.g., OpenTelemetry, Jaeger) to correlate requests across services. Real User Monitoring (RUM) uses client-side JavaScript. Synthetic monitoring involves headless browsers or scripting engines. AWS X-Ray is AWS's native distributed tracing service, and CloudWatch Synthetics provides synthetic monitoring capabilities. Combining these with CloudWatch Metrics and Logs provides a comprehensive observability solution.",
                tools: "AWS X-Ray, New Relic, Datadog APM, Dynatrace, AppDynamics, OpenTelemetry, Jaeger, AWS CloudWatch Synthetics, Sentry (for error tracking), LogRocket (for session replay)."
            },
            'log-analysis': {
                name: "Log Analysis",
                purpose: "To collect, parse, store, index, and analyze vast quantities of log data generated by applications, servers, and infrastructure. It provides insights for troubleshooting, security monitoring, auditing, performance optimization, and understanding user behavior.",
                features: [
                    { title: "Log Aggregation & Ingestion", desc: "Collecting and centralizing logs from disparate sources across an entire infrastructure (e.g., EC2 instances, Lambda functions, containers, network devices, databases, web servers) into a unified logging platform. This typically involves log shippers or direct integrations." },
                    { title: "Parsing, Structuring & Enrichment", desc: "Transforming unstructured log data (raw text lines) into structured, queryable data (e.g., JSON) by parsing out key fields (timestamp, log level, message, user ID). Logs can also be enriched with contextual metadata (e.g., EC2 instance ID, application version, user agent)." },
                    { title: "Powerful Search & Filtering", desc: "Providing advanced search capabilities to quickly find specific events, error messages, user activities, or patterns within massive datasets of historical and real-time log data. This is crucial for rapid troubleshooting and incident investigation." },
                    { title: "Visualization & Dashboards", desc: "Presenting log data in graphical formats (e.g., error rate trends over time, distribution of log levels, geographical origin of requests, top users) to identify issues, anomalies, and operational trends more easily than sifting through raw logs." },
                    { title: "Real-time Alerting from Logs", desc: "Setting up alarms that automatically trigger notifications or automated actions based on specific log events (e.g., a sudden spike in 'ERROR' messages, detection of a specific security event, repeated failed login attempts). This enables proactive issue response." },
                    { title: "Long-Term Retention & Archival", desc: "Storing log data for extended periods (months or years) to meet compliance requirements, support deep forensic investigations, and enable historical trend analysis. This often involves tiered storage solutions." }
                ],
                examples: [
                    "Using Amazon CloudWatch Logs Insights to run ad-hoc queries on AWS Lambda function logs to find all errors containing a specific `NullPointerException` over the last 24 hours, quickly identifying the root cause of an application issue.",
                    "Sending all VPC Flow Logs (network traffic logs) to an Amazon S3 bucket, then using AWS Athena or Amazon OpenSearch Service to analyze network traffic patterns, identify unauthorized access attempts, or diagnose connectivity issues.",
                    "Implementing the ELK Stack (Elasticsearch for storage, Logstash for processing, Kibana for visualization) to collect web server access logs. Developers then build Kibana dashboards to visualize user traffic patterns, identify top error pages, and detect suspicious requests.",
                    "An engineer uses a CloudWatch Logs metric filter to count the occurrences of 'AuthenticationFailed' messages in an application's logs and creates an alarm to notify the security team if the count exceeds a threshold within a minute, indicating a potential brute-force attack."
                ],
                technicalDetails: "Log analysis solutions involve a pipeline of components: log shippers (e.g., Fluentd, Logstash, CloudWatch Agent) to collect logs, message queues (e.g., Kinesis Data Firehose, SQS) for buffering, storage solutions (e.g., Elasticsearch, S3, OpenSearch Service) for persistence and indexing, and visualization tools (e.g., Kibana, Grafana, CloudWatch Dashboards). Structured logging (JSON format) greatly simplifies parsing and analysis. AWS provides a rich ecosystem of services for comprehensive log management.",
                tools: "Amazon CloudWatch Logs, Amazon OpenSearch Service (formerly Elasticsearch Service), ELK Stack (Elasticsearch, Logstash, Kibana), Splunk, Datadog Log Management, Sumo Logic, Grafana Loki, Fluentd, Logstash, AWS Kinesis Data Firehose, AWS Athena."
            },
            'aws-xray': {
                name: "AWS X-Ray",
                purpose: "To help developers analyze and debug distributed applications, such as those built using microservices, serverless architectures, or hybrid cloud setups. X-Ray provides an end-to-end view of requests as they travel through your application, showing where performance bottlenecks, errors, and faults occur.",
                features: [
                    { title: "Service Map Visualization", desc: "Generates a visual 'service map' that displays the services and resources (e.g., Lambda functions, EC2 instances, SQS queues, DynamoDB tables, external APIs) that your application uses. It shows connections, health status, and average latency between these components at a glance, making it easy to understand complex architectures." },
                    { title: "Detailed Trace Analysis", desc: "Provides detailed information for individual requests (called 'traces'), breaking down the request's journey into 'segments' (representing services) and 'subsegments' (representing individual calls within a service, like database queries or HTTP calls to other services). This allows for deep inspection of latency, errors, and payload data for each step." },
                    { title: "Performance Bottleneck Identification", desc: "Helps pinpoint where performance issues or high latency originate by highlighting sections of the request path that are taking too long. This enables developers to focus optimization efforts on the most impactful areas." },
                    { title: "Error & Fault Detection", desc: "Automatically detects and highlights errors (4xx client errors) and faults (5xx server errors) within your application's request flow. It provides stack traces and error messages, accelerating the diagnosis of application failures." },
                    { title: "Annotations & Metadata", desc: "Allows developers to add custom annotations (key-value pairs) and metadata (JSON objects) to traces. This enables easier filtering and analysis of traces based on business context, such as user IDs, transaction IDs, or specific feature flags." },
                    { title: "Sampling & Filtering", desc: "X-Ray supports sampling rules to control which requests are traced, balancing between comprehensive data collection and cost. You can also filter traces based on various criteria to focus on specific issues." }
                ],
                examples: [
                    "Troubleshooting a slow user login in a serverless application: by using X-Ray, an engineer traces the request and discovers that the latency is primarily caused by an inefficient scan operation on a DynamoDB table, or a slow external authentication service.",
                    "A developer integrates the X-Ray SDK into their AWS Lambda functions. When a customer reports an issue, the developer can quickly find the corresponding trace in X-Ray, identify the specific function causing an error (e.g., a 500 fault), and view its logs directly.",
                    "Using X-Ray's service map to visualize the dependencies and performance of a newly deployed microservices architecture on Amazon ECS, ensuring that all services are communicating as expected and identifying any unexpected dependencies or high-latency calls.",
                    "During a performance test, X-Ray helps identify specific API calls or database operations that become bottlenecks under high load, guiding optimization efforts."
                ],
                technicalDetails: "AWS X-Ray relies on an SDK (integrated into application code) and an X-Ray daemon (running on EC2, ECS, or integrated into Lambda) to collect trace data. Traces are composed of segments and subsegments, forming a hierarchical view of the request. X-Ray integrates natively with many AWS services (e.g., API Gateway, Lambda, EC2, ECS, SQS, SNS, DynamoDB, RDS). It uses a sampling algorithm to decide which requests to trace, and the data is stored for up to 30 days.",
                tools: "AWS X-Ray (SDK, Daemon, Console), AWS CLI, AWS SDKs, OpenTelemetry (can send traces to X-Ray)."
            },
            'aws-cloudtrail': {
                name: "AWS CloudTrail",
                purpose: "To enable governance, compliance, operational auditing, and risk auditing of your AWS account. It records AWS API calls and related events made by an identity or service in your account, capturing activity across your AWS infrastructure.",
                features: [
                    { title: "AWS API Activity Logging", desc: "Records a detailed history of AWS API calls for your account, including calls made through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This provides a comprehensive audit trail of actions performed in your account." },
                    { title: "Event History (90 Days)", desc: "Provides a searchable and filterable view of up to 90 days of management events (API activity) directly in the CloudTrail console. This allows for quick lookup of recent actions and changes." },
                    { title: "Log File Delivery to S3", desc: "Delivers encrypted (using S3-managed keys or KMS) and immutable log files to an Amazon S3 bucket for long-term storage, archival, and analysis. This is crucial for forensic investigations, compliance, and historical trend analysis." },
                    { title: "Integration with CloudWatch Logs & Events", desc: "Can send CloudTrail events to Amazon CloudWatch Logs for real-time monitoring, alarming on specific activities, and centralized logging. It also integrates with Amazon EventBridge (formerly CloudWatch Events) to trigger automated actions in response to API activity." },
                    { title: "Security & Compliance Auditing", desc: "Essential for security investigations (e.g., 'Who deleted this S3 bucket?'), troubleshooting operational issues, and demonstrating compliance with various regulatory standards (e.g., HIPAA, PCI DSS, GDPR, SOC 2) by providing evidence of activity." },
                    { title: "Data Events (S3, Lambda)", desc: "Beyond management events, CloudTrail can also log 'data events' for services like Amazon S3 (object-level API activity) and AWS Lambda (function invocation activity), providing even more granular auditing capabilities (additional cost may apply)." }
                ],
                examples: [
                    "Investigating a suspected security incident by reviewing CloudTrail logs to determine who made a suspicious `DeleteBucket` API call on an Amazon S3 bucket, what time it occurred, and from what IP address.",
                    "Monitoring CloudTrail for `RunInstances` API calls to detect unauthorized EC2 instance launches in your AWS account and triggering an automated alert to the security team.",
                    "Using CloudTrail logs in conjunction with an external SIEM (Security Information and Event Management) system to gain a comprehensive view of all AWS account activity for auditing and threat detection purposes.",
                    "Creating an Amazon EventBridge rule that reacts to a `CreateUser` or `AttachUserPolicy` IAM API call logged by CloudTrail, triggering a Lambda function to review and audit new IAM changes automatically."
                ],
                technicalDetails: "CloudTrail captures events as JSON log files, which are typically delivered to a designated S3 bucket. It is a global service by default, consolidating activity from all AWS regions into a single log file stream if configured as an 'organization trail'. CloudTrail Lake provides advanced query capabilities for analyzing immutable CloudTrail event data. Understanding the difference between management events and data events is important for cost and scope.",
                tools: "AWS CloudTrail, Amazon S3, Amazon CloudWatch Logs, Amazon EventBridge, AWS Security Hub (for CloudTrail insights), AWS Audit Manager, AWS CLI, AWS SDKs, third-party SIEM solutions."
            },
            'iam': {
                name: "Identity and Access Management (IAM)",
                purpose: "To securely manage access to AWS services and resources. It allows you to create and manage AWS users and groups, and use permissions to allow and deny their access to resources, implementing the principle of least privilege.",
                features: [
                    { title: "IAM Users, Groups, and Roles", desc: "Create IAM users for individual people or applications with long-term credentials. Group users together (IAM Groups) to apply permissions more easily. Define IAM roles to grant temporary, time-limited access to AWS services (e.g., an EC2 instance accessing S3) or to users in other AWS accounts/federated identities." },
                    { title: "IAM Policies (Permissions)", desc: "Define granular permissions using JSON policies that specify what actions are allowed or denied on which AWS resources, under what conditions. Policies are attached to users, groups, or roles and enforce the 'principle of least privilege'." },
                    { title: "Multi-Factor Authentication (MFA)", desc: "Enhance security by requiring users to provide two or more different types of verification factors (e.g., password + virtual MFA device, hardware token, SMS) before granting access. This significantly reduces the risk of unauthorized access even if passwords are compromised." },
                    { title: "Temporary Security Credentials", desc: "AWS STS (Security Token Service) provides temporary, short-lived credentials for users or roles. This is a best practice, especially for applications running on EC2 or Lambda, as it removes the need to store long-term access keys directly on instances." },
                    { title: "IAM Access Analyzer", desc: "Helps identify resources shared with an external entity outside your AWS account (e.g., public S3 buckets, cross-account IAM roles), flagging potential unintended access and misconfigurations." },
                    { title: "Federated Identities & SSO", desc: "Integrates with enterprise identity providers (e.g., Active Directory, Okta, Azure AD) using standards like SAML 2.0 or OpenID Connect. This enables users to log into their AWS accounts using their existing corporate credentials (Single Sign-On - SSO), streamlining access management." }
                ],
                examples: [
                    "Creating an IAM role for an Amazon EC2 instance that grants it specific permissions to read and write objects to a designated Amazon S3 bucket, ensuring the application running on the instance can only access its required storage.",
                    "Configuring an IAM policy that grants read-only access to all DynamoDB tables for developers in the 'Dev' IAM group, enforcing the principle of least privilege.",
                    "Enabling MFA for all root account users and administrative IAM users to significantly reduce the risk of unauthorized access, adding an extra layer of security beyond just a password.",
                    "An AWS Lambda function assumes an IAM role at runtime to write logs to CloudWatch Logs and interact with a specific DynamoDB table, without any hardcoded credentials in the function code.",
                    "Using AWS IAM Identity Center (successor to AWS SSO) to federate enterprise Active Directory users into multiple AWS accounts, providing a centralized and consistent login experience."
                ],
                technicalDetails: "IAM is a global service within AWS that controls all authentication and authorization for AWS operations. Policies are evaluated by the IAM service whenever an API call is made. Understanding policy evaluation logic (explicit deny > explicit allow > implicit deny) is crucial. Best practices include following the principle of least privilege, regular credential rotation, and using IAM roles for AWS services and federated users instead of long-lived access keys.",
                tools: "AWS IAM, AWS Identity and Access Management (IAM) Identity Center (formerly AWS SSO), AWS STS, AWS CLI, AWS SDKs, Third-party identity providers (Okta, Azure AD)."
            },
            'compliance': {
                name: "Compliance & Auditing",
                purpose: "To ensure that AWS environments and applications adhere to relevant industry standards, regulatory requirements (e.g., GDPR, HIPAA, PCI DSS, SOC 2, ISO 27001), and internal security policies. It also involves continuously monitoring and demonstrating this adherence through audit trails, reports, and automated checks.",
                features: [
                    { title: "Automated Compliance Checks (AWS Config Rules)", desc: "Leveraging services like AWS Config to continuously monitor and assess resource configurations against predefined compliance benchmarks (e.g., CIS AWS Foundations Benchmark) or custom rules. It automatically reports on deviations from desired configurations." },
                    { title: "Comprehensive Audit Trails (AWS CloudTrail)", desc: "Maintaining a detailed and immutable record of all AWS API calls and related events performed in your account via AWS CloudTrail. This provides a crucial audit trail for forensic investigations, troubleshooting, and demonstrating accountability for changes." },
                    { title: "Centralized Security Findings (AWS Security Hub)", desc: "Aggregates security findings and compliance status from various AWS services (e.g., Config, GuardDuty, Inspector, Macie) and partner solutions into a standardized format. This provides a comprehensive, centralized view of your security and compliance posture." },
                    { title: "Configuration Management & Drift Detection", desc: "Ensuring that resource configurations remain compliant over time and automatically detecting and alerting on 'configuration drift' (unauthorized or accidental changes that violate policies). AWS Config and Systems Manager State Manager assist here." },
                    { title: "Reporting & Dashboarding", desc: "Providing tools to generate comprehensive reports for auditors, regulators, internal stakeholders, and customers, demonstrating adherence to various compliance mandates. Dashboards visualize compliance posture and progress." },
                    { title: "Automated Remediation", desc: "Automating the remediation of non-compliant resources or security findings, often triggered by AWS Config rules or Security Hub insights (e.g., automatically making a publicly exposed S3 bucket private)." }
                ],
                examples: [
                    "Using AWS Config to continuously monitor if all Amazon S3 buckets are encrypted at rest and publicly inaccessible, reporting on any non-compliant buckets. If a bucket is found public, a remediation Lambda function can automatically make it private.",
                    "Leveraging AWS Security Hub to aggregate security findings from GuardDuty (for threat detection), Inspector (for vulnerability scanning), and Config (for compliance checks), providing a unified view of the security and compliance status across an enterprise's AWS accounts.",
                    "Generating AWS CloudTrail logs and sending them to a WORM-enabled (Write Once Read Many) Amazon S3 bucket for long-term, immutable storage to meet specific regulatory requirements (e.g., for financial or healthcare data).",
                    "Using AWS Audit Manager to continuously collect evidence of compliance with frameworks like HIPAA or PCI DSS, streamlining the auditing process and reducing manual effort during compliance reviews."
                ],
                technicalDetails: "AWS provides a suite of native services that directly support compliance and auditing. AWS Config evaluates resource configurations, CloudTrail logs API activity, Security Hub centralizes findings, and Audit Manager helps automate evidence collection for specific frameworks. Integrating these services creates a robust compliance monitoring and reporting system. External GRC (Governance, Risk, and Compliance) tools often consume data from these AWS services via APIs.",
                tools: "AWS Config (Rules, Conformance Packs), AWS CloudTrail, AWS Security Hub, AWS Audit Manager, AWS Systems Manager (State Manager), AWS Lambda (for custom Config rules and remediation), Third-party GRC tools."
            },
            'security-automation': {
                name: "Security Automation",
                purpose: "To automate repetitive security tasks, responses to security events, and continuous compliance checks across the cloud environment. This improves efficiency, consistency, speed of reaction to threats, and reduces the manual burden on security teams.",
                features: [
                    { title: "Automated Incident Response", desc: "Triggering automated actions in response to detected security alerts or incidents. Examples include isolating a compromised EC2 instance, blocking a malicious IP on a Web Application Firewall (WAF), or automatically collecting forensic data from a suspicious host." },
                    { title: "Continuous Compliance & Remediation", desc: "Automatically auditing resource configurations against security best practices and compliance standards (e.g., CIS Benchmark). If a non-compliant resource is detected, automated remediation actions can be triggered to bring it back into compliance (e.g., automatically encrypting an unencrypted S3 bucket)." },
                    { title: "Vulnerability Management Automation", desc: "Automating aspects of vulnerability management, such as the patching of systems (e.g., via AWS Systems Manager Patch Manager) or the application of security configurations based on detected vulnerabilities, integrating with vulnerability scanning tools." },
                    { title: "Security Orchestration & Playbooks", desc: "Connecting and coordinating various security tools and processes to work together seamlessly. This involves defining security 'playbooks' or 'runbooks' that automate sequences of actions across different systems in response to specific threats." },
                    { title: "Credential Rotation & Secret Management", desc: "Automating the periodic rotation of database credentials, API keys, and other secrets stored in secret management services (e.g., AWS Secrets Manager), significantly reducing the risk associated with long-lived credentials." },
                    { title: "Policy Enforcement as Code", desc: "Defining security policies as code (e.g., using AWS Config Rules, AWS IAM policies) that are automatically enforced across the environment, ensuring consistent security posture from the start." }
                ],
                examples: [
                    "An AWS Security Hub insight about a compromised EC2 instance (detected by GuardDuty) triggers an Amazon EventBridge rule, which then invokes an AWS Lambda function. This Lambda function automatically modifies the security group of the compromised instance to isolate it from the network.",
                    "Using AWS Config Rules to automatically detect if an S3 bucket is publicly accessible. If it is, an AWS Systems Manager Automation document is triggered to make the bucket private, enforcing a security policy.",
                    "Automating the rotation of database credentials stored in AWS Secrets Manager using a scheduled AWS Lambda function, which updates both the secret and the database user's password.",
                    "A CI/CD pipeline includes a security automation step that uses AWS Inspector to scan new Docker images for vulnerabilities before they are deployed to production. If critical vulnerabilities are found, the pipeline automatically fails."
                ],
                technicalDetails: "Security automation in AWS heavily leverages serverless services like AWS Lambda and Amazon EventBridge (for event-driven logic), AWS Systems Manager Automation documents, AWS Security Hub (for centralized findings and custom actions), and various AWS security services (WAF, GuardDuty, Config). It's a key component of DevSecOps, shifting security left into the development pipeline and providing rapid, scalable responses to security events.",
                tools: "AWS Lambda, Amazon EventBridge, AWS Systems Manager Automation, AWS Security Hub, AWS Config, AWS WAF, AWS GuardDuty, AWS Secrets Manager, AWS Inspector, SOAR platforms (e.g., Splunk SOAR, Cortex XSOAR)."
            },
            'aws-security-hub': {
                name: "AWS Security Hub",
                purpose: "A cloud security posture management service that centralizes security findings from various AWS services (like Amazon GuardDuty, Amazon Inspector, Amazon Macie, AWS Config) and partner solutions, providing a comprehensive and standardized view of your security posture across your AWS accounts and enabling automated remediation.",
                features: [
                    { title: "Centralized Security Findings Aggregation", desc: "Aggregates security alerts, vulnerabilities, and compliance status from dozens of AWS services and integrated third-party security products into a single, standardized format (AWS Security Finding Format - ASFF). This eliminates the need to check multiple consoles for security alerts." },
                    { title: "Automated Security Checks & Compliance Benchmarks", desc: "Automatically runs continuous security checks against industry standards (e.g., CIS AWS Foundations Benchmark, PCI DSS) and AWS best practices. It identifies deviations from these standards and highlights non-compliant resources, providing actionable insights." },
                    { title: "Actionable Insights & Customizable Dashboards", desc: "Provides high-level, actionable insights into your overall security posture, allowing you to prioritize the most critical findings. Customizable dashboards visualize compliance status, trending security issues, and overall risk." },
                    { title: "Integration with Incident Response & Automation", desc: "Enables automated remediation actions by integrating with services like Amazon EventBridge and AWS Lambda. This allows you to automatically trigger functions or workflows to respond to specific findings (e.g., isolate a compromised instance, apply a security patch)." },
                    { title: "Cross-Account Aggregation", desc: "Allows you to aggregate security findings from multiple AWS accounts into a single delegated administrator account, providing a centralized security view for large organizations." },
                    { title: "Partnership Integrations", desc: "Supports integrations with numerous third-party security products (e.g., vulnerability scanners, SIEMs, container security tools), enriching findings and allowing them to be consumed by other systems." }
                ],
                examples: [
                    "Monitoring AWS Security Hub for critical findings like publicly exposed S3 buckets, unencrypted EBS volumes, or compromised IAM credentials across all AWS accounts in an organization's AWS Organizations structure.",
                    "Setting up a custom action in Security Hub: when a 'high severity' finding (e.g., GuardDuty detecting a crypto-mining activity) is detected, it triggers an Amazon EventBridge rule that invokes an AWS Lambda function to automatically isolate the affected EC2 instance and notify the security operations center.",
                    "Using Security Hub to track the organization's compliance with the CIS AWS Foundations Benchmark, identifying specific controls that need to be addressed and monitoring progress over time.",
                    "A security analyst uses Security Hub's aggregated findings and insights to prioritize daily security tasks and understand the most pressing vulnerabilities in their AWS environment."
                ],
                technicalDetails: "Security Hub consumes findings from integrated services, normalizes them into ASFF, and stores them. It uses AWS Config for compliance checks and EventBridge for triggering automated responses. It's a crucial service for implementing cloud security posture management (CSPM) and centralizing security operations in AWS. Permissions for Security Hub are managed via AWS IAM.",
                tools: "AWS Security Hub, Amazon GuardDuty, Amazon Inspector, Amazon Macie, AWS Config, Amazon EventBridge, AWS Lambda, AWS WAF, Third-party security vendors."
            },
            'aws-config': {
                name: "AWS Config",
                purpose: "To allow you to assess, audit, and evaluate the configurations of your AWS resources. It continuously monitors and records your AWS resource configurations and allows you to automate the evaluation of recorded configurations against desired configurations, ensuring compliance and security.",
                features: [
                    { title: "Continuous Configuration Monitoring", desc: "Records point-in-time configurations of your AWS resources (e.g., EC2 instances, S3 buckets, security groups, RDS databases) and tracks configuration changes over time. This provides a complete historical record of how resources were configured." },
                    { title: "Automated Compliance Rules (AWS Config Rules)", desc: "Allows you to define 'AWS Config Rules' (pre-built managed rules or custom rules backed by AWS Lambda functions) to automatically evaluate resource configurations against desired policies (e.g., 'S3 bucket should not be public', 'EC2 instances must have an approved AMI', 'RDS instances must be encrypted')." },
                    { title: "Configuration History & Snapshots", desc: "Maintains a detailed configuration history for each resource, showing all changes that occurred. It also provides configuration snapshots (a point-in-time record of all resource configurations in your account), which are invaluable for auditing, compliance, and incident forensics." },
                    { title: "Conformance Packs", desc: "A collection of AWS Config rules and optional remediation actions that can be deployed as a single entity to establish a common, organization-wide baseline for security, operational governance, or industry-specific compliance frameworks (e.g., HIPAA, PCI DSS)." },
                    { title: "Change Tracking & Notifications", desc: "Sends notifications via Amazon SNS (Simple Notification Service) when resource configurations change or when a resource violates an AWS Config Rule. This allows for real-time awareness of configuration drift and non-compliance." },
                    { title: "Resource Relationships & Inventory", desc: "Discovers and maps relationships between AWS resources (e.g., an EC2 instance associated with a specific security group and VPC). It also builds and maintains an inventory of all your AWS resources, which is crucial for asset management and understanding your environment." }
                ],
                examples: [
                    "Setting up an AWS Config rule to ensure that all newly created S3 buckets are launched with server-side encryption enabled and are not publicly accessible. If a bucket is found public, a remediation Lambda function can automatically make it private.",
                    "Auditing historical changes to a critical Amazon EC2 security group to determine when a specific inbound port (e.g., port 22 for SSH) was opened, by whom, and from what IP address, for security forensics.",
                    "Deploying a Conformance Pack to multiple AWS accounts within an organization to enforce a baseline set of security and operational best practices related to IAM, S3, VPC, and EC2 across all environments.",
                    "An operations team uses AWS Config to continuously monitor for configuration drift on their production EC2 instances, ensuring they remain compliant with the approved baseline."
                ],
                technicalDetails: "AWS Config continuously records configuration changes by reacting to AWS API calls (via CloudTrail) and periodic scans. It triggers evaluation against defined rules, sending findings to AWS Security Hub and notifications via SNS. Configuration history is stored in an S3 bucket. Config is a foundational service for cloud governance, compliance, and security posture management in AWS.",
                tools: "AWS Config (Rules, Conformance Packs, Recorder), AWS CloudTrail, Amazon S3, AWS Lambda (for custom rules and remediation), AWS Security Hub (for findings aggregation), AWS Systems Manager (State Manager for remediation)."
            }
        };

        let currentActiveBranch = null; // Tracks the currently active main branch

        /**
         * Toggles the visibility of sub-services (categories) within a main branch.
         * Closes other open branches when a new one is opened.
         * @param {string} branchId - The ID of the branch element to toggle.
         */
        function toggleBranch(branchId) {
            const subServices = document.getElementById(branchId);
            // If there's an active branch and it's not the one just clicked, close it
            if (currentActiveBranch && currentActiveBranch !== subServices) {
                currentActiveBranch.classList.remove('active');
            }
            // Toggle the 'active' class for the clicked branch's sub-services
            subServices.classList.toggle('active');
            // Update the currentActiveBranch variable
            currentActiveBranch = subServices.classList.contains('active') ? subServices : null;
        }

        /**
         * Displays the detailed information about a DevOps category/AWS service in a modal.
         * @param {string} categoryId - The ID of the category to display.
         * @param {string} initialFeatureTitle - Optional: The title of a specific feature to show initially.
         */
        function showCategoryDetails(categoryId, initialFeatureTitle = null) {
            const data = devOpsData[categoryId];
            if (!data) return; // Exit if category data is not found

            const modalContent = document.getElementById('modalContent');
            
            // Store the current category and features for navigation
            modalContent.dataset.currentCategoryId = categoryId;
            modalContent.dataset.features = JSON.stringify(data.features.map(f => f.title));

            // Generate Features HTML with feature-tag and feature-details
            const featuresHtml = data.features.map(feature => `
                <span class="feature-tag" onclick="toggleFeatureDetails('${categoryId}', '${feature.title}')">${feature.title}</span>
            `).join('');

            const featureDetailsHtml = data.features.map((feature, index) => {
                const featureCleanId = feature.title.replace(/[\s\/.-]/g, ''); // Clean ID for direct access
                const howToStepsHtml = feature.howToSteps ? `
                    <div class="how-to-steps">
                        <h3>💡 How-to Steps:</h3>
                        <ol>
                            ${feature.howToSteps.map(step => `<li>${step}</li>`).join('')}
                        </ol>
                    </div>
                ` : ''; // Only render if howToSteps exist

                return `
                    <div id="feature-details-${categoryId}-${featureCleanId}" class="feature-details">
                        <div class="sub-feature">
                            <div class="sub-feature-title">${feature.title}</div>
                            <div class="sub-feature-desc">${feature.desc}</div>
                            ${feature.awsRelevance ? `<p class="feature-nav" style="margin-top:10px;"><strong>AWS Relevance:</strong> ${feature.awsRelevance}</p>` : ''}
                        </div>
                        ${howToStepsHtml} <!-- Include How-to Steps here -->
                        <div class="feature-nav">
                            <button ${index === 0 ? 'disabled' : ''} onclick="navigateFeature('${categoryId}', ${index - 1})">Previous Feature</button>
                            <span>${index + 1} / ${data.features.length}</span>
                            <button ${index === data.features.length - 1 ? 'disabled' : ''} onclick="navigateFeature('${categoryId}', ${index + 1})">Next Feature</button>
                        </div>
                    </div>
                `;
            }).join('');

            // Populate the modal with category details
            modalContent.innerHTML = `
                <h2>${data.name}</h2>
                <p class="category-desc">${data.purpose}</p>
                <div style="display: flex; gap: 10px; margin-top: 10px; flex-wrap: wrap;">
                    <button class="llm-action-button" onclick="summarizeCategoryPurpose('${data.name}', '${data.purpose}', this)">Summarize Purpose ✨</button>
                    <button class="llm-action-button" onclick="generateMoreExamples('${data.name}', '${data.examples.join(', ')}', this)">Suggest More Examples ✨</button>
                    <button class="llm-action-button" onclick="explainTechnicalDetails('${data.name}', '${data.technicalDetails}', this)">Explain Technical Details ✨</button>
                </div>
                <div id="llm-category-output" class="llm-output-area" style="display: none;"></div>
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>🌟 Key Features (click to expand)</h3>
                <div class="features" id="feature-tags-container">
                    ${featuresHtml}
                </div>
                ${featureDetailsHtml}
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>🎯 Examples / Use Cases</h3>
                <div class="scenario-box">
                    <ul class="use-cases-list">
                        ${data.examples.map(example => `<li>${example}</li>`).join('')}
                    </ul>
                </div>
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>💻 Technical Details</h3>
                <div class="tech-stack-list">
                    <p>${data.technicalDetails}</p>
                </div>
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>🛠️ Common Tools</h3>
                <div class="pricing-info-box">
                    <p>${data.tools}</p>
                </div>
            `;
            document.getElementById('categoryModal').style.display = 'block'; // Show the modal

            // Automatically show the first feature details or a specified one
            if (data.features.length > 0) {
                const featureToShow = initialFeatureTitle || data.features[0].title;
                toggleFeatureDetails(categoryId, featureToShow);
            }
        }

        /**
         * Toggles the visibility of specific feature details within the category modal.
         * Ensures only one feature detail section is open at a time.
         * @param {string} categoryId - The ID of the current category.
         * @param {string} featureTitle - The title of the feature to toggle.
         */
        function toggleFeatureDetails(categoryId, featureTitle) {
            // Clean ID for consistency with how it's generated
            const featureCleanId = featureTitle.replace(/[\s\/.-]/g, '');
            const featureId = `feature-details-${categoryId}-${featureCleanId}`;
            const featureDetailsElement = document.getElementById(featureId);

            // Get all feature tags and feature details elements within the current modal
            const allFeatureDetailsInModal = document.querySelectorAll('#modalContent .feature-details');
            const allFeatureTagsInModal = document.querySelectorAll('#modalContent .feature-tag');

            // Deactivate all tags and hide all details initially
            allFeatureTagsInModal.forEach(tag => tag.classList.remove('active-tag'));
            allFeatureDetailsInModal.forEach(element => element.classList.remove('active'));

            // Activate the clicked tag and show its corresponding details
            const clickedTag = document.querySelector(`#feature-tags-container .feature-tag[onclick*="toggleFeatureDetails('${categoryId}', '${featureTitle}')"]`);
            if (clickedTag) {
                clickedTag.classList.add('active-tag');
            }
            if (featureDetailsElement) {
                featureDetailsElement.classList.add('active');
            }
        }

        /**
         * Navigates to the previous or next feature within the currently open category modal.
         * @param {string} categoryId - The ID of the current category.
         * @param {number} newIndex - The index of the feature to navigate to.
         */
        function navigateFeature(categoryId, newIndex) {
            const modalContent = document.getElementById('modalContent');
            const features = JSON.parse(modalContent.dataset.features);

            if (newIndex >= 0 && newIndex < features.length) {
                const newFeatureTitle = features[newIndex];
                toggleFeatureDetails(categoryId, newFeatureTitle);
            }
        }


        /**
         * Closes the category details modal.
         */
        function closeModal() {
            document.getElementById('categoryModal').style.display = 'none';
            // Optionally, clear modal content or reset state when closing
            document.getElementById('modalContent').innerHTML = '';
        }

        // Close modal when clicking outside of it
        window.onclick = function(event) {
            const modal = document.getElementById('categoryModal');
            if (event.target == modal) {
                closeModal(); // Use the existing closeModal function
            }
        }

        // LLM specific functions
        /**
         * Summarizes the given category purpose using the Gemini API.
         * @param {string} categoryName - The name of the DevOps category.
         * @param {string} purpose - The category purpose to summarize.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function summarizeCategoryPurpose(categoryName, purpose, buttonElement) {
            const prompt = `Summarize the purpose of "${categoryName}" in DevOps and AWS concisely in 2-3 sentences:\n\n"${purpose}"`;
            await callGeminiAPI(prompt, 'llm-category-output', buttonElement);
        }

        /**
         * Generates new examples for a given DevOps category/AWS service using the Gemini API.
         * @param {string} categoryName - The name of the DevOps category.
         * @param {string} existingExamples - Comma-separated existing examples.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function generateMoreExamples(categoryName, existingExamples, buttonElement) {
            const prompt = `Given the DevOps/AWS category "${categoryName}" with existing examples: "${existingExamples}", suggest 2-3 additional distinct real-world examples or use cases in bullet point format, specifically highlighting AWS relevance if applicable.`;
            await callGeminiAPI(prompt, 'llm-category-output', buttonElement);
        }

        /**
         * Explains the technical details for a given DevOps category/AWS service using the Gemini API.
         * @param {string} categoryName - The name of the DevOps category.
         * @param {string} technicalDetails - The existing technical details.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function explainTechnicalDetails(categoryName, technicalDetails, buttonElement) {
            const prompt = `Elaborate on the technical details for the DevOps/AWS feature "${categoryName}" based on this information: "${technicalDetails}". Explain how it fundamentally works and any relevant underlying technologies or concepts. Keep it concise (3-5 sentences), focusing on AWS where relevant.`;
            await callGeminiAPI(prompt, 'llm-category-output', buttonElement);
        }

        /**
         * Calls the Gemini API with a given prompt and displays the response.
         * @param {string} prompt - The text prompt to send to the LLM.
         * @param {string} outputElementId - The ID of the HTML element where the response should be displayed.
         * @param {HTMLElement} buttonElement - The button element that triggered the call, to manage its state.
         */
        async function callGeminiAPI(prompt, outputElementId, buttonElement) {
            const outputElement = document.getElementById(outputElementId);
            const originalButtonText = buttonElement.innerHTML; // Store original button text

            outputElement.style.display = 'block'; // Ensure output area is visible
            outputElement.innerHTML = '<div class="loading-indicator"></div> Loading AI response...'; // Show loading

            buttonElement.disabled = true; // Disable button during API call
            buttonElement.innerHTML = `<div class="loading-indicator"></div> Thinking...`; // Change button text to show loading

            try {
                let chatHistory = [];
                chatHistory.push({ role: "user", parts: [{ text: prompt }] });
                const payload = { contents: chatHistory };
                const apiKey = ""; // Canvas will automatically provide the API key here.
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`HTTP error! status: ${response.status}, message: ${errorText}`);
                }

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    outputElement.innerHTML = text; // Display the response
                } else {
                    outputElement.innerHTML = 'Error: Could not get a valid response from the AI. Unexpected structure.';
                }
            } catch (error) {
                outputElement.innerHTML = `Error: Failed to connect to AI. Details: ${error.message}`;
            } finally {
                buttonElement.innerHTML = originalButtonText; // Restore button text
                buttonElement.disabled = false; // Re-enable button
            }
        }

        /**
         * Fetches and displays the latest DevOps and AWS news using Gemini AI (simulated).
         */
        async function fetchDevOpsNews() {
            const newsOutputElement = document.getElementById('news-list');
            newsOutputElement.innerHTML = '<div class="loading-indicator"></div> Fetching latest DevOps & AWS news via Gemini AI...';

            const prompt = `Find and summarize at least 10 recent news articles (published within the last 3-6 months) related to DevOps and AWS topics (e.g., new AWS DevOps services, best practices, success stories, industry trends, containerization, serverless, IaC). For each article, provide the title, a 1-2 sentence summary, and a placeholder URL. Ensure the summaries are concise and informative.`;
            
            try {
                // Simulate a call to a backend service that would perform the deep search with Gemini/Google Search.
                const simulatedNewsResponse = await new Promise(resolve => {
                    setTimeout(() => {
                        // Dummy data as if returned from a Gemini-powered search backend.
                        const articles = [
                            { title: "AWS Announces New Features for CodeCatalyst to Streamline DevOps", summary: "Amazon Web Services has unveiled several enhancements to CodeCatalyst, their unified software development service, aiming to simplify DevOps workflows for developers.", url: "https://example.com/aws-codecatalyst-updates" },
                            { title: "Serverless First: Adopting DevOps Best Practices for AWS Lambda", summary: "A recent case study highlights how a company achieved faster deployments and reduced operational overhead by applying DevOps principles specifically tailored for AWS Lambda functions.", url: "https://example.com/serverless-devops-aws" },
                            { title: "Terraform Cloud Integrates Deeper with AWS for IaC Management", summary: "HashiCorp has announced deeper integrations for Terraform Cloud with AWS, offering enhanced capabilities for managing infrastructure as code deployments across AWS accounts.", url: "https://example.com/terraform-aws-integration" },
                            { title: "DevOps Institute Report Shows Continued Growth in SRE Roles", summary: "The annual DevOps Institute report indicates a strong demand and growth in Site Reliability Engineering (SRE) roles, emphasizing the critical need for operations expertise in DevOps teams.", url: "https://example.com/sre-growth-devops" },
                            { title: "Optimizing Container Workloads on Amazon EKS with FinOps Principles", summary: "New guidance released on applying FinOps practices to Amazon EKS, enabling organizations to optimize cost efficiency for their Kubernetes container deployments on AWS.", url: "https://example.com/eks-finops" },
                            { title: "AWS re:Invent 2024: Key DevOps Announcements and Innovations", summary: "A recap of the most impactful DevOps-related announcements from AWS re:Invent 2024, including new services and updates for CI/CD, monitoring, and security.", url: "https://example.com/reinvent-devops-recap" },
                            { title: "Shift-Left Security: Integrating SAST and DAST in AWS Pipelines", summary: "Best practices emerge for embedding Static (SAST) and Dynamic (DAST) Application Security Testing directly into AWS CodePipeline and CodeBuild workflows for earlier vulnerability detection.", url: "https://example.com/shift-left-security-aws" },
                            { title: "Observability as Code: Managing AWS CloudWatch and X-Ray with IaC", summary: "Engineers are increasingly defining their monitoring and observability configurations for AWS CloudWatch and X-Ray as code, treating them like any other infrastructure component for consistency and automation.", url: "https://example.com/observability-as-code" },
                            { title: "The Rise of Platform Engineering in Cloud-Native DevOps", summary: "A trend towards Platform Engineering is accelerating, where dedicated teams build internal developer platforms to empower feature teams and standardize cloud-native DevOps practices.", url: "https://example.com/platform-engineering" },
                            { title: "AWS Lambda Enhancements for Faster Cold Starts and Increased Concurrency", summary: "Recent updates to AWS Lambda promise significant improvements in cold start times and enhanced concurrency controls, further boosting its appeal for serverless application development.", url: "https://example.com/lambda-cold-starts" }
                        ];
                        resolve({ articles });
                    }, 1500); // Simulate 1.5 second network delay
                });

                if (simulatedNewsResponse.articles && simulatedNewsResponse.articles.length > 0) {
                    newsOutputElement.innerHTML = simulatedNewsResponse.articles.map(article => `
                        <li class="news-item">
                            <h3><a href="${article.url}" target="_blank">${article.title}</a></h3>
                            <p>${article.summary}</p>
                            <p style="font-size: 0.75rem; color: #ccc;">Source: ${article.source || 'Various'} | Published: ${article.date || 'Recent'}</p>
                        </li>
                    `).join('');
                } else {
                    newsOutputElement.innerHTML = '<p>No DevOps & AWS news found at this time. Please try again later.</p>';
                }
            } catch (error) {
                newsOutputElement.innerHTML = `<p style="color: #ffcccc;">Error fetching news: ${error.message}. Displaying placeholder data.</p>`;
            }
        }

        /**
         * Performs a search using Gemini AI and displays the result in the floating search area.
         */
        async function performAISearch() {
            const searchInput = document.getElementById('ai-search-input');
            const searchOutput = document.getElementById('ai-search-output');
            const searchButton = document.getElementById('ai-search-button');
            const userQuery = searchInput.value.trim();

            if (!userQuery) {
                searchOutput.innerHTML = '<p style="color: #ffcccc;">Please enter a search query.</p>';
                searchOutput.style.display = 'block';
                return;
            }

            const prompt = `As a concise AI search assistant focused *only* on DevOps and AWS topics (e.g., CI/CD, IaC, monitoring, containerization, serverless, specific AWS services like CodePipeline, CloudWatch, Lambda, EC2), provide a relevant and helpful answer to the following query: "${userQuery}". Keep the answer to a maximum of 3-4 sentences. If the query is outside the scope of DevOps or AWS, state that politely.`;
            await callGeminiAPI(prompt, 'ai-search-output', searchButton);
        }

        // Draggable functionality for the floating search bar
        let isDragging = false;
        let offset = { x: 0, y: 0 };
        const floatingSearchElement = document.getElementById('floatingAISearch');

        floatingSearchElement.addEventListener('mousedown', (e) => {
            // Only start dragging if the bar is not expanded or if the click is on the toggle button itself
            if (!floatingSearchElement.classList.contains('expanded') || e.target.closest('.search-toggle-button')) {
                isDragging = true;
                offset = {
                    x: e.clientX - floatingSearchElement.getBoundingClientRect().left,
                    y: e.clientY - floatingSearchElement.getBoundingClientRect().top
                };
                floatingSearchElement.style.cursor = 'grabbing';
            }
        });

        document.addEventListener('mousemove', (e) => {
            if (!isDragging) return;

            // Calculate new position
            let newX = e.clientX - offset.x;
            let newY = e.clientY - offset.y;

            // Get viewport dimensions to constrain dragging
            const viewportWidth = window.innerWidth;
            const viewportHeight = window.innerHeight;
            const elementWidth = floatingSearchElement.offsetWidth;
            const elementHeight = floatingSearchElement.offsetHeight;

            // Constrain newX to stay within viewport bounds
            newX = Math.max(0, Math.min(newX, viewportWidth - elementWidth));
            // Constrain newY to stay within viewport bounds
            newY = Math.max(0, Math.min(newY, viewportHeight - elementHeight));

            // Set position using left/top (overriding right/bottom)
            floatingSearchElement.style.left = `${newX}px`;
            floatingSearchElement.style.top = `${newY}px`;
            floatingSearchElement.style.right = 'auto'; // Disable right/bottom positioning when dragging via left/top
            floatingSearchElement.style.bottom = 'auto';
        });

        document.addEventListener('mouseup', () => {
            isDragging = false;
            floatingSearchElement.style.cursor = floatingSearchElement.classList.contains('expanded') ? 'auto' : 'grab';
        });

        /**
         * Toggles the visibility and expanded state of the floating AI search bar.
         * Also handles dynamic positioning (left/right) based on current location.
         */
        function toggleFloatingSearch() {
            const floatingSearch = document.getElementById('floatingAISearch');
            const searchIcon = document.getElementById('searchIcon');

            // Get current position before toggling the class
            const currentLeft = floatingSearch.getBoundingClientRect().left;
            const viewportWidth = window.innerWidth;

            floatingSearch.classList.toggle('expanded');

            if (floatingSearch.classList.contains('expanded')) {
                searchIcon.textContent = '✖'; // Change icon to close
                document.getElementById('ai-search-input').focus(); // Focus on input when expanded

                // Determine whether to open to the left or right
                if (currentLeft > (viewportWidth / 2)) {
                    // It's on the right half, open to the left
                    floatingSearch.style.right = '20px';
                    floatingSearch.style.left = 'auto'; // Ensure left is auto
                } else {
                    // It's on the left half, open to the right
                    floatingSearch.style.left = '20px';
                    floatingSearch.style.right = 'auto'; // Ensure right is auto
                }
                // Ensure top is maintained or set if not dragged
                if (floatingSearch.style.top === 'auto' || floatingSearch.style.top === '') {
                    floatingSearch.style.bottom = '20px';
                    floatingSearch.style.top = 'auto';
                }

            } else {
                searchIcon.textContent = '✨'; // Change icon to default
                document.getElementById('ai-search-output').style.display = 'none'; // Hide output when collapsed
                document.getElementById('ai-search-output').innerHTML = ''; // Clear output when collapsed
                document.getElementById('ai-search-input').value = ''; // Clear input when collapsed

                // Reset position to default bottom-right on collapse
                floatingSearch.style.right = '20px';
                floatingSearch.style.bottom = '20px';
                floatingSearch.style.left = 'auto';
                floatingSearch.style.top = 'auto';
            }
        }

        // Initialize fetching news on page load
        document.addEventListener('DOMContentLoaded', fetchDevOpsNews);

        // Remove onclick from central node as it does nothing in this version
        document.querySelector('.central-node').onclick = null;
    </script>
</body>
</html>
