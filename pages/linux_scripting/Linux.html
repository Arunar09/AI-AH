<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Linux System Administration Mindmap</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    <style>
        /* General Reset */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Inter', sans-serif; /* Using Inter font */
            border-radius: 8px; /* Applying rounded corners to all elements */
        }

        /* Body Styles */
        body {
            background: linear-gradient(135deg, #1A202C 0%, #2D3748 50%, #4A5568 100%); /* Dark blue-gray gradient for Linux */
            min-height: 100vh;
            padding: 20px;
            color: white;
            display: flex;
            flex-direction: column;
            gap: 30px;
            align-items: center;
        }

        /* Container for overall layout */
        .container {
            max-width: 1400px;
            margin: 0 auto;
            width: 100%;
        }

        /* Main Heading */
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.8rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            color: #68D391; /* Light green accent for Linux */
        }

        /* Mindmap Layout */
        .mindmap {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 30px;
            width: 100%;
        }

        /* Central Node */
        .central-node {
            background: linear-gradient(45deg, #68D391, #48BB78); /* Linux Green gradient */
            padding: 20px 40px;
            border-radius: 50px;
            font-size: 1.5rem;
            font-weight: bold;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            cursor: pointer;
            transform: scale(1);
            transition: all 0.3s ease;
        }

        .central-node:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(0,0,0,0.4);
        }

        /* Main Branches Grid Layout */
        .main-branches {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            width: 100%;
        }

        /* Individual Branch Styles */
        .branch {
            background: rgba(255,255,255,0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255,255,255,0.2);
            padding: 25px;
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .branch:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.15);
            box-shadow: 0 15px 40px rgba(0,0,0,0.2);
        }

        .branch-header {
            font-size: 1.3rem;
            font-weight: bold;
            margin-bottom: 15px;
            color: #9F7AEA; /* Purple accent for Linux */
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .branch-icon {
            font-size: 1.5rem;
        }

        /* Sub-services (initially hidden) */
        .sub-services {
            display: none;
            animation: fadeIn 0.3s ease;
        }

        .sub-services.active {
            display: block;
        }

        /* Fade-in animation for sub-services */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Individual Service Item Styles (now category-item) */
        .category-item {
            background: rgba(0,0,0,0.2);
            margin: 10px 0;
            padding: 15px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .category-item:hover {
            background: rgba(0,0,0,0.3);
            transform: translateX(10px);
        }

        .category-name {
            font-weight: bold;
            color: #F6E05E; /* Yellow accent */
            margin-bottom: 5px;
        }

        .category-desc {
            font-size: 0.9rem;
            color: #e0e0e0;
            margin-bottom: 10px;
        }

        /* Feature Tag Styles within modal */
        .feature-tag {
            display: inline-block;
            /* Original: background: #68D391; */
            background: linear-gradient(to right, #805AD5, #6B46C1); /* Non-radiating purple gradient */
            color: white;
            padding: 3px 8px;
            margin: 2px;
            font-size: 0.8rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .feature-tag:hover {
            /* Original: background: #48BB78; */
            background: linear-gradient(to right, #6B46C1, #553C9A); /* Darker purple gradient on hover */
            transform: scale(1.05);
        }

        /* Feature Details (initially hidden, expands on click) */
        .feature-details {
            display: none;
            margin-top: 15px;
            padding: 15px;
            background: rgba(0,0,0,0.4);
            border-left: 4px solid #68D391; /* Linux Green accent */
        }

        .feature-details.active {
            display: block;
            animation: slideDown 0.3s ease;
        }

        /* Slide-down animation for feature details */
        @keyframes slideDown {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        /* Sub-feature styles within details */
        .sub-feature {
            background: rgba(255,255,255,0.1);
            margin: 8px 0;
            padding: 10px;
            border-left: 3px solid #9F7AEA; /* Purple accent */
        }

        .sub-feature-title {
            font-weight: bold;
            color: #9F7AEA; /* Purple accent */
            margin-bottom: 5px;
        }

        .sub-feature-desc {
            font-size: 0.9rem;
            color: #e0e0e0;
            line-height: 1.4;
        }

        /* How-to Steps specific styling */
        .how-to-steps {
            background: rgba(0,0,0,0.2);
            padding: 15px;
            margin-top: 15px;
            border-radius: 8px;
        }
        .how-to-steps ol {
            list-style-type: decimal;
            margin-left: 20px;
        }
        .how-to-steps li {
            margin-bottom: 8px;
            font-size: 0.9rem;
            color: #e0e0e0;
            line-height: 1.5;
        }
        .how-to-steps li strong {
            color: #F6E05E; /* Yellow accent for emphasis in steps */
        }

        .feature-nav {
            text-align: center; /* Center the navigation links */
            margin: 15px 0 0; /* Add margin to the top, none to bottom */
            font-size: 0.9rem;
            color: #fff; /* White for better contrast */
            display: flex; /* Use flexbox for spacing */
            justify-content: space-between; /* Space out the next/previous buttons */
            align-items: center;
        }
        .feature-nav strong {
            color: #A3BFDF; /* Light blue accent for strong text */
        }
        .feature-nav button {
            background-color: #9F7AEA; /* Purple accent */
            color: white;
            border: none;
            padding: 5px 10px;
            cursor: pointer;
            border-radius: 4px;
            transition: background-color 0.2s ease;
        }
        .feature-nav button:hover {
            background-color: #805AD5;
        }
        .feature-nav button:disabled {
            background-color: #555;
            cursor: not-allowed;
            opacity: 0.7;
        }

        .use-cases-list { /* Renamed for clarity */
            margin-top: 10px;
            font-size: 0.85rem;
            color: #F6AD55; /* Orange accent */
            list-style: disc;
            margin-left: 20px;
        }
        .use-cases-list li {
            margin-bottom: 5px;
        }


        /* Modal Overlay */
        .modal {
            display: none;
            position: fixed;
            z-index: 1000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.8);
            animation: fadeIn 0.3s ease;
            overflow-y: auto; /* Allow scrolling for modal content */
        }

        /* Modal Content Box */
        .modal-content {
            background: linear-gradient(135deg, #1A202C 0%, #2D3748 100%); /* Consistent with body background */
            margin: 5% auto;
            padding: 30px;
            width: 90%;
            max-width: 800px;
            max-height: 90vh; /* Max height to prevent overflow */
            overflow-y: auto; /* Ensure scrollability within modal */
            box-shadow: 0 20px 60px rgba(0,0,0,0.5);
            border-radius: 12px;
        }

        /* Close Button for Modal */
        .close {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
        }

        .close:hover {
            color: white;
        }

        /* Sections within the modal */
        .tech-stack-list, .interdependencies-list, .config-options { /* Renamed for clarity */
            background: rgba(0,0,0,0.2);
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
        }
        .tech-stack-list ul, .interdependencies-list ul, .config-options ul {
            list-style: disc;
            margin-left: 20px;
            padding-left: 0;
        }

        .pricing-info-box { /* Renamed for clarity */
            background: rgba(129, 140, 248, 0.2); /* Light blue from Tailwind indigo-200 */
            padding: 10px;
            margin: 10px 0;
            font-size: 0.9rem;
            border-radius: 8px;
        }

        .scenario-box {
            background: rgba(104, 211, 145, 0.2); /* Light green from Tailwind green-300 */
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
        }
        
        .config-options li {
            margin-bottom: 5px;
        }

        .llm-action-button {
            /* Original: background-color: #68D391; */
            background: linear-gradient(to right, #5A67D8, #4C51BF); /* Non-radiating blue/indigo gradient */
            color: white;
            border: none;
            padding: 8px 12px;
            cursor: pointer;
            font-size: 0.9rem;
            margin-top: 10px;
            margin-right: 10px;
            transition: background-color 0.3s ease;
            border-radius: 6px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }

        .llm-action-button:hover {
            /* Original: background-color: #48BB78; */
            background: linear-gradient(to right, #4C51BF, #3E3E8C); /* Darker blue/indigo gradient on hover */
            transform: translateY(-1px);
        }

        .llm-output-area {
            background: rgba(0,0,0,0.3);
            padding: 15px;
            margin-top: 20px;
            border: 1px solid rgba(255,255,255,0.2);
            min-height: 50px;
            font-size: 0.95rem;
            line-height: 1.5;
            white-space: pre-wrap;
            word-wrap: break-word;
            display: none; /* Hidden by default */
            border-radius: 8px;
        }

        .loading-indicator {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top-color: #68D391; /* Linux Green accent */
            animation: spin 1s ease-in-out infinite;
            -webkit-animation: spin 1s ease-in-out infinite;
            margin-left: 10px;
            vertical-align: middle;
        }

        @keyframes spin {
            to { -webkit-transform: rotate(360deg); }
        }
        @-webkit-animation {
            to { -webkit-transform: rotate(360deg); }
        }

        /* Floating Search Bar Styles */
        .floating-search-container {
            position: fixed;
            bottom: 20px;
            right: 20px; /* Default position */
            z-index: 1001;
            background: linear-gradient(135deg, #2D3748 0%, #4A5568 100%);
            padding: 10px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.5);
            transition: all 0.3s ease-in-out;
            opacity: 0.8;
            width: 60px;
            height: 60px;
            display: flex;
            justify-content: center;
            align-items: center;
            border: 1px solid rgba(255,255,255,0.2);
            cursor: grab;
            border-radius: 50%; /* Make it round */
        }

        .floating-search-container:hover {
            opacity: 1;
        }

        .floating-search-container.expanded {
            width: 350px;
            height: auto;
            opacity: 1;
            flex-direction: column;
            align-items: flex-start;
            padding: 20px;
            cursor: auto;
            border-radius: 8px; /* Square when expanded */
        }

        .search-toggle-button {
            background-color: #68D391; /* Linux Green accent */
            color: white;
            border: none;
            width: 40px;
            height: 40px;
            font-size: 1.5rem;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            transition: background-color 0.3s ease;
            border-radius: 50%; /* Always round */
        }

        .search-toggle-button:hover {
            background-color: #48BB78;
        }

        .floating-search-content {
            display: none;
            width: 100%;
        }

        .floating-search-container.expanded .floating-search-content {
            display: block;
        }

        .floating-search-content .search-bar-container {
            display: flex;
            gap: 10px;
            margin-bottom: 10px;
            flex-direction: column;
        }
        
        .floating-search-content .search-bar-container input[type="text"] {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid rgba(255,255,255,0.3);
            background-color: rgba(0,0,0,0.3);
            color: white;
            font-size: 1rem;
            width: 100%;
            border-radius: 6px;
        }

        .floating-search-content .search-bar-container button {
            padding: 10px 20px;
            background-color: #9F7AEA; /* Purple accent */
            color: white;
            border: none;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s ease;
            width: 100%;
            border-radius: 6px;
        }

        .floating-search-content .search-bar-container button:hover {
            background-color: #805AD5;
        }

        /* Close button for expanded search */
        .floating-search-close {
            color: #aaa;
            align-self: flex-end;
            font-size: 24px;
            font-weight: bold;
            cursor: pointer;
            margin-bottom: 10px;
            display: none;
        }

        .floating-search-container.expanded .floating-search-close {
            display: block;
        }

        .floating-search-close:hover {
            color: white;
        }

        /* Responsive Adjustments */
        @media (max-width: 768px) {
            .main-branches {
                grid-template-columns: 1fr;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .modal-content {
                width: 95%;
                margin: 10% auto;
                padding: 20px;
            }
            .floating-search-container.expanded {
                width: 90%;
                right: 5%;
                bottom: 10%;
            }
            .floating-search-content .search-bar-container {
                flex-direction: column;
            }
            .news-section {
                padding: 15px;
            }
            .central-node {
                font-size: 1.2rem;
                padding: 15px 30px;
            }
            .branch-header {
                font-size: 1.1rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🐧 Linux System Administration Mindmap</h1>
        
        <div class="mindmap">
            <div class="central-node">
                Mastering the Linux OS
            </div>
            	 
	<!-- Back to Landing Page Button -->
    <a href="../../index.html" class="fixed top-4 left-4 z-50 bg-purple-700 text-white py-2 px-4 rounded-lg shadow-lg hover:bg-purple-800 transition duration-300 ease-in-out text-lg font-bold">
        &larr; Back to Hub
    </a>
	
            <div class="main-branches">
                <!-- Core Linux Concepts -->
                <div class="branch" onclick="toggleBranch('core-linux-concepts')">
                    <div class="branch-header">
                        <span class="branch-icon">🐧</span>
                        Core Linux Concepts
                    </div>
                    <div id="core-linux-concepts" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('file-system')">
                            <div class="category-name">File System Hierarchy (FHS)</div>
                            <div class="category-desc">Standard directory structure.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('shell-commands')">
                            <div class="category-name">Shell & Basic Commands</div>
                            <div class="category-desc">Interacting with the system.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('text-editors')">
                            <div class="category-name">Text Editors (Vim, Nano)</div>
                            <div class="category-desc">Essential for configuration.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('boot-process')">
                            <div class="category-name">Boot Process & Init Systems</div>
                            <div class="category-desc">Understanding system startup.</div>
                        </div>
                    </div>
                </div>

                <!-- User & File Management -->
                <div class="branch" onclick="toggleBranch('user-file-management')">
                    <div class="branch-header">
                        <span class="branch-icon">👤</span>
                        User & File Management
                    </div>
                    <div id="user-file-management" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('user-groups')">
                            <div class="category-name">Users & Groups</div>
                            <div class="category-desc">Managing access and permissions.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('file-permissions')">
                            <div class="category-name">File Permissions (chmod, chown)</div>
                            <div class="category-desc">Controlling file access.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('sudo')">
                            <div class="category-name">Sudo & Privilege Escalation</div>
                            <div class="category-desc">Executing commands as root.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('directory-operations')">
                            <div class="category-name">Directory Operations (mkdir, rm, mv)</div>
                            <div class="category-desc">Working with directories.</div>
                        </div>
                    </div>
                </div>

                <!-- Process & Service Management -->
                <div class="branch" onclick="toggleBranch('process-service-management')">
                    <div class="branch-header">
                        <span class="branch-icon">⚙️</span>
                        Process & Service Management
                    </div>
                    <div id="process-service-management" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('process-monitoring')">
                            <div class="category-name">Process Monitoring (top, htop, ps)</div>
                            <div class="category-desc">Viewing and managing running processes.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('service-management')">
                            <div class="category-name">Service Management (systemd, service)</div>
                            <div class="category-desc">Controlling background services.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('logging-management')">
                            <div class="category-name">Logging (Syslog, Journald)</div>
                            <div class="category-desc">System and application logs.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('scheduling-tasks')">
                            <div class="category-name">Scheduling Tasks (Cron, At)</div>
                            <div class="category-desc">Automating repetitive jobs.</div>
                        </div>
                    </div>
                </div>

                <!-- Networking -->
                <div class="branch" onclick="toggleBranch('networking')">
                    <div class="branch-header">
                        <span class="branch-icon">🌐</span>
                        Networking
                    </div>
                    <div id="networking" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('network-interfaces')">
                            <div class="category-name">Network Interface Configuration (ip, ifconfig)</div>
                            <div class="category-desc">Setting up network connections.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('dns-config')">
                            <div class="category-name">DNS Configuration</div>
                            <div class="category-desc">Resolving domain names.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('ssh')">
                            <div class="category-name">SSH (Secure Shell)</div>
                            <div class="category-desc">Secure remote access.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('firewall-linux')">
                            <div class="category-name">Firewall (iptables, ufw, firewalld)</div>
                            <div class="category-desc">Controlling network access.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('network-troubleshooting')">
                            <div class="category-name">Network Troubleshooting (ping, traceroute, netstat)</div>
                            <div class="category-desc">Diagnosing connectivity issues.</div>
                        </div>
                    </div>
                </div>

                <!-- Software Management -->
                <div class="branch" onclick="toggleBranch('software-management')">
                    <div class="branch-header">
                        <span class="branch-icon">📦</span>
                        Software Management
                    </div>
                    <div id="software-management" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('package-managers')">
                            <div class="category-name">Package Managers (APT, YUM/DNF)</div>
                            <div class="category-desc">Installing and managing software.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('compiling-from-source')">
                            <div class="category-name">Compiling from Source</div>
                            <div class="category-desc">Installing software manually.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('containerization-linux')">
                            <div class="category-name">Containerization (Docker)</div>
                            <div class="category-desc">Packaging and running isolated apps.</div>
                        </div>
                    </div>
                </div>

                <!-- Storage & Filesystems -->
                <div class="branch" onclick="toggleBranch('storage-filesystems')">
                    <div class="branch-header">
                        <span class="branch-icon">🗄️</span>
                        Storage & Filesystems
                    </div>
                    <div id="storage-filesystems" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('disk-management')">
                            <div class="category-name">Disk Management (fdisk, parted)</div>
                            <div class="category-desc">Partitioning and formatting disks.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('filesystem-types')">
                            <div class="category-name">Filesystem Types (ext4, XFS)</div>
                            <div class="category-desc">Understanding common filesystems.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('mounting-filesystems')">
                            <div class="category-name">Mounting & Unmounting</div>
                            <div class="category-desc">Accessing storage devices.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('raid-lvm')">
                            <div class="category-name">RAID & LVM</div>
                            <div class="category-desc">Advanced storage configurations.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('backup-restore')">
                            <div class="category-name">Backup & Restore (tar, rsync)</div>
                            <div class="category-desc">Protecting data.</div>
                        </div>
                    </div>
                </div>

                <!-- Security Hardening -->
                <div class="branch" onclick="toggleBranch('security-hardening')">
                    <div class="branch-header">
                        <span class="branch-icon">🔒</span>
                        Security Hardening
                    </div>
                    <div id="security-hardening" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('os-hardening')">
                            <div class="category-name">OS Hardening (CIS Benchmarks)</div>
                            <div class="category-desc">Securing the Linux operating system.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('ssh-hardening')">
                            <div class="category-name">SSH Hardening</div>
                            <div class="category-desc">Securing remote access.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('selinux-apparmor')">
                            <div class="category-name">SELinux & AppArmor</div>
                            <div class="category-desc">Mandatory Access Control (MAC).</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('vulnerability-scanning')">
                            <div class="category-name">Vulnerability Scanning (Nessus, OpenVAS)</div>
                            <div class="category-desc">Identifying security weaknesses.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('audit-d')">
                            <div class="category-name">Auditd & System Auditing</div>
                            <div class="category-desc">Monitoring system calls and events.</div>
                        </div>
                    </div>
                </div>

                <!-- Automation & Scripting -->
                <div class="branch" onclick="toggleBranch('automation-scripting')">
                    <div class="branch-header">
                        <span class="branch-icon">🤖</span>
                        Automation & Scripting
                    </div>
                    <div id="automation-scripting" class="sub-services">
                        <div class="category-item" onclick="showCategoryDetails('bash-scripting')">
                            <div class="category-name">Bash Scripting</div>
                            <div class="category-desc">Automating tasks with shell scripts.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('ansible')">
                            <div class="category-name">Ansible (Configuration Management)</div>
                            <div class="category-desc">Automating server configuration.</div>
                        </div>
                        <div class="category-item" onclick="showCategoryDetails('python-automation')">
                            <div class="category-name">Python for Automation</div>
                            <div class="category-desc">Scripting for complex tasks.</div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Category Details Modal -->
    <div id="categoryModal" class="modal">
        <div class="modal-content">
            <span class="close" onclick="closeModal()">&times;</span>
            <div id="modalContent"></div>
        </div>
    </div>

    <!-- Floating AI Search Bar -->
    <div id="floatingAISearch" class="floating-search-container">
        <button class="search-toggle-button" onclick="toggleFloatingSearch()">
            <span id="searchIcon">🔍</span>
        </button>
        <div class="floating-search-content">
            <span class="floating-search-close" onclick="toggleFloatingSearch()">&times;</span>
            <div class="search-bar-container">
                <input type="text" id="ai-search-input" placeholder="Ask Gemini AI about Linux SysAdmin...">
                <button id="ai-search-button" onclick="performAISearch()">Search with AI ✨</button>
            </div>
            <div id="ai-search-output" class="llm-output-area">
                <!-- Search results will appear here -->
            </div>
        </div>
    </div>

    <script>
        // Data structure containing details for each Linux System Administration category
        const linuxSysAdminData = {
            'file-system': {
                name: "File System Hierarchy (FHS)",
                purpose: "To provide a standardized directory structure on Linux and Unix-like operating systems, ensuring consistent placement of files and directories across different distributions. This helps administrators and applications locate files predictably. Without it, you'd have a mess.",
                features: [
                    { title: "/ (Root Directory)", desc: "The top-level directory in the Linux file system hierarchy. All other directories and files are located under the root directory. It is analogous to the C:\\ drive in Windows, but don't call it that. This is where everything begins." },
                    { title: "/bin & /usr/bin (User Binaries)", desc: "`/bin` contains essential user command binaries (e.g., `ls`, `cp`, `mv`) required for system startup and for single-user mode. If you can't find it here, your system is broken. `/usr/bin` contains most user commands that are not essential for boot or rescue mode; think of it as the general-purpose executable bin." },
                    { title: "/etc (Host-specific Configuration)", desc: "Contains system-wide configuration files (e.g., network settings, user password files, application configuration). These files are typically text-based and readable, but only writable by root or authorized users. This is where you *really* configure your system. Mess it up at your peril." },
                    { title: "/var (Variable Data)", desc: "Holds variable data files that change frequently during system operation, such as log files (`/var/log`), temporary spool files (`/var/spool`), and dynamic website content (`/var/www/html`). If you're looking for logs, this is where they live. Don't let it fill up your disk." },
                    { title: "/home (User Home Directories)", desc: "Contains personal directories for regular users. Each user typically has a subdirectory here (e.g., `/home/username`) where they store their personal files, configurations, and documents. Users put their junk here; keep it organized." },
                    { title: "/opt (Optional Application Software)", desc: "Used for installing optional software packages that are not part of the standard system distribution. This is often where third-party or proprietary software is installed in a self-contained manner. For large, self-contained apps, this is your spot." },
                    { title: "/proc (Process Information Pseudo-filesystem)", desc: "A virtual filesystem providing an interface to kernel data structures. It's not stored on disk but is dynamically generated, offering real-time information about processes, system configuration, and kernel parameters. If you want to understand what the kernel is *really* doing, look here. It's your window into the running system." },
                    { title: "/sys (System Information Pseudo-filesystem)", desc: "Another virtual filesystem exposing kernel objects, drivers, and device information. Used for interacting with hardware and kernel components dynamically. Similar to `/proc`, but more focused on devices and kernel configurations. Don't touch unless you know what you're doing." }
                ],
                examples: [
                    "Checking system logs in `/var/log` for recent errors: `tail -f /var/log/syslog` (Debian/Ubuntu) or `journalctl -f` (systemd-based).",
                    "Modifying network configuration by editing a file in `/etc/network/interfaces` or `/etc/sysconfig/network-scripts`.",
                    "Installing a new application to `/opt/my_app` to keep it separate from system binaries and libraries.",
                    "Navigating to your home directory to find your personal `.bashrc` file: `cd ~` or `cd /home/yourusername`.",
                    "Peeking into CPU information: `cat /proc/cpuinfo`.",
                    "Adjusting a kernel parameter: `echo 1 > /proc/sys/net/ipv4/ip_forward` (for temporary changes, use `sysctl` for persistent)."
                ],
                technicalDetails: "The FHS, or Filesystem Hierarchy Standard, is less a 'standard' and more a 'convention that everyone agrees to follow, mostly.' It's crucial because it enables consistent tooling and development across different Linux distributions. The separation (e.g., `/usr` containing shareable, read-only data vs. `/etc` for host-specific configs) is a design choice rooted in Unix philosophy for modularity and system recovery. Virtual filesystems like `/proc` and `/sys` are runtime interfaces to the kernel's inner workings; they don't consume disk space, they just reflect live data. Understand this, and you'll understand Linux.",
                tools: "ls, cd, pwd, find, tree, man fhs, cat, echo, sysctl"
            },
            'shell-commands': {
                name: "Shell & Basic Commands",
                purpose: "To provide the primary interface for users to interact with the Linux operating system. The shell interprets commands entered by the user and executes them, allowing for system administration, scripting, and application execution. If you can't use the CLI, you're not a real sysadmin.",
                features: [
                    { title: "Bash (Bourne Again SHell)", desc: "The most common default shell on Linux distributions. It offers command-line editing, history, tab completion, scripting capabilities, and various built-in commands. It's highly versatile for both interactive use and automation. Learn it, live it, love it. Or suffer." },
                    { title: "Command Line Interface (CLI)", desc: "A text-based interface used to operate software and operating systems by typing commands. It offers precise control, is highly efficient for automation, and consumes minimal system resources compared to graphical user interfaces (GUIs). GUIs are for n00bs, the CLI is where the real power is." },
                    { title: "Input/Output Redirection", desc: "Allows changing where a command reads its input from (standard input - stdin) or sends its output to (standard output - stdout, standard error - stderr). Operators like `>`, `>>`, `2>`, `&>`, and `<` are used to redirect output to files, append to files, redirect errors, or read input from files. Master this, and you can connect anything to anything." },
                    { title: "Piping (`|`)", desc: "Connects the standard output of one command to the standard input of another command. This enables building complex operations by chaining multiple simpler commands together, where the output of one becomes the input for the next (e.g., `ls -l | grep .txt`). This is the *essence* of Unix philosophy: small tools doing one thing well, chained together to do big things. Don't re-invent the wheel; pipe it!" },
                    { title: "Wildcards (`*`, `?`, `[]`)", desc: "Special characters used in shell commands to match patterns in filenames or paths. `*` matches zero or more characters, `?` matches a single character, and `[]` matches any single character within a specified set. Useful for selecting multiple files. Don't be lazy, use them correctly, or you'll delete the wrong things." },
                    { title: "Environment Variables", desc: "Dynamic named values that affect the way processes run on a computer. They provide information to the shell and processes about the environment, such as the `PATH` (directories to search for executables), `HOME` (user's home directory), and `USER`. Crucial for understanding how processes find things and where they store stuff. `export` is your friend." }
                ],
                examples: [
                    "Listing files in a directory: `ls -l /etc`.",
                    "Copying a file: `cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bak`.",
                    "Searching for a string in a file: `grep 'Error' /var/log/syslog`.",
                    "Creating a new file: `touch myfile.txt`.",
                    "Viewing the first 10 lines of a file: `head /var/log/messages`.",
                    "Piping `ls -l` output to `grep` to find only `.log` files: `ls -l | grep '.log$'`.",
                    "Redirecting output and errors to a single file: `mycommand > output.log 2>&1`."
                ],
                technicalDetails: "The shell isn't just a fancy prompt; it's a powerful programming environment. When you type a command, the shell first checks if it's a built-in. If not, it searches your `PATH` environment variable for an executable. It then forks a child process to execute that command. Understanding how process spawning, I/O handles, and environment inheritance work is what separates a user from an administrator. Bash scripting takes these basic commands and turns them into full-fledged automation solutions. Don't underestimate it.",
                tools: "bash, zsh, sh, ls, cp, mv, rm, cd, pwd, cat, less, more, head, tail, grep, find, which, echo, export, wc, sort, uniq, cut, tee."
            },
            'text-editors': {
                name: "Text Editors (Vim, Nano)",
                purpose: "To allow system administrators to create, view, and modify plain text files directly on the command line. These are essential for editing configuration files, scripts, and logs on Linux servers where a graphical interface may not be available or desired. Pick one, master it, or waste your life clicking.",
                features: [
                    { title: "Vim (Vi IMproved)", desc: "A powerful, highly configurable, and efficient text editor known for its modal editing (Normal, Insert, Visual modes). It has a steep learning curve but offers incredible speed and flexibility once mastered, with extensive keyboard shortcuts for navigation and editing. Widely available on almost all Linux systems. Vim is *the* editor for serious work. It's not just an editor; it's a way of life. If you don't know Vim, you're missing out." },
                    { title: "Nano", desc: "A simple, easy-to-use, and beginner-friendly text editor. It displays common commands at the bottom of the screen, making it intuitive for new users. Ideal for quick edits and basic file creation without needing to memorize complex commands. For quick dirty edits, Nano is fine. Don't expect miracles." },
                    { title: "Command-line Interface (CLI) Operation", desc: "Both editors are designed to be used entirely within a terminal, without requiring a graphical desktop environment. This makes them indispensable for remote server management via SSH. No GUI? No problem. This is how you work on a server." },
                    { title: "Syntax Highlighting", desc: "Highlights different parts of the code or configuration file (e.g., keywords, strings, comments) in different colors, improving readability and making it easier to spot syntax errors. Makes your config files readable, a minor but helpful feature." },
                    { title: "Search & Replace", desc: "Allows users to search for specific text patterns within a file and replace them, either interactively or globally. Essential for modifying multiple occurrences of a string in a configuration file. Essential for bulk changes; don't do it manually." },
                    { title: "File Saving & Exiting", desc: "Provide straightforward ways to save changes to a file and exit the editor, or discard changes if necessary. Remember, `Esc :wq` in Vim, or you'll be stuck forever." }
                ],
                examples: [
                    "Editing the Nginx configuration file with Vim: `sudo vim /etc/nginx/nginx.conf` (Press `i` for insert mode, `Esc` then `:wq` to save and quit).",
                    "Making a quick change to a Bash script with Nano: `nano myscript.sh` (Ctrl+O to save, Ctrl+X to exit).",
                    "Viewing a log file with less for easy navigation: `less /var/log/auth.log` (Press `q` to quit).",
                    "Using `sed` for non-interactive search and replace in scripts: `sed -i 's/old_text/new_text/g' config.file`."
                ],
                technicalDetails: "Vim is fundamentally different: it operates on 'buffers' and 'registers', and its modal nature means commands are optimized for efficient text manipulation without constantly reaching for the mouse. Nano is a direct text stream editor. While `sed` and `awk` are for stream editing, Vim and Nano are for interactive, human-driven modification. You *will* need one of these to fix things when the GUI is gone or you're on a remote server.",
                tools: "Vim, Nano, Emacs, Micro, `ed` (the original line editor), `sed` (stream editor for non-interactive), `awk` (pattern scanning and processing language)."
            },
            'boot-process': {
                name: "Boot Process & Init Systems",
                purpose: "To understand the sequence of events that occur when a Linux system starts up, from power-on to a fully operational state. Init systems manage the startup and shutdown of services and daemons. If your system doesn't boot, you need to understand this, or you're just guessing.",
                features: [
                    { title: "BIOS/UEFI", desc: "The first software executed on system power-on. BIOS (Basic Input/Output System) or its successor UEFI (Unified Extensible Firmware Interface) performs Power-On Self-Test (POST) and initializes hardware, then identifies and loads the bootloader from a designated boot device (e.g., hard drive). This is the firmware, the lowest level. If it's broken, you've got bigger problems than Linux." },
                    { title: "Bootloader (GRUB)", desc: "GRUB (GRand Unified Bootloader) is the most common bootloader for Linux. It presents a menu to the user (if multiple OSes are present), loads the Linux kernel into memory, and passes control to it. It supports various filesystems and boot methods. GRUB is what gets your kernel off the disk and into memory. Without it, you've just got a fancy brick." },
                    { title: "Kernel Initialization", desc: "Once loaded, the Linux kernel initializes the system's hardware, sets up memory management, and loads necessary device drivers. The kernel then starts the first process, which is always `init` (or `systemd` on modern systems) with PID 1. This is the heart of your system waking up. `dmesg` shows you its early thoughts." },
                    { title: "Init Systems (System V init, systemd)", desc: "The `init` system is responsible for managing all other processes on the system, bringing it to a defined 'runlevel' or 'target'. **System V init** (SysVinit) uses runlevels and shell scripts, simple but sequential. **systemd** (modern default) uses 'units' (services, sockets, mount points) and provides parallel startup, better dependency management, and powerful logging (Journald). Yes, there were 'init wars'. systemd won. Deal with it, it's efficient." },
                    { title: "Runlevels / Targets", desc: "In SysVinit, 'runlevels' (e.g., 0 for halt, 3 for multi-user CLI, 5 for graphical) define the services that start. In systemd, 'targets' (e.g., `multi-user.target`, `graphical.target`) serve a similar purpose but are more flexible and dependency-driven. It's how your system knows *what* to run at startup. Don't blindly change your default target." },
                    { title: "Service Startup", desc: "The init system starts essential system services and daemons (e.g., networking, logging, SSH server, web server) according to the configured runlevel/target, bringing the system to a usable state. This is where your applications finally come alive." }
                ],
                examples: [
                    "Checking the default boot target on a systemd-based Linux: `systemctl get-default`.",
                    "Changing to multi-user (CLI) mode temporarily: `systemctl isolate multi-user.target`.",
                    "Troubleshooting boot issues by inspecting kernel messages: `dmesg` or `journalctl -k`.",
                    "Rebuilding GRUB configuration after a kernel update: `sudo update-grub`.",
                    "Viewing the boot sequence graph (systemd): `systemd-analyze plot > boot.svg` then open `boot.svg`."
                ],
                technicalDetails: "The boot process is a delicate dance of hardware, firmware, and software. GRUB's job is to load the kernel and initial ramdisk (`initrd`), which then takes over. The kernel's job is to initialize everything *else* and then hand off to PID 1, your init system. systemd's parallelization and cgroup integration drastically speed up boot times compared to the old sequential SysVinit scripts. Understanding this flow is paramount for diagnosing boot failures, which are always a pain. When things go wrong, the kernel messages (`dmesg`) and `journalctl` are your first and best friends.",
                tools: "GRUB, systemd, systemctl, journalctl, dmesg, init, runlevel (SysVinit), BIOS, UEFI, initramfs/initrd, `systemd-analyze`."
            },
            'user-groups': {
                name: "Users & Groups",
                purpose: "To manage who can access the Linux system and what permissions they have. Users represent individual accounts, while groups are collections of users, simplifying the assignment of permissions to multiple users simultaneously. This is basic security: know who's on your system.",
                features: [
                    { title: "User Accounts", desc: "Individual entities that can log into the system. Each user has a unique ID (UID), a home directory, a default shell, and a password. Users own files and processes and their activities are logged. Every login, every action, should be tied to a specific user. This is accountability." },
                    { title: "Group Accounts", desc: "Collections of users. Each user belongs to at least one primary group and can be a member of multiple supplementary groups. Permissions can be assigned to groups, allowing all members of that group to inherit those permissions, simplifying access control. Don't manage permissions for individuals; use groups, it's scalable." },
                    { title: "Root User", desc: "The superuser account with UID 0. It has full administrative privileges on the system, bypassing all permission checks. Direct use of the root account for daily tasks is discouraged; `sudo` is preferred for elevated privileges. Root is god. Only use god-mode when absolutely necessary, and then with extreme caution." },
                    { title: "User Management Commands", desc: "Commands like `useradd` (create user), `usermod` (modify user), `userdel` (delete user), `passwd` (change password), `chage` (manage password expiration) are used to manage user accounts. `id` shows user and group IDs. These are your essential tools for managing human access." },
                    { title: "Group Management Commands", desc: "Commands like `groupadd` (create group), `groupmod` (modify group), `groupdel` (delete group), `gpasswd` (manage group members and passwords) are used to manage group accounts. Don't forget `newgrp` to change your active group." },
                    { title: "Password Files (`/etc/passwd`, `/etc/shadow`)", desc: "`/etc/passwd` stores user account information (username, UID, GID, home directory, shell) but not passwords. Passwords (hashed and salted) are stored securely in `/etc/shadow`, which is only readable by root, protecting sensitive credential information. If `/etc/shadow` is compromised, your system is compromised. Guard it with your life." }
                ],
                examples: [
                    "Creating a new user `devuser` with a home directory and bash shell: `sudo useradd -m -s /bin/bash devuser`.",
                    "Setting a password for `devuser`: `sudo passwd devuser`.",
                    "Adding `devuser` to the `sudo` group (on Debian/Ubuntu) or `wheel` group (on RHEL/CentOS) to grant sudo privileges: `sudo usermod -aG sudo devuser`.",
                    "Creating a new group `webadmins`: `sudo groupadd webadmins`.",
                    "Viewing a user's details, including all groups: `id devuser`.",
                    "Checking the last password change date for `devuser`: `sudo chage -l devuser`."
                ],
                technicalDetails: "Linux uses User IDs (UIDs) and Group IDs (GIDs) internally; names are just for human convenience. The kernel performs permission checks based on these IDs. The principle of least privilege is not a suggestion, it's a fundamental security mantra: give users and processes *only* the access they absolutely need, nothing more. This dramatically reduces the blast radius if an account is compromised. Always verify UID/GID associations when troubleshooting access issues.",
                tools: "useradd, usermod, userdel, passwd, groupadd, groupmod, groupdel, id, whoami, groups, chage, /etc/passwd, /etc/shadow, /etc/group, `newgrp`."
            },
            'file-permissions': {
                name: "File Permissions (chmod, chown)",
                purpose: "To control who can read, write, or execute files and directories on a Linux system. This is a crucial security mechanism that enforces access control and protects sensitive data from unauthorized access or modification. If you don't understand permissions, you don't understand Linux security.",
                features: [
                    { title: "Read (r), Write (w), Execute (x)", desc: "The three primary permissions: **Read (r)** allows viewing file content or listing directory contents. **Write (w)** allows modifying file content or creating/deleting files within a directory. **Execute (x)** allows running a file as a program or entering/traversing a directory. These are fundamental. Get them wrong, and your system is either insecure or unusable." },
                    { title: "Owner, Group, Others", desc: "Permissions are assigned to three categories: the **Owner** (the user who owns the file/directory), the **Group** (the group that owns the file/directory), and **Others** (everyone else on the system). This allows for granular control over access. Don't be lazy and grant 'other' too much access." },
                    { title: "Symbolic Notation", desc: "Uses letters `u` (user/owner), `g` (group), `o` (others), `a` (all) combined with `+` (add), `-` (remove), `=` (set explicitly) and `r`, `w`, `x` (e.g., `chmod u+x file.sh`). This is intuitive for understanding current permissions, seen in `ls -l` output (e.g., `-rw-r--r--`). It spells out what's happening." },
                    { title: "Octal (Numeric) Notation", desc: "Uses numbers (0-7) to represent combinations of permissions. Read=4, Write=2, Execute=1. The sum of these values gives the octal digit (e.g., `rwx = 4+2+1=7`, `rw- = 4+2+0=6`). This is commonly used with `chmod` for setting permissions (e.g., `chmod 755 file.sh`). It's concise, but opaque if you don't know the values." },
                    { title: "Special Permissions (SUID, SGID, Sticky Bit)", desc: "**SUID (Set User ID)**: When an executable file with SUID set is run, it executes with the permissions of the file owner, not the user running it (e.g., `passwd` program *must* run as root to change `/etc/shadow`). **SGID (Set Group ID)**: For files, executes with group owner's permissions. For directories, new files/subdirectories inherit the parent's group, useful for shared directories. **Sticky Bit**: For directories (e.g., `/tmp`), only the owner (or root) can delete or rename files within that directory, even if others have write permission. These are powerful, and thus dangerous. Use with extreme caution and understand their implications!" },
                    { title: "Changing Ownership (chown, chgrp)", desc: "`chown` changes the user owner and/or group owner of a file or directory (e.g., `chown user:group file`). `chgrp` changes only the group owner. These commands are essential for managing access control based on ownership. You need `sudo` for `chown` usually, as changing ownership is a big deal." }
                ],
                examples: [
                    "Granting read, write, and execute permissions to the owner, and read and execute to group and others for a script: `chmod 755 myscript.sh`.",
                    "Making a configuration file readable only by the owner: `chmod 600 sensitive.conf`.",
                    "Changing the owner of a file to `john` and the group to `webdevs`: `sudo chown john:webdevs /var/www/html/index.html`.",
                    "Viewing permissions for a file: `ls -l /etc/passwd`.",
                    "Setting SGID on a shared directory so new files inherit group: `chmod g+s /shared/projects`.",
                    "Checking the default file creation permissions using `umask`: `umask` or `umask -S`."
                ],
                technicalDetails: "Permissions are not just abstract rules; they're bits stored in the filesystem's inode structure. When a process tries to access a file, the kernel literally checks these bits against the calling process's UID and GIDs. The `umask` value directly affects the *default* permissions new files and directories get, effectively *removing* permissions from the default `666` (files) or `777` (directories). Understanding `umask` is vital for initial file security. Misconfigured permissions are a gaping hole in security, often overlooked by beginners.",
                tools: "chmod, chown, chgrp, ls -l, umask, stat, setfacl, getfacl (for ACLs)."
            },
            'sudo': {
                name: "Sudo & Privilege Escalation",
                purpose: "To allow a permitted user to execute a command as the superuser (root) or another user, without needing to know the root password. It provides a secure and auditable way to grant administrative privileges on a granular basis. If you're still logging in as root, you're doing it wrong and asking for trouble.",
                features: [
                    { title: "Controlled Privilege Escalation", desc: "`sudo` grants temporary elevated privileges for specific commands, rather than requiring a full login as root. This minimizes the time an administrator operates with full root powers, reducing the risk of accidental damage or malicious activity. It's a precise scalpel, not a sledgehammer." },
                    { title: "Auditing & Logging", desc: "Every command executed with `sudo` is logged, typically to `/var/log/auth.log` or `/var/log/secure`, including who ran the command, what command was run, and when. This provides a clear audit trail for security and compliance purposes. If something breaks or someone malicious acts, you know who did what, when. Essential for forensics." },
                    { title: "Granular Permissions (`/etc/sudoers`)", desc: "The `/etc/sudoers` file (edited ONLY with `visudo`) defines which users or groups can run which commands as which other users (typically root), from which hosts, and whether a password is required. This allows for highly specific delegation of administrative tasks. This file is sacred. Do not edit it directly. `visudo` exists to save you from yourself." },
                    { title: "Password Authentication", desc: "By default, `sudo` prompts for the *user's own password*, not the root password. This adds an extra layer of security, as compromising the root password is not necessary for an attacker to gain limited elevated privileges if a user's account is compromised. You're authenticating *yourself* to `sudo`, not `root`." },
                    { title: "No Password (`NOPASSWD`) Option", desc: "For specific automation scripts or very frequently used commands, `NOPASSWD` can be configured in `/etc/sudoers` to allow a command to run without prompting for a password. This should be used with extreme caution due to the security implications. Only for trusted, specific, automated scripts. Don't abuse it." }
                ],
                examples: [
                    "Installing a package: `sudo apt update && sudo apt install nginx`.",
                    "Restarting a service: `sudo systemctl restart apache2`.",
                    "Editing a system configuration file: `sudo nano /etc/hosts`.",
                    "Running a command as a different user: `sudo -u www-data touch /var/www/html/test.txt`.",
                    "Checking your sudo privileges: `sudo -l`."
                ],
                technicalDetails: "`sudo` reads `/etc/sudoers` to determine if a user has permission to execute a command. It then uses PAM (Pluggable Authentication Modules) for authentication against the user's password. Once authenticated, `sudo` executes the command with the privileges of the target user (usually root). The `Defaults requiretty` option in `sudoers` is important for preventing `sudo` from being used in non-interactive sessions unless explicitly allowed. Misconfiguring `sudoers` is a classic way to lock yourself out of a system; `visudo` validates syntax *before* saving. Always use it.",
                tools: "sudo, visudo, /etc/sudoers, /var/log/auth.log, /var/log/secure, `sudo -l`, PAM (Pluggable Authentication Modules)."
            },
            'directory-operations': {
                name: "Directory Operations (mkdir, rm, mv)",
                purpose: "To manage and manipulate directories (folders) on the Linux file system. These commands allow users to create, remove, rename, and move directories, which are fundamental tasks for organizing data and setting up file structures. These are your bread and butter for file management.",
                features: [
                    { title: "mkdir (Make Directory)", desc: "Creates new directories. Can create single directories or multiple nested directories recursively using the `-p` option (e.g., `mkdir -p /path/to/new/directory`). The `-p` flag is for when you're too lazy to create intermediate directories. Use it." },
                    { title: "rm (Remove File/Directory)", desc: "Removes files or directories. The `-r` (recursive) option is required to remove directories and their contents. The `-f` (force) option can be used to remove files/directories without prompting, even if they are write-protected. **Use `rm -rf` with extreme caution! It's the ultimate footgun. There is no undo.**" },
                    { title: "rmdir (Remove Empty Directory)", desc: "Removes an empty directory. It will not remove a directory if it contains any files or subdirectories. `rm -r` is typically used for non-empty directories, but `rmdir` is safer if you *know* it should be empty." },
                    { title: "mv (Move/Rename File/Directory)", desc: "Moves files or directories from one location to another. If the destination is a new name in the same directory, it effectively renames the file/directory (e.g., `mv oldname newname`). If the destination is a directory, it moves the item into that directory. It's atomic within the same filesystem, a quick rename." },
                    { title: "cp (Copy File/Directory)", desc: "Copies files or directories. The `-r` (recursive) option is required to copy directories and their contents (e.g., `cp -r sourcedir destdir`). Be aware of permissions and ownership when copying; they might not transfer as you expect." },
                    { title: "ln (Create Link)", desc: "Creates links to files or directories. **Hard links** (`ln source target`) are direct pointers to the same inode. They cannot span filesystems and refer to the *data*. **Symbolic links** or **symlinks** (`ln -s source target`) are pointers to other files or directories, and *can* span different filesystems. They refer to the *name*. Symlinks are more commonly used and less confusing. Don't get hard links wrong, they can bite you." }
                ],
                examples: [
                    "Creating a new directory named `projects`: `mkdir projects`.",
                    "Creating nested directories `logs/app1/today`: `mkdir -p logs/app1/today`.",
                    "Renaming `old_data` directory to `archive`: `mv old_data archive`.",
                    "Moving `config.txt` from current directory to `/etc/app/`: `sudo mv config.txt /etc/app/`.",
                    "Copying a directory recursively: `cp -r /var/www/html/my_app /tmp/backup_app`.",
                    "Creating a symbolic link to a long path: `ln -s /var/log/apache2/access.log /home/admin/apache_access.log`."
                ],
                technicalDetails: "These commands operate directly on the filesystem's metadata (inodes, directory entries). When you `rm` a file, you're not deleting the data immediately, you're removing its directory entry and decrementing its inode's link count. The data blocks are only truly freed when the link count hits zero. `mv` on the same filesystem is just a metadata update; across filesystems, it's a `cp` then `rm`. Understanding this prevents 'phantom disk space' issues and reinforces why `rm -rf /` is so catastrophic.",
                tools: "mkdir, rmdir, rm, mv, cp, ln, find, `tree`."
            },
            'process-monitoring': {
                name: "Process Monitoring (top, htop, ps)",
                purpose: "To observe and manage running processes on a Linux system. This is essential for troubleshooting performance issues, identifying runaway processes, ensuring critical services are running, and diagnosing system health. If your system is slow, this is where you start looking.",
                features: [
                    { title: "ps (Process Status)", desc: "Displays information about currently running processes. Various options (`ps aux`, `ps -ef`) allow for different output formats, showing process ID (PID), user, CPU/memory usage, command, and start time. It provides a snapshot of processes at the time the command is run. A static snapshot. For quick checks." },
                    { title: "top (Table Of Processes)", desc: "Provides a dynamic, real-time view of running processes, sorted by CPU utilization by default. It displays system summary information (uptime, load average, CPU/memory usage) and a list of processes that updates periodically. Useful for quickly identifying resource-hungry processes. The classic. Good for getting a feel for load." },
                    { title: "htop (Interactive Process Viewer)", desc: "An enhanced and more user-friendly interactive process viewer than `top`. It offers a colorful interface, easy scrolling, visual CPU/memory usage meters, and simplified process management (kill, renice) using function keys. `htop` is not installed by default on all systems but is highly recommended. It's `top`, but better. Install it, use it." },
                    { title: "kill & killall (Terminate Processes)", desc: "`kill` sends signals to processes by their PID to terminate them (e.g., `kill <PID>`, `kill -9 <PID>` for forceful kill – `SIGKILL`). `killall` terminates processes by their name (e.g., `killall apache2`), which is useful for stopping all instances of a service. Don't jump to `kill -9` immediately; try graceful termination first (e.g., `kill <PID>` which sends `SIGTERM`)." },
                    { title: "PIDs (Process IDs)", desc: "Unique numerical identifiers assigned to each running process. PIDs are used by many commands (e.g., `kill`, `lsof`) to refer to specific processes. PID 1 is always the `init` or `systemd` process, the parent of all other processes. Every process has one. It's its unique identifier." },
                    { title: "Background/Foreground Processes", desc: "Users can run commands in the background (`&`) to free up the terminal for other tasks, or bring background jobs to the foreground (`fg`). `jobs` command lists current background jobs. Don't tie up your terminal with long-running tasks. Use `nohup` if you need it to run even after you log out." }
                ],
                examples: [
                    "Finding a specific process: `ps aux | grep nginx`.",
                    "Viewing real-time system and process metrics: `top` or `htop` (if installed).",
                    "Killing a runaway process with PID 12345: `kill 12345` (graceful stop), `kill -9 12345` (force kill).",
                    "Running a long-running command in the background: `my_script.sh &`.",
                    "Bringing a background job (e.g., `job 1`) to the foreground: `fg 1`."
                ],
                technicalDetails: "The `/proc` filesystem is your window into the kernel's process table. Tools like `ps`, `top`, and `htop` parse the text files in `/proc/<PID>/` to gather their information. Understanding process states (Running, Sleeping, Zombie, Stopped, Disk Sleep) is crucial for effective troubleshooting. A 'zombie' process is a child process that has terminated but still has an entry in the process table because its parent hasn't collected its exit status – they consume no resources but can indicate a buggy parent. Signals (`SIGTERM`, `SIGKILL`, `SIGHUP`) are how the kernel communicates with processes. Don't be afraid to experiment, but understand the signals.",
                tools: "ps, top, htop, kill, killall, pgrep, pidof, pstree, jobs, fg, bg, nice, renice, `lsof` (list open files), `strace` (trace system calls), `/proc` filesystem."
            },
            'service-management': {
                name: "Service Management (systemd, service)",
                purpose: "To control the lifecycle of system services (daemons), including starting, stopping, restarting, enabling (to start on boot), and disabling them. Modern Linux distributions primarily use `systemd` for this, replacing older `System V init` (`service`) scripts. This is how you keep your server's applications alive.",
                features: [
                    { title: "systemd", desc: "The modern and widely adopted init system and service manager on most current Linux distributions (e.g., Ubuntu, Fedora, Debian, CentOS 7+). It uses 'units' (e.g., service units for daemons, socket units, mount units) and provides parallel startup, advanced dependency management, logging via Journald, and powerful control with `systemctl`. Yes, it was controversial, but it's here to stay and it works. Efficiently." },
                    { title: "systemctl (systemd Control)", desc: "The primary command-line utility for controlling `systemd`. It can start, stop, restart, enable, disable, and check the status of services (e.g., `systemctl start apache2`, `systemctl status nginx`). It also manages targets, mounts, sockets, and timers. This is your one-stop shop for service management now." },
                    { title: "Service Units (`.service` files)", desc: "Text files that define how a service is managed by systemd. They contain information about the service (description, dependencies, command to execute, user to run as, restart policies). These files are typically located in `/etc/systemd/system/` or `/usr/lib/systemd/system/`. Learn to read and write these. They are the new `init.d` scripts." },
                    { title: "System V Init (`service` command)", desc: "The older init system used on some legacy Linux distributions (e.g., Ubuntu 14.04, CentOS 6). It uses numbered 'runlevels' and shell scripts in `/etc/init.d/` to manage services. The `service` command (e.g., `service apache2 start`) is a wrapper for these scripts. You might still encounter it on old boxes, but systemd is the future." },
                    { title: "Enabling/Disabling Services", desc: "`systemctl enable <service_name>` creates symbolic links to ensure a service starts automatically on system boot. `systemctl disable <service_name>` removes these links. This is crucial for ensuring essential services are always available and unnecessary ones don't consume resources or pose security risks. Don't run services you don't need." },
                    { title: "Logging (Journald Integration)", desc: "systemd integrates tightly with `journald`, its logging daemon. All service output (stdout, stderr) is captured by the journal, providing a centralized and structured logging system that can be queried powerfully with `journalctl`. This is a *major* improvement over scattered log files. Use `journalctl`." }
                ],
                examples: [
                    "Starting the Nginx web server: `sudo systemctl start nginx`.",
                    "Checking the status of Apache: `systemctl status apache2`.",
                    "Enabling SSH to start on boot: `sudo systemctl enable ssh`.",
                    "Viewing logs for a specific service: `journalctl -u nginx.service`.",
                    "Restarting the network service: `sudo systemctl restart networking` (Debian/Ubuntu) or `sudo systemctl restart NetworkManager` (some distributions).",
                    "Reloading systemd daemon after creating/modifying a unit file: `sudo systemctl daemon-reload`."
                ],
                technicalDetails: "systemd's strength comes from its parallelized startup, cgroup integration for resource management, and unified 'unit' concept. It's not just an init system; it's a full-fledged service manager. The `service` command on modern systems is often just a compatibility wrapper for `systemctl`. Understanding dependencies in unit files (`After=`, `Requires=`) is key to debugging complex service startup issues. Proper service management is paramount for system stability, performance, and, crucially, security. If a service is running unmonitored or unnecessarily, it's a potential vulnerability.",
                tools: "systemd, systemctl, journalctl, service (legacy wrapper), init.d (legacy), rc.d (legacy), `daemon-reload`, `/etc/systemd/system/*.service`."
            },
            'logging-management': {
                name: "Logging (Syslog, Journald)",
                purpose: "To collect, store, and manage system and application logs on a Linux system. Logs are critical for troubleshooting, security auditing, performance monitoring, and understanding system behavior. Effective log management is essential for any administrator. Logs are your system's diary. Read them.",
                features: [
                    { title: "Syslog (Traditional Logging)", desc: "A standard protocol and system for sending and receiving log messages from various devices and applications. On Linux, `rsyslog` or `syslog-ng` are common implementations. Logs are typically written to plain text files in `/var/log` (e.g., `/var/log/syslog`, `/var/log/auth.log`, `/var/log/messages`). It's simple, text-based, and works." },
                    { title: "Journald (systemd Logging)", desc: "The logging daemon for `systemd`. It captures all kernel messages, process output (stdout, stderr), and syslog messages. It stores logs in a structured, binary format (by default) that can be queried powerfully with `journalctl`. This provides centralized logging for systemd-based systems. It's faster, more powerful, and easier to filter than old text logs. Embrace it." },
                    { title: "Log Rotation (`logrotate`)", desc: "A utility that automatically compresses, archives, and deletes old log files to prevent them from consuming excessive disk space. It ensures that current log files remain manageable while preserving historical data according to defined policies. Without this, your `/var/log` will eat your disk alive. Configure it properly." },
                    { title: "Log Analysis & Search", desc: "Tools and techniques for searching, filtering, and analyzing log data to identify errors, security events, performance issues, or user activities. Commands like `grep`, `awk`, `sed`, `less`, `tail` are fundamental for interactive log analysis. For Journald, `journalctl` is key. You can't fix what you can't find. Learn to search logs effectively." },
                    { title: "Remote Logging (Syslog over network)", desc: "Allows sending log messages from multiple Linux servers to a central log server (e.g., a Syslog server, or a SIEM). This centralizes log collection, simplifying analysis and providing a more secure backup of logs in case a local server is compromised. For anything beyond a single server, centralize your logs. It's a security and sanity must-have." },
                    { title: "Security Auditing & Compliance", desc: "Logs are a primary source of evidence for security investigations and audits. They record user logins, privilege escalations, system changes, and security-related events, which are crucial for demonstrating compliance with various regulations. Your logs are your forensic trail. Don't clear them unless you know why." }
                ],
                examples: [
                    "Viewing the last 100 lines of the authentication log: `tail -n 100 /var/log/auth.log`.",
                    "Searching for all 'failed login' attempts in the journal for SSHD: `journalctl _COMM=sshd -g 'Failed password'`.",
                    "Monitoring new entries in the system log in real-time: `tail -f /var/log/syslog`.",
                    "Checking the status of the `nginx` service logs using journalctl: `journalctl -u nginx.service -f`.",
                    "Forcing a logrotate run for Apache logs: `sudo logrotate -f /etc/logrotate.d/apache2`."
                ],
                technicalDetails: "Syslog works by routing messages based on 'facility' (e.g., auth, mail) and 'severity' (e.g., info, error). Journald stores logs in a binary database (`/var/log/journal/`), allowing for much faster indexing, filtering, and cross-referencing than plain text files. It also captures stdout/stderr from services automatically. `logrotate` is configured via `/etc/logrotate.conf` and files in `/etc/logrotate.d/`. Effective log management involves not just collecting, but also analyzing and archiving. Don't let your logs overwhelm you, but don't ignore them.",
                tools: "Syslog (rsyslog, syslog-ng), journald, journalctl, logrotate, tail, head, less, grep, awk, sed, zcat (for compressed logs), Filebeat, Fluentd, `logger` (for sending custom messages to syslog/journal)."
            },
            'scheduling-tasks': {
                name: "Scheduling Tasks (Cron, At)",
                purpose: "To automate the execution of commands or scripts at specific times or intervals on a Linux system. This is crucial for performing routine administrative tasks, backups, log rotations, and other recurring jobs without manual intervention. If you're doing it manually, you're doing it wrong.",
                features: [
                    { title: "Cron (Daemon & Crontab)", desc: "The most common utility for scheduling repetitive tasks. The `cron` daemon runs in the background and executes commands specified in 'crontab' files. Each user can have their own crontab, and system-wide crontabs exist (e.g., `/etc/crontab`, `/etc/cron.d/`). This is your reliable workhorse for automation. Don't overthink it, but understand its quirks." },
                    { title: "Crontab Syntax", desc: "Crontab entries follow a specific five-field format for time/date specification: `minute hour day_of_month month day_of_week command`. Wildcards (`*`) and ranges (`-`) are used for flexible scheduling (e.g., `0 2 * * *` for 2 AM daily). Get this syntax wrong, and your job won't run. Or worse, it runs at the wrong time." },
                    { title: "Predefined Cron Scheduling", desc: "Many systems include predefined directories for common daily, weekly, and monthly tasks (`/etc/cron.daily`, `/etc/cron.weekly`, `/etc/cron.monthly`). Scripts placed in these directories are automatically executed by cron at the appropriate intervals. Simple way to drop a script in and have it run regularly." },
                    { title: "At Command (One-time Schedule)", desc: "Allows scheduling a command to run only once at a specific future time. It's useful for tasks that don't need to be repeated regularly (e.g., `echo 'shutdown -h now' | at 23:00`). For one-offs, `at` is your friend. Don't clutter your crontab with single-use jobs." },
                    { title: "Anacron", desc: "A utility that executes commands at specified intervals, but unlike cron, it doesn't assume the system is running continuously. If the system is off during a scheduled time, Anacron will execute the missed jobs when the system is next powered on. Ideal for desktop systems or servers that might be shut down periodically. For non-24/7 machines, this saves you from missed jobs." },
                    { title: "Systemd Timers", desc: "On `systemd`-based systems, timers can replace traditional cron jobs. Systemd timers offer more granular control, better logging via Journald, and can be used to trigger any `systemd` unit (e.g., run a service unit, activate a mount point). They are defined in `.timer` files (e.g., `mybackup.timer`). The modern, `systemd`-native way to schedule. Leverage it if your distro supports it." }
                ],
                examples: [
                    "Editing your user crontab: `crontab -e`.",
                    "Scheduling a daily backup script to run at 3:30 AM: `30 3 * * * /usr/local/bin/backup_script.sh` in crontab.",
                    "Scheduling a system reboot in 10 minutes: `echo 'sudo reboot' | at now + 10 minutes`.",
                    "Creating a systemd timer to run a cleanup script weekly: `mycleanup.timer` and `mycleanup.service` files. Define and enable them like any other systemd unit.",
                    "Listing currently scheduled `at` jobs: `atq`."
                ],
                technicalDetails: "Cron jobs are managed by the `crond` daemon. User crontabs are typically stored in `/var/spool/cron/`. System-wide jobs are in `/etc/crontab` or `/etc/cron.d/`. `cron` jobs run in a minimal environment, so always use full paths for executables within scripts, or set the `PATH` variable at the top of your crontab. Systemd timers are more robust, handling dependencies, calendar events, and even reacting to file changes. Always check the logs (syslog/journal) for cron/timer job output; if your script fails silently, you'll never know. Output from cron jobs is typically mailed to the user running the job.",
                tools: "cron, crontab, at, batch, anacron, systemd-timers, systemctl (for timers), /etc/crontab, /etc/cron.d/, /var/spool/cron/, mail, `man 5 crontab`."
            },
            'network-interfaces': {
                name: "Network Interface Configuration (ip, ifconfig)",
                purpose: "To configure and manage network interfaces (e.g., Ethernet, Wi-Fi, loopback) on a Linux system, allowing it to communicate over a network. This includes setting IP addresses, netmasks, gateways, and managing interface states. If your network is down, this is where you start.",
                features: [
                    { title: "ip Command (Modern)", desc: "The modern and recommended utility for configuring network interfaces, routing, and other network settings. It is part of the `iproute2` suite and offers a unified interface for various networking tasks (e.g., `ip address show`, `ip route add`). It provides more detailed and structured output than `ifconfig`. Forget `ifconfig`, use `ip`. It's better, it's more complete." },
                    { title: "ifconfig (Legacy)", desc: "A traditional utility for configuring and displaying network interface parameters. While still available on many systems, it is deprecated in favor of the `ip` command. It can show IP addresses, MAC addresses, and interface status (up/down). If you're using this, you're probably on an ancient system. Update your skills." },
                    { title: "Static vs. DHCP IP Configuration", desc: "**Static IP:** Manually assigning a fixed IP address, netmask, and gateway. For servers, always use static IPs. **DHCP (Dynamic Host Configuration Protocol):** Automatically obtains network configuration (IP address, DNS servers, gateway) from a DHCP server. Good for desktops, bad for servers you need to reliably find." },
                    { title: "Network Configuration Files", desc: "Linux distributions store network configurations in various locations and formats. Examples include: `/etc/network/interfaces` (Debian/Ubuntu, managed by `ifupdown`), `/etc/sysconfig/network-scripts/` (RHEL/CentOS, managed by `NetworkManager` or `network` service), or declarative formats like `netplan` (`/etc/netplan/`) for Ubuntu 18.04+. Know your distro's config file location, or you'll be lost." },
                    { title: "Loopback Interface (`lo`)", desc: "A special virtual network interface (`127.0.0.1`) that allows a computer to communicate with itself. It's used for testing network applications locally and for inter-process communication. Don't mess with it. It's always there, always working." },
                    { title: "Promiscuous Mode", desc: "A network interface operating in promiscuous mode captures all network traffic passing through it, not just traffic destined for that interface. Used by network sniffers (e.g., Wireshark, tcpdump) and IDS/IPS systems for monitoring. Requires root privileges. Powerful, but means you're seeing *everything* on that segment. Use with caution." }
                ],
                examples: [
                    "Viewing all network interfaces and their IP addresses: `ip address show` or `ip a`.",
                    "Bringing an interface up/down: `sudo ip link set eth0 up`, `sudo ip link set eth0 down`.",
                    "Assigning a static IP address temporarily: `sudo ip address add 192.168.1.100/24 dev eth0`.",
                    "Restarting network service after config changes (e.g., `netplan` on Ubuntu): `sudo netplan apply`.",
                    "Listing the MAC address of `eth0`: `ip link show eth0`."
                ],
                technicalDetails: "The `ip` command directly manipulates the Linux kernel's networking stack, specifically the `netlink` socket. Configuration changes made with `ip` are often temporary; for persistence, you *must* edit the appropriate configuration files for your distribution's network management service (e.g., `NetworkManager`, `systemd-networkd`, `ifupdown`). Understanding CIDR notation (`/24`) for subnets and how default gateways function is non-negotiable for effective network administration. Without proper configuration, your server is an island.",
                tools: "ip, ifconfig (legacy), route (legacy), netplan, /etc/network/interfaces, /etc/sysconfig/network-scripts/, NetworkManager, nmcli, nmtui, `tcpdump`, `wireshark`."
            },
            'dns-config': {
                name: "DNS Configuration",
                purpose: "To configure how a Linux system resolves domain names to IP addresses (and vice versa). Correct DNS configuration is essential for accessing websites, network services, and internal resources by their human-readable names. If DNS is broken, nothing works. Period.",
                features: [
                    { title: "`/etc/resolv.conf` (DNS Resolver Configuration)", desc: "The primary file for configuring DNS resolution. It contains entries for `nameserver` (IP addresses of DNS servers to use), `search` (domain suffixes to append to hostnames), and `options`. Changes made directly to this file might be overwritten by NetworkManager or DHCP clients. This file is often managed automatically; direct edits can be temporary." },
                    { title: "DNS Servers (Nameservers)", desc: "IP addresses of servers responsible for translating domain names into IP addresses. These can be public DNS servers (e.g., Google DNS 8.8.8.8, Cloudflare 1.1.1.1) or internal DNS servers managed by the organization. Choose reliable, fast ones." },
                    { title: "`/etc/hosts` (Local Hostname Resolution)", desc: "A simple text file that maps IP addresses to hostnames locally on the system. Entries in `/etc/hosts` take precedence over DNS queries. Useful for local development, blocking specific domains, or overriding DNS for internal services. It's your local override file. First stop for name resolution issues." },
                    { title: "DNS Client Utilities", desc: "Commands like `dig` and `nslookup` are used to query DNS servers directly, troubleshoot DNS resolution issues, and inspect DNS records (A, CNAME, MX, NS). `host` is a simpler alternative to `dig`. If you can't `dig`, you can't troubleshoot DNS." },
                    { title: "Caching DNS Resolvers", desc: "Local DNS caching (e.g., `systemd-resolved`, `dnsmasq`, `unbound`) can speed up DNS lookups by storing recently resolved names. This reduces network traffic and improves application performance. Use a local cache; it makes your system snappier and reduces external dependencies." }
                ],
                examples: [
                    "Manually setting DNS servers in `/etc/resolv.conf`: `nameserver 8.8.8.8`, `nameserver 1.1.1.1`.",
                    "Adding a local entry to `/etc/hosts` for testing: `192.168.1.100  myserver.local`.",
                    "Querying a specific DNS server for a domain's IP: `dig @8.8.8.8 example.com A`.",
                    "Restarting systemd-resolved after config changes: `sudo systemctl restart systemd-resolved`.",
                    "Checking the order of name resolution: `cat /etc/nsswitch.conf` (look for `hosts: files dns`)."
                ],
                technicalDetails: "DNS resolution typically follows a hierarchy: `nsswitch.conf` determines the order (usually `/etc/hosts` first), then local caching resolvers, then external DNS servers listed in `/etc/resolv.conf`. Many modern distributions manage `/etc/resolv.conf` automatically via NetworkManager or systemd-resolved, often symlinking it to `/run/systemd/resolve/stub-resolv.conf`. Direct manual edits to `/etc/resolv.conf` might be temporary. DNS poisoning (malicious redirection) is a serious threat, so ensuring trusted DNS sources is crucial. If your `getaddrinfo` calls fail, your applications fail.",
                tools: "/etc/resolv.conf, /etc/hosts, dig, nslookup, host, systemd-resolved, NetworkManager, dnsmasq, unbound, `/etc/nsswitch.conf`."
            },
            'ssh': {
                name: "SSH (Secure Shell)",
                purpose: "To provide a secure method for remote login and execution of commands on a Linux server over an unsecured network. It encrypts all traffic, including passwords, commands, and data transfers, preventing eavesdropping and tampering. SSH is the backbone of remote Linux administration. Get it right, or get hacked.",
                features: [
                    { title: "Secure Remote Login", desc: "Allows users to log into a remote Linux server from a client machine as if they were sitting directly in front of it. All communication (terminal session, commands, output) is encrypted, protecting against man-in-the-middle attacks. It's an encrypted tunnel for your terminal. Indispensable." },
                    { title: "Password Authentication", desc: "The simplest method, where users authenticate with a username and password. While convenient, it's less secure than key-based authentication and vulnerable to brute-force attacks. **DISABLE THIS ON PRODUCTION SERVERS.** Strong passwords and MFA are crucial *if* you absolutely must use it." },
                    { title: "Key-based Authentication", desc: "A more secure and recommended method using public-key cryptography. A public key is placed on the server (`~/.ssh/authorized_keys`), and the client uses a corresponding private key (protected by a passphrase) to authenticate. This eliminates password exposure and is highly resistant to brute-force attacks. This is the only way to do SSH. Period. Automate it with `ssh-copy-id`." },
                    { title: "SSH File Transfer (SFTP, SCP)", desc: "SSH includes secure file transfer capabilities: **SFTP (SSH File Transfer Protocol)** provides an interactive file transfer program similar to FTP but encrypted over SSH. **SCP (Secure Copy Protocol)** is a command-line utility for simple, non-interactive file copying between hosts over SSH. Don't use FTP; use SFTP/SCP. It's secure by default." },
                    { title: "SSH Tunneling/Port Forwarding", desc: "Allows securely tunneling arbitrary network connections through an SSH session. **Local port forwarding** (`-L`) forwards local ports to a remote destination. **Remote port forwarding** (`-R`) forwards remote ports to a local destination. **Dynamic port forwarding** (`-D`) creates a SOCKS proxy. Useful for accessing internal services securely. Your private VPN, essentially. Extremely powerful, learn it." },
                    { title: "SSH Hardening", desc: "Applying security best practices to the SSH daemon (`sshd`) configuration (e.g., disabling password authentication, changing default port, restricting root login, allowing only specific users/IPs) to minimize the attack surface. Your `/etc/ssh/sshd_config` is your fortress blueprint. Lock it down." }
                ],
                examples: [
                    "Logging into a remote server: `ssh username@remote_ip`.",
                    "Copying a file from local to remote using SCP: `scp myfile.txt username@remote_ip:/path/to/destination/`.",
                    "Generating an SSH key pair: `ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\"`.",
                    "Editing SSH daemon configuration to disable password authentication: `sudo nano /etc/ssh/sshd_config` (set `PasswordAuthentication no`), then `sudo systemctl restart sshd`.",
                    "Creating a local tunnel to access an internal web server: `ssh -L 8080:internal-webserver:80 username@jump_host`."
                ],
                technicalDetails: "SSH operates at the application layer, but its security is built on robust public-key cryptography (RSA, ED25519 for key exchange) and symmetric-key cryptography (AES, ChaCha20-Poly1305 for session encryption). The `sshd` daemon runs on the server, listening for connections. Your `~/.ssh/authorized_keys` file is critical; its permissions (`chmod 600`) are enforced strictly by `sshd`. `ssh-agent` keeps your private keys in memory so you don't type your passphrase constantly. `fail2ban` is a great tool for automatically blocking IPs that attempt brute-force attacks against SSH. Don't underestimate persistent attackers; secure your SSH!",
                tools: "ssh, sshd, ssh-keygen, scp, sftp, ssh-agent, `ssh-copy-id`, `/etc/ssh/sshd_config`, `~/.ssh/authorized_keys`, `fail2ban`, `sshd_config(5)` man page."
            },
            'firewall-linux': {
                name: "Firewall (iptables, ufw, firewalld)",
                purpose: "To control network traffic passing through a Linux system, acting as a filter to allow or deny connections based on predefined rules. This is essential for protecting the server itself and the services running on it from unauthorized access and attacks. Your first line of defense. Don't run a server on the internet without one.",
                features: [
                    { title: "iptables (Kernel Module)", desc: "The traditional Linux kernel-level firewall, used to set up, maintain, and inspect the tables of IP packet filter rules via the `netfilter` framework. It works with 'chains' (e.g., INPUT, OUTPUT, FORWARD) and 'tables' (e.g., filter, nat, mangle). `iptables` rules are powerful but can be complex to manage directly. It's the low-level tool, raw power. Learn it if you truly want to understand." },
                    { title: "ufw (Uncomplicated Firewall)", desc: "A user-friendly command-line interface for `iptables` (and sometimes `nftables`) on Debian/Ubuntu systems. It simplifies firewall management with straightforward commands (e.g., `ufw allow ssh`, `ufw enable`). It's designed to be easy to use for common firewall tasks. For simple use cases, UFW is good enough. Don't overcomplicate it." },
                    { title: "firewalld (Dynamic Firewall Daemon)", desc: "A dynamic firewall management daemon used on RHEL/CentOS/Fedora systems. It uses 'zones' (e.g., public, home, internal) and allows changes to be made without reloading the entire firewall, maintaining stateful connections. Rules can be permanent or runtime-only. Modern, flexible, and zone-based. Great for servers with multiple network interfaces." },
                    { title: "Chains & Rules", desc: "Firewalls operate on 'chains' (e.g., INPUT for incoming connections, OUTPUT for outgoing, FORWARD for routed traffic). Rules are processed sequentially within a chain, specifying criteria (source/destination IP, port, protocol) and an action (ACCEPT, DROP, REJECT). The order of rules matters. A lot. Get it wrong, and you're either exposed or locked out." },
                    { title: "Port Blocking/Opening", desc: "Common firewall tasks involve explicitly opening specific ports for services (e.g., port 80 for HTTP, 443 for HTTPS, 22 for SSH) and blocking all other incoming connections by default (deny-by-default policy). Close everything you don't need open. Seriously." },
                    { title: "Stateful Packet Inspection", desc: "Most modern Linux firewalls are stateful, meaning they track the state of network connections. Once an outgoing connection is established, the firewall automatically allows the return traffic for that connection, simplifying rule management for legitimate traffic. This is why you don't need 'allow established' rules explicitly; the kernel handles it. Efficient and secure." },
                    { title: "nftables (Newer Kernel Framework)", desc: "A newer packet filtering framework that aims to supersede `iptables`. It offers a more flexible and unified syntax for IPv4, IPv6, ARP, and Netfilter firewalling. It's gaining adoption and is the future. If you're starting fresh, look into `nftables`." }
                ],
                examples: [
                    "Allowing SSH access (port 22) through `ufw`: `sudo ufw allow ssh` then `sudo ufw enable`.",
                    "Allowing HTTP (port 80) and HTTPS (port 443) with `firewalld`: `sudo firewall-cmd --permanent --add-service=http` and `sudo firewall-cmd --permanent --add-service=https` followed by `sudo firewall-cmd --reload`.",
                    "Blocking all incoming traffic from a specific IP address using `iptables`: `sudo iptables -A INPUT -s 192.168.1.10 -j DROP`.",
                    "Listing current `iptables` rules: `sudo iptables -L -n -v`.",
                    "Listing `nftables` rules: `sudo nft list ruleset`."
                ],
                technicalDetails: "Linux firewalls leverage `netfilter`, a framework within the kernel that allows various network operations to be performed on packets as they traverse the network stack. `iptables`, `ufw`, and `firewalld` are just user-space tools that interact with `netfilter` to define rules. `nftables` is a significant rewrite, offering a more unified and expressive language. The 'deny-by-default' policy is a security fundamental: if it's not explicitly allowed, it's denied. Always test your firewall rules from a *different* machine, otherwise, you'll lock yourself out.",
                tools: "iptables, ufw, firewalld, nftables, `netfilter` (kernel module), `conntrack`, `nmap` (for external port scanning)."
            },
            'network-troubleshooting': {
                name: "Network Troubleshooting (ping, traceroute, netstat)",
                purpose: "To diagnose and resolve network connectivity issues on a Linux system. These tools help identify problems with network interfaces, routing, DNS resolution, and firewall rules. If the network isn't working, your services aren't working.",
                features: [
                    { title: "ping (Packet Internet Groper)", desc: "Sends ICMP (Internet Control Message Protocol) echo requests to a target host and listens for echo replies. Used to test basic network connectivity and measure round-trip time (latency) to a destination. `ping -c 4 google.com` sends 4 packets. It tells you if you can reach a host, but not necessarily if a *service* is running. Don't confuse reachability with service availability." },
                    { title: "traceroute / tracert (Trace Route to Host)", desc: "Traces the path that packets take to reach a destination host, showing each hop (router) along the way and the latency to each hop. Useful for identifying where network connectivity breaks down or where delays are occurring on the path. For figuring out *where* the problem is, this is key." },
                    { title: "netstat (Network Statistics)", desc: "Displays network connections (incoming and outgoing), routing tables, interface statistics, and multicast memberships. Useful for seeing open ports (`netstat -tuln`), active connections (`netstat -nat`), and network interface errors. It's old, but it works." },
                    { title: "ss (Socket Statistics)", desc: "A newer utility that largely replaces `netstat` on modern Linux systems. It is faster and more efficient for displaying socket statistics, including listening ports, established connections, and associated processes (`ss -tulnp`). Use `ss` instead of `netstat` on modern systems. It's faster and better integrated." },
                    { title: "ip Command (Network Configuration & Routing)", desc: "Beyond interface configuration, `ip route show` displays the kernel routing table, which is critical for understanding how packets are forwarded. `ip neigh show` shows the ARP cache (MAC address to IP mapping). Your routing table determines where packets go. Know it." },
                    { title: "dig / nslookup (DNS Lookup)", desc: "Tools to query DNS servers directly. Used to verify DNS resolution, check for correct IP mappings, and diagnose DNS-related connectivity issues (e.g., `dig example.com`, `nslookup example.com`). Don't assume DNS works; verify it explicitly with these tools." },
                    { title: "tcpdump (Packet Sniffer)", desc: "A command-line packet analyzer that captures and displays network traffic. Highly powerful for low-level debugging of network problems, revealing exactly what's on the wire. If you want to see what's *really* happening, use `tcpdump`. It's raw, but it's the truth." }
                ],
                examples: [
                    "Testing connectivity to a web server: `ping example.com`.",
                    "Identifying where a network path breaks: `traceroute google.com`.",
                    "Listing all open listening ports on the server: `sudo ss -tulnp`.",
                    "Checking the default gateway: `ip route show default`.",
                    "Diagnosing a DNS resolution problem for a specific domain: `dig problematicapp.internal`.",
                    "Capturing SSH traffic on port 22: `sudo tcpdump -i eth0 port 22`."
                ],
                technicalDetails: "Network troubleshooting is about systematic elimination. Start at the local interface (`ip a`), check the routing table (`ip route`), verify DNS (`dig`), and then test external connectivity (`ping`, `traceroute`). If all that checks out, then it's likely a firewall (`iptables`, `ufw`, `firewalld`) or application issue. The Linux kernel's networking stack is complex; these tools give you windows into different layers of it. `tcpdump` directly taps into the `libpcap` library to capture raw packets before they are processed by the applications. Don't guess; observe.",
                tools: "ping, traceroute, mtr, netstat (legacy), ss, ip, dig, nslookup, host, tcpdump, Wireshark (GUI packet analyzer), nmap (for port scanning), route (legacy)."
            },
            'package-managers': {
                name: "Package Managers (APT, YUM/DNF)",
                purpose: "To automate the process of installing, updating, configuring, and removing software packages on a Linux system. They simplify dependency resolution, ensure system consistency, and provide a secure way to manage software. These are how you get software onto your system, reliably.",
                features: [
                    { title: "APT (Advanced Package Tool)", desc: "The package management system used by Debian-based distributions (e.g., Debian, Ubuntu, Linux Mint). It handles `.deb` packages and manages dependencies automatically. `apt` is the user-friendly command that combines functionalities of `apt-get` and `apt-cache`. It's efficient and usually just works. Trust it." },
                    { title: "YUM/DNF (Yellowdog Updater, Modified / Dandified YUM)", desc: "`YUM` was traditionally used by Red Hat-based distributions (e.g., CentOS, Fedora < 22, RHEL 7). `DNF` is its modern successor, offering improved performance, better dependency resolution, and a clearer API, now default on Fedora and RHEL 8+ and CentOS 8+. `DNF` is a significant upgrade, use it if available." },
                    { title: "Repositories", desc: "Centralized locations (servers) where software packages are stored and maintained. Package managers fetch packages from these repositories. Distributions typically have official repositories, and users can add third-party or custom repositories for additional software (e.g., PPAs for Ubuntu, EPEL for RHEL/CentOS). Use trusted repositories. Random internet repos are a security risk." },
                    { title: "Dependency Resolution", desc: "A key feature where the package manager automatically identifies and installs all necessary prerequisite packages (dependencies) that a requested software package requires to function correctly. This prevents 'dependency hell' and ensures applications run correctly. This is the superpower of package managers. Without it, you'd be building everything from source and crying." },
                    { title: "Software Updates", desc: "Enables easy updating of all installed packages to their latest versions, including security patches and bug fixes. Commands like `apt update && apt upgrade` or `dnf update` keep the system current. Keep your system updated! Unpatched systems are easy targets." },
                    { title: "Package Search & Information", desc: "Allows searching for available packages by name or description (e.g., `apt search nginx`, `dnf search httpd`). It also provides detailed information about a package (dependencies, version, description) before installation (e.g., `apt show apache2`, `dnf info nginx`). Don't install blindly. Know what you're getting." }
                ],
                examples: [
                    "Updating package lists (Ubuntu/Debian): `sudo apt update`.",
                    "Installing Nginx (Ubuntu/Debian): `sudo apt install nginx`.",
                    "Updating all installed packages (RHEL/CentOS): `sudo dnf update`.",
                    "Installing Apache HTTP Server (RHEL/CentOS): `sudo dnf install httpd`.",
                    "Removing a package and its dependencies: `sudo apt autoremove firefox` or `sudo dnf remove mariadb-server`.",
                    "Searching for a package: `apt search <keyword>` or `dnf search <keyword>`."
                ],
                technicalDetails: "Package managers use local databases (e.g., `/var/lib/apt/lists`, `/var/lib/rpm`) to track installed packages, available versions, and their dependencies. They verify package integrity using GPG (GNU Privacy Guard) signatures against a trusted keyring to prevent malicious package injection. `dpkg` (Debian) and `rpm` (Red Hat) are the low-level tools that actually install/remove packages, while `apt` and `dnf` are high-level frontends that handle dependency resolution and repository interaction. Understand the difference between `apt update` (syncs package lists) and `apt upgrade` (installs updates).",
                tools: "APT (apt, apt-get, apt-cache, dpkg), YUM, DNF, rpm, snap, flatpak, `/etc/apt/sources.list`, `/etc/apt/sources.list.d/`, `/etc/yum.repos.d/`, GPG."
            },
            'compiling-from-source': {
                name: "Compiling from Source",
                purpose: "To install software by compiling its source code directly on the Linux system, rather than using pre-built binary packages. This provides maximum flexibility, allowing for custom configurations, optimization, or installation of very new/old software versions not available in repositories. When package managers fail, or you need absolute control, this is your path. Be prepared for pain.",
                features: [
                    { title: "Source Code Acquisition", desc: "Downloading the software's source code, typically as a compressed archive (e.g., `.tar.gz`, `.zip`) from a project's official website, GitHub repository, or a release mirror. Always verify checksums and sources. Don't trust random downloads." },
                    { title: "Dependencies Resolution (Manual)", desc: "Unlike package managers, identifying and installing all required build-time and runtime dependencies (e.g., compilers, libraries, development headers) is often a manual process when compiling from source. This can be complex and error-prone. This is 'dependency hell'. You'll spend more time here than compiling." },
                    { title: "Configuration (`./configure`)", desc: "Running a configuration script (often `./configure` generated by Autoconf) that checks for system capabilities, required libraries, and creates a `Makefile`. This step allows for specifying installation paths (`--prefix`), enabling/disabling features (`--enable-foo`), and optimizing the build for the specific system architecture. This is where you customize. Read the `README` and `--help` for flags." },
                    { title: "Compilation (`make`)", desc: "Executing the `make` command, which reads the `Makefile` and compiles the source code into executable binaries and libraries. This step converts the human-readable source code into machine-executable instructions. If this fails, you missed a dependency, or the code is broken. Good luck." },
                    { title: "Installation (`make install`)", desc: "Running `make install` (typically as root) copies the compiled binaries, libraries, and documentation to their designated installation directories (often `/usr/local/bin`, `/usr/local/lib`). This is where it finally goes live. Keep track of what you installed, as package managers won't know." },
                    { title: "Customization & Optimization", desc: "Compiling from source allows for fine-tuning build options (e.g., enabling specific features, optimizing for a particular CPU architecture) that might not be available in pre-compiled packages. This is why you do it: ultimate control and performance." }
                ],
                examples: [
                    "Compiling a custom version of Nginx with a specific module not available in the package manager: download source, `tar -xvzf nginx-*.tar.gz`, `cd nginx-*`, `./configure --prefix=/opt/nginx-custom --with-http_stub_status_module`, `make -j$(nproc)`, `sudo make install`.",
                    "Installing the latest Git release before it's available in your distribution's repositories: download source, `tar -xvzf git-*.tar.gz`, `cd git-*`, `make prefix=/usr/local all`, `sudo make prefix=/usr/local install`.",
                    "Building a legacy application that requires an older compiler version or specific library not supported by modern package managers. This is often the only way for niche or very old software."
                ],
                technicalDetails: "The 'configure, make, make install' paradigm is standard for many open-source projects. `configure` (often an `autoconf` generated script) probes your system. `make` is a build automation tool that reads `Makefile` instructions to compile source files with `gcc`/`g++`. The binaries end up in `/usr/local/` (if `--prefix=/usr/local` is used), making them 'locally installed' and not managed by the system package manager. This can lead to conflicts and makes uninstallation difficult. It requires development tools (`build-essential` on Debian, `Development Tools` group on RHEL). Only do this if you absolutely have to, and document *everything* you do.",
                tools: "wget/curl, tar, make, gcc/g++, configure, autoconf, automake, pkg-config, `ldd` (list shared library dependencies), `/usr/local/bin`, `/usr/local/lib`."
            },
            'containerization-linux': {
                name: "Containerization (Docker)",
                purpose: "To package applications and their dependencies into portable, isolated environments called containers. This ensures that software runs consistently across different computing environments (development, testing, production) by abstracting away the underlying infrastructure. Containers are the new virtualization, but lighter and faster. Embrace it.",
                features: [
                    { title: "Docker Engine", desc: "The core component that runs and manages Docker containers. It consists of a daemon (dockerd) that listens for Docker API requests, a REST API for programmatic interaction, and a command-line interface (docker CLI) for users to interact with the daemon. This is the heart of Docker on your Linux host." },
                    { title: "Docker Images", desc: "Lightweight, standalone, executable packages that include everything needed to run a piece of software: code, runtime, system tools, libraries, and settings. Images are built from Dockerfiles and are read-only templates for creating containers. They're like blueprints for your isolated environments." },
                    { title: "Docker Containers", desc: "Runnable instances of Docker images. Containers are isolated, self-contained environments that share the host OS kernel but have their own filesystem, processes, and network interfaces. They provide consistency and portability across different Linux hosts. They are *not* full virtual machines. Get that straight." },
                    { title: "Docker Hub / Registries", desc: "Public or private repositories for storing and sharing Docker images. Docker Hub is the default public registry. Organizations can also use private registries (e.g., GitLab Container Registry, Harbor) for internal image management. Your central repository for container images. Public or private, your choice." },
                    { title: "Dockerfile", desc: "A text file containing instructions for building a Docker image. It defines the base image, steps to install software, copy files, set environment variables, and define the command to run when the container starts. This defines your application's environment. Reproducibility starts here." },
                    { title: "Docker Compose", desc: "A tool for defining and running multi-container Docker applications. It uses a YAML file to configure application services, networks, and volumes, allowing for easy setup and teardown of complex local development or testing environments. For local development or simple multi-container apps, `docker-compose` is fantastic. Don't try to use it for production orchestration." }
                ],
                examples: [
                    "Building a Docker image for a Node.js web application: `docker build -t my-nodejs-app .` from a directory containing a `Dockerfile`.",
                    "Running a web server in a Docker container, mapping port 80: `docker run -d -p 80:80 nginx`.",
                    "Defining a multi-service application (web app, database, Redis cache) using `docker-compose.yml` and starting it with: `docker-compose up -d`.",
                    "Pushing a custom application image to Docker Hub: `docker push myusername/my-nodejs-app:latest`."
                ],
                technicalDetails: "Docker's magic relies on core Linux kernel features: **Namespaces** (PID, NET, MNT, UTS, IPC, USER) provide process and network isolation; **cgroups** (Control Groups) manage and limit resource allocation (CPU, memory, I/O); and a **layered filesystem** (e.g., OverlayFS, AUFS) allows images to share common layers, making them lightweight and efficient. Containers are *not* VMs; they share the host kernel. This makes them faster and more resource-efficient but also means they have a tighter coupling to the host kernel than VMs. Understanding these kernel features is key to truly understanding containers. When you need to manage many containers or complex deployments, look to orchestrators like Kubernetes.",
                tools: "Docker Engine, Docker CLI, Dockerfile, Docker Compose, Docker Hub, Podman (daemonless alternative to Docker), containerd (core container runtime), runc (low-level container runtime), Kubernetes (for orchestration), Linux namespaces, cgroups, OverlayFS."
            },
            'disk-management': {
                name: "Disk Management (fdisk, parted)",
                purpose: "To manage storage devices on a Linux system, including partitioning hard drives, creating logical volumes, and formatting filesystems. This is fundamental for setting up new storage, expanding existing storage, and preparing disks for data storage. If you can't manage disks, you can't manage a server. Period.",
                features: [
                    { title: "fdisk (Partition Table Manipulator)", desc: "A command-line utility for managing disk partitions using MBR (Master Boot Record) partition tables. It allows creating, deleting, and modifying partitions on hard drives. It's suitable for disks up to 2TB. It's old, it's reliable for MBR, but be aware of its limitations." },
                    { title: "parted (Partition Editor)", desc: "A more powerful and modern command-line utility for managing disk partitions, supporting both MBR and GPT (GUID Partition Table). It can create, delete, resize, and copy partitions. It's recommended for larger disks (over 2TB) and more complex partitioning schemes. Use `parted` for modern systems and large disks. It's the way forward." },
                    { title: "Partitioning", desc: "Dividing a physical hard drive into one or more logical sections (partitions). Each partition can then be formatted with a filesystem and mounted as a separate directory in the Linux file system. This allows for flexible organization and management of disk space. Don't put everything on one partition." },
                    { title: "Logical Volume Manager (LVM)", desc: "A flexible storage management system that sits on top of physical partitions or disks. LVM allows creating logical volumes (LVs) that span multiple physical volumes (PVs) or groups them into volume groups (VGs). This enables dynamic resizing of filesystems, snapshots, and flexible disk allocation. It's the standard for flexible storage on Linux. Learn it." },
                    { title: "Formatting Filesystems (mkfs)", desc: "Creating a filesystem (e.g., ext4, XFS, NTFS) on a partition, making it ready to store data. The `mkfs` command (e.g., `mkfs.ext4 /dev/sdb1`) is used for this purpose. This involves writing the filesystem's metadata structures to the disk. You can't use a disk without a filesystem. Period." },
                    { title: "Swap Space", desc: "A portion of a hard drive or a separate partition used as virtual memory when the physical RAM is full. The kernel moves less-used pages of memory to swap space to free up RAM. Important for system stability when physical memory is constrained. Don't rely on it, but have it for emergencies. SSDs don't like heavy swap usage." }
                ],
                examples: [
                    "Listing all disk devices and their partitions: `sudo fdisk -l` or `sudo parted -l`.",
                    "Creating a new partition on `/dev/sdb` using `fdisk` (interactive): `sudo fdisk /dev/sdb`.",
                    "Formatting a partition with ext4 filesystem: `sudo mkfs.ext4 /dev/sdb1`.",
                    "Creating a new LVM logical volume for data: `sudo lvcreate -n data -L 50G vg_name`.",
                    "Adding swap space: `sudo mkswap /dev/sdc1` followed by `sudo swapon /dev/sdc1`.",
                    "Viewing disk space usage: `df -h`."
                ],
                technicalDetails: "Linux represents disks as block devices (e.g., `/dev/sda`, `/dev/nvme0n1`). Partitioning creates logical divisions on these devices, and then filesystems are laid on top of these partitions. MBR (Master Boot Record) is legacy for disks up to 2TB; GPT (GUID Partition Table) is modern and required for larger disks and UEFI boot. LVM adds a crucial layer of abstraction, allowing you to manage storage pools rather than fixed partitions. This means you can resize filesystems and add/remove disks from pools dynamically. `dd` is a powerful tool for disk imaging but is also known as the 'data destroyer' if used incorrectly. Always double-check your `dd` commands!",
                tools: "fdisk, parted, gdisk, sfdisk, mkfs (mkfs.ext4, mkfs.xfs, mkfs.btrfs), mount, umount, LVM tools (pvcreate, vgcreate, lvcreate, pvdisplay, vgdisplay, lvdisplay, lvextend, lvreduce, lvremove), swapon, swapoff, df, du, `lsblk` (list block devices), `dd`."
            },
            'filesystem-types': {
                name: "Filesystem Types (ext4, XFS)",
                purpose: "To organize and manage files on storage devices (hard drives, SSDs). A filesystem provides a structure for storing data, managing metadata (e.g., file names, permissions, timestamps), and ensuring data integrity and efficient access. Your data's home. Choose wisely.",
                features: [
                    { title: "ext4 (Fourth Extended Filesystem)", desc: "The default and most widely used journaling filesystem for Linux distributions. It records changes in a journal before committing them to the main filesystem, improving data integrity and faster recovery after unexpected shutdowns or crashes. Supports large filesystems (up to 1EB) and files (up to 16TB). It's a solid, general-purpose choice." },
                    { title: "XFS (eXtended Filesystem)", desc: "A high-performance journaling filesystem commonly used for very large filesystems (up to 8EB) and high-concurrency workloads, especially on enterprise Linux distributions like RHEL and CentOS. It excels in parallel I/O operations and scaling. If you're dealing with massive files or heavy database I/O, XFS is often a better choice than ext4." },
                    { title: "Journaling", desc: "A key feature of modern filesystems (ext4, XFS, NTFS, HFS+). It records metadata changes in a special log (journal) before applying them to the filesystem. This ensures filesystem consistency after a crash or power failure, significantly reducing filesystem check times during boot compared to non-journaling filesystems. This prevents lengthy `fsck` runs after a crash, saving you time and stress." },
                    { title: "Inodes", desc: "A data structure on a Unix-style filesystem that describes a filesystem object (e.g., file, directory). Each file/directory has an inode, which stores metadata like permissions, ownership, timestamps, and pointers to the actual data blocks on the disk, but not the filename itself. The inode *is* the file's identity; the filename is just a label in a directory entry. Run `df -i` to check inode usage." },
                    { title: "Data Blocks", desc: "The smallest unit of storage that the filesystem can allocate. Files are stored in one or more data blocks. The filesystem manages the allocation and deallocation of these blocks. This is where your actual data lives." },
                    { title: "Metadata", desc: "Information about files and directories, such as filenames, sizes, creation/modification/access times, permissions, ownership, and locations of data blocks. Journaling primarily protects metadata integrity, not necessarily the data itself. Know the difference." },
                    { title: "Btrfs & ZFS (Next-Gen Filesystems)", desc: "Modern filesystems offering advanced features like snapshots, data integrity (checksumming), pooling, and built-in RAID functionalities. While powerful, they can have a steeper learning curve and may not be default on all distributions. For advanced use cases and data paranoia, these are worth exploring. They're complex, but offer unparalleled features." }
                ],
                examples: [
                    "Creating an ext4 filesystem on a partition: `sudo mkfs.ext4 /dev/sdb1`.",
                    "Creating an XFS filesystem for a large data volume: `sudo mkfs.xfs /dev/sdc1`.",
                    "Checking filesystem usage for free space: `df -h`.",
                    "Inspecting inode usage to see if you're out of inodes before disk space: `df -i`.",
                    "Growing an ext4 filesystem after LVM resize: `sudo resize2fs /dev/mapper/vg_data-lv_app`."
                ],
                technicalDetails: "Filesystems are the critical abstraction layer between raw disk blocks and the human-readable file hierarchy. The kernel's VFS (Virtual File System) layer provides a consistent interface to different filesystem implementations. Journaling is a massive improvement for crash recovery; older filesystems like ext2 required full `fsck` on every crash. Performance characteristics vary significantly between filesystems; ext4 is balanced, XFS excels at large files and concurrency, while Btrfs/ZFS offer copy-on-write (CoW) for snapshots and robust data integrity checks. Don't choose your filesystem based on hype; choose it based on your actual workload and data integrity needs.",
                tools: "mkfs.ext4, mkfs.xfs, tune2fs, xfs_info, df, du, fsck, mount, tune2fs, `e2label`, `xfs_admin`, `btrfs` (Btrfs tools), `zfs` (ZFS tools)."
            },
            'mounting-filesystems': {
                name: "Mounting & Unmounting",
                purpose: "To make filesystems accessible to the Linux operating system's directory tree. Mounting attaches a filesystem (from a partition, USB drive, network share) to a specific directory (mount point), allowing users and applications to access the data. Unmounting detaches it. If it's not mounted, you can't use it. Simple as that.",
                features: [
                    { title: "Mount Point", desc: "An empty directory on the existing Linux file system where a new filesystem is attached. Once mounted, the contents of the new filesystem become accessible through this directory. Common mount points include `/mnt` (temporary mounts), `/media` (removable devices), and `/var/www/html` for web content. Choose a logical mount point." },
                    { title: "mount Command", desc: "Used to attach a filesystem to a mount point (e.g., `sudo mount /dev/sdb1 /mnt/data`). It can also display currently mounted filesystems and their options. Your primary tool for manually mounting." },
                    { title: "umount Command", desc: "Used to detach a mounted filesystem from its mount point (e.g., `sudo umount /mnt/data`). It's crucial to unmount a filesystem before physically removing the device or modifying its partitions to prevent data corruption. Always unmount cleanly. If it says 'device or resource busy', find out why (`lsof`) before forcing it." },
                    { title: "`/etc/fstab` (Filesystem Table)", desc: "A configuration file that contains a list of filesystems that the system should mount automatically at boot time. It specifies the device (often UUID for reliability), mount point, filesystem type, and mount options. This ensures persistence of mounts across reboots. This file is critical; a misconfigured `fstab` can prevent your system from booting." },
                    { title: "Mount Options", desc: "Various options can be specified during mounting to control filesystem behavior (e.g., `ro` for read-only, `rw` for read-write, `noexec` to prevent binaries from executing, `defaults` for common options, `nofail` to allow boot even if mount fails, `acl` for Access Control Lists). Use appropriate options for security and performance." },
                    { title: "Block Devices", desc: "Physical or logical storage devices (e.g., `/dev/sda1`, `/dev/sdb`, `/dev/mapper/vg_data-lv_app`) that are partitioned and formatted with a filesystem. The `mount` command operates on these block devices. Know your device names, or you'll mount the wrong thing." }
                ],
                examples: [
                    "Mounting a USB drive temporarily: `sudo mount /dev/sdb1 /media/usb`.",
                    "Unmounting a directory: `sudo umount /media/usb`.",
                    "Making a new data partition persist across reboots by adding an entry to `/etc/fstab`: `UUID=<UUID_of_partition> /data ext4 defaults,nofail 0 2`.",
                    "Listing all currently mounted filesystems and their options: `mount` or `findmnt`.",
                    "Finding processes using a busy mount point: `sudo lsof +D /mnt/data`."
                ],
                technicalDetails: "The kernel's VFS (Virtual File System) layer handles all mount operations, presenting a unified filesystem view to applications. `/etc/fstab` is read by `systemd` (or `mount -a` during boot) to establish persistent mounts. Using UUIDs (Universally Unique Identifiers) from `blkid` in `fstab` is crucial for reliable mounts, as device names (`/dev/sdb1`) can change. Forcing an unmount (`umount -f`) should be a last resort, as it can lead to data corruption. Network File Systems (NFS, Samba/CIFS) also use mounting to access remote shares, but have additional considerations like auto-mounters.",
                tools: "mount, umount, /etc/fstab, blkid (to get UUIDs), findmnt, lsblk, `lsof` (list open files), `autofs` (for automounting)."
            },
            'raid-lvm': {
                name: "RAID & LVM",
                purpose: "To provide advanced storage management capabilities on Linux systems, enhancing data redundancy, performance, and storage flexibility. These technologies are crucial for building robust and scalable server storage solutions. Don't use a single disk for critical data.",
                features: [
                    { title: "RAID (Redundant Array of Independent Disks)", desc: "A technology that combines multiple physical hard drives into a single logical unit to improve performance, provide data redundancy, or both. Common RAID levels: **RAID 0 (Striping)**: Speed, no redundancy. **RAID 1 (Mirroring)**: Redundancy, 50% capacity. **RAID 5 (Striping with Parity)**: Balance of speed/redundancy, N-1 capacity. **RAID 10 (Stripe of Mirrors)**: High speed *and* redundancy. Implemented via hardware or software (`mdadm` on Linux). Choose your RAID level based on your needs for speed, redundancy, and cost. Don't cheap out on redundancy for critical data." },
                    { title: "LVM (Logical Volume Manager)", desc: "A flexible storage management system that abstracts the underlying physical storage. It allows administrators to combine multiple physical volumes (partitions or disks) into a single 'volume group' (VG), from which 'logical volumes' (LVs) can be created. LVs can be dynamically resized, snapshotted, and moved, providing extreme flexibility for filesystem management without downtime. LVM is a game-changer for storage flexibility. Learn it well." },
                    { title: "Physical Volumes (PVs) - LVM", desc: "Raw block devices (e.g., `/dev/sdb1`, `/dev/sdc`) that are initialized for use by LVM. These are the fundamental building blocks of LVM storage. These are your raw disks, ready for LVM." },
                    { title: "Volume Groups (VGs) - LVM", desc: "Collections of one or more physical volumes, acting as a pool of storage. Logical volumes are carved out of volume groups. A VG can span multiple physical disks. This is your aggregated storage pool." },
                    { title: "Logical Volumes (LVs) - LVM", desc: "The equivalent of a partition in traditional disk management. LVs are created from a volume group and are what operating systems (and filesystems) interact with. They offer flexibility in size and can be resized online or offline. This is what your OS sees as a disk partition." },
                    { title: "Data Redundancy & Performance", desc: "RAID specifically focuses on these aspects. Mirroring (RAID 1/10) protects against single disk failures. Striping (RAID 0/5/10) distributes data across disks for faster read/write performance. LVM primarily offers flexibility, but can be built on top of RAID for redundancy. Combine them for the best of both worlds." }
                ],
                examples: [
                    "Creating a software RAID 1 array (mirror) from two physical disks to ensure data redundancy for a critical server: `sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1`.",
                    "Extending an existing LVM logical volume (e.g., for `/var/log`) without downtime: `sudo lvextend -L +10G /dev/vg_name/lv_log` followed by `sudo resize2fs /dev/vg_name/lv_log` (for ext4/3) or `xfs_growfs /dev/vg_name/lv_log` (for XFS).",
                    "Taking a snapshot of a logical volume before applying a major application update, allowing for instant rollback if the update fails: `sudo lvcreate --size 1G --snapshot --name lv_app_snap /dev/vg_name/lv_app`."
                ],
                technicalDetails: "RAID can be implemented in hardware (via a dedicated RAID controller card, which often means better performance but vendor lock-in) or software (via the Linux kernel's `md` (Multiple Device) driver, managed by `mdadm`, which is flexible and hardware-agnostic). LVM is a layer in the kernel's device mapper framework. It allows for online resizing of logical volumes and filesystems (with appropriate filesystem support), and efficient snapshots (copy-on-write). You typically create RAID volumes *first*, then initialize those as LVM PVs. Proper configuration and *constant monitoring* of RAID arrays (check `cat /proc/mdstat`) and LVM volumes are essential for data integrity and preventing silent data loss. Don't assume your RAID array is healthy; check it regularly!",
                tools: "mdadm (for software RAID), LVM tools (pvcreate, vgcreate, lvcreate, pvdisplay, vgdisplay, lvdisplay, lvextend, lvreduce, lvremove, lvdisplay -m), fdisk/parted (for partitioning before LVM/RAID), `smartctl` (for disk health monitoring), `/proc/mdstat`."
            },
            'backup-restore': {
                name: "Backup & Restore (tar, rsync)",
                purpose: "To create copies of files and directories for protection against data loss, corruption, or accidental deletion, and to restore that data when needed. Essential for disaster recovery and maintaining data integrity. Backups are worthless if you can't restore them. Test your restores!",
                features: [
                    { title: "tar (Tape Archiver)", desc: "A command-line utility used to create archives (collections of files and directories) and extract contents from them. It can also compress archives using gzip (`-z`), bzip2 (`-j`), or xz (`-J`). Widely used for system backups and packaging software. Example: `tar -czvf archive.tar.gz /path/to/backup`. It's old, it's robust, it preserves permissions and ownership. A true Unix workhorse." },
                    { title: "rsync (Remote Sync)", desc: "A versatile utility for efficiently synchronizing files and directories, either locally or remotely (over SSH or a daemon). It uses a 'delta-transfer' algorithm, transferring only the differences between source and destination files, making it very efficient for incremental backups and maintaining mirrors. For synchronization and incremental backups, `rsync` is unparalleled. It only moves what's changed." },
                    { title: "Full vs. Incremental Backups", desc: "**Full backup:** Copies all selected data. Simple, but consumes more space and time. **Incremental backup:** Copies only data that has changed since the last full or incremental backup. Faster and uses less space but requires the full backup and all subsequent incrementals for recovery. Understand your RPO/RTO when choosing a strategy." },
                    { title: "Compression", desc: "Reduces the size of backup archives, saving disk space and reducing transfer times. `gzip`, `bzip2`, `xz` are common compression utilities integrated with `tar` or used separately. Don't waste disk space on uncompressed backups." },
                    { title: "Remote Backups", desc: "Sending backup copies to a remote server or cloud storage for offsite protection against local disasters. `rsync` over SSH is a common method for this. **Offsite backups are non-negotiable for disaster recovery.** If your building burns down, your local backups are useless." },
                    { title: "Restore Operations", desc: "The process of retrieving data from a backup and returning it to its original location or a new location. This involves extracting archives or synchronizing data back from the backup source. This is the whole point of a backup. **Test your restore procedures regularly!** A backup you can't restore isn't a backup." }
                ],
                examples: [
                    "Creating a compressed backup of `/etc` and `/home` directories: `sudo tar -czvf /backup/system_config_$(date +%F).tar.gz /etc /home`.",
                    "Restoring files from a tar archive to the current directory: `sudo tar -xzvf archive.tar.gz`.",
                    "Performing an incremental backup of a web server's content to a remote server: `rsync -avz --delete /var/www/html/ user@remote_backup_server:/backups/website/`.",
                    "Creating a simple daily backup cron job using `tar`.",
                    "Verifying a tar archive without extracting: `tar -tzf archive.tar.gz`."
                ],
                technicalDetails: "`tar` operates by concatenating files into a single archive file (a 'tarball'), preserving metadata like permissions and timestamps. `rsync` uses a sophisticated 'rolling checksum' algorithm to efficiently identify and transfer only the changed portions of files, making it incredibly fast for incremental updates. Backup strategies often involve a combination of full and incremental/differential backups. Important considerations: storage location (local, network, cloud), encryption of backups (for sensitive data), retention policies, and most importantly, regular testing of the restore process. Don't be the sysadmin who finds out their backups were corrupt *after* a disaster.",
                tools: "tar, rsync, gzip, bzip2, xz, dd (for disk imaging, with extreme care), `dump`/`restore` (legacy filesystem-level backup), `BorgBackup` (deduplicating, encrypted backups), `Duplicity` (encrypted, incremental backups), `restic` (modern backup tool), `cron` (for scheduling)."
            },
            'os-hardening': {
                name: "OS Hardening (CIS Benchmarks)",
                purpose: "To reduce the attack surface of a Linux operating system by implementing security best practices, disabling unnecessary services, configuring secure settings, and applying principle of least privilege. The goal is to make the system more resilient to attacks. Security is not an afterthought; it's a constant battle. This is your foundation.",
                features: [
                    { title: "Principle of Least Privilege", desc: "Ensuring that users, applications, and services are granted only the minimum necessary permissions and access rights required to perform their legitimate functions. This limits the potential damage if an account or process is compromised. It's the golden rule of security: never give more access than absolutely needed." },
                    { title: "CIS Benchmarks", desc: "Security configuration guides developed by the Center for Internet Security (CIS). They provide a consensus-based set of best practices for securely configuring various operating systems (e.g., CIS Ubuntu Linux Benchmark, CIS Red Hat Enterprise Linux Benchmark), applications, and network devices. These are your blueprints for secure systems. Follow them, adapt them." },
                    { title: "Disable Unnecessary Services", desc: "Shutting down and disabling services (daemons) that are not required for the system's function. Each running service represents a potential attack vector. For example, disabling unused web servers, FTP servers, or remote desktop services. If you don't need it, turn it off. Every open port is an invitation." },
                    { title: "Secure SSH Configuration", desc: "Implementing strong SSH security (e.g., disabling password authentication, forcing key-based login, disabling root login, changing default SSH port, using strong ciphers) to protect remote access. Your primary remote access tool must be locked down tight." },
                    { title: "Firewall Configuration", desc: "Implementing a strict firewall (e.g., `iptables`, `ufw`, `firewalld`) to block all incoming connections by default and explicitly allow only necessary ports for legitimate services. Deny-by-default. No excuses." },
                    { title: "Regular Patching & Updates", desc: "Keeping the operating system, kernel, and all installed software packages up-to-date with the latest security patches to fix known vulnerabilities. Automated patch management is crucial. Unpatched systems are a joke for attackers. Update religiously." },
                    { title: "Account & Password Policies", desc: "Enforcing strong password complexity, length, and expiration policies. Implementing account lockout mechanisms for too many failed login attempts. Removing or disabling unused/default accounts. Weak passwords are an open door." },
                    { title: "Logging & Auditing", desc: "Configuring robust logging (e.g., `auditd`, `syslog`) to capture all security-relevant events, including logins, failed attempts, privilege escalations, and system modifications. Regularly reviewing these logs for suspicious activity. If you're not logging, you're blind. If you're not reviewing, you're still blind." }
                ],
                examples: [
                    "Following the CIS Ubuntu Linux Benchmark to harden a new web server: disabling the `telnet` service (`sudo systemctl disable telnet.socket`), configuring SSH to only allow key-based authentication, and setting up `ufw` to only allow HTTP, HTTPS, and SSH traffic.",
                    "Implementing a cron job to regularly check for and apply security updates using `apt` or `dnf` (`sudo apt update && sudo apt upgrade -y`).",
                    "Removing all default user accounts that are not in use and enforcing a strong password policy for all remaining users.",
                    "Restricting `su` access to a specific group using PAM rules in `/etc/pam.d/su`."
                ],
                technicalDetails: "OS hardening is a continuous, iterative process. It involves modifying numerous system configuration files (e.g., `/etc/sysctl.conf` for kernel parameters, `/etc/security/limits.conf` for resource limits, PAM files in `/etc/pam.d/`), and service configurations. Automated configuration management tools (like Ansible, Puppet, Chef) are essential for enforcing and maintaining these baselines at scale. The effectiveness of hardening should be regularly verified through internal and external vulnerability scanning and penetration testing. Don't just apply rules; understand their impact and verify they work. Security is about layers of defense, not a single silver bullet.",
                tools: "CIS Benchmarks, OpenSCAP (for automated compliance checking), Lynis (security auditing tool), SSH (for secure config), iptables/ufw/firewalld, `passwd`, `userdel`, `chmod`, `chown`, `systemctl`, `apt`/`dnf`, `auditd`, `logrotate`, `pam_cracklib` (for password strength), `faillock` (for account lockout)."
            },
            'ssh-hardening': {
                name: "SSH Hardening",
                purpose: "To secure the SSH (Secure Shell) service on Linux servers against unauthorized access, brute-force attacks, and credential compromise. This involves configuring the SSH daemon (`sshd`) to follow best practices for secure remote access. Your primary remote access tool is a prime target. Lock it down. Hard.",
                features: [
                    { title: "Disable Password Authentication", desc: "The most critical step. Configure `sshd` to only allow authentication using SSH keys (public-key cryptography) and disable traditional password logins. This makes brute-force attacks extremely difficult and eliminates password exposure. **DO THIS. NOW. No exceptions.**" },
                    { title: "Disable Root Login", desc: "Prevent direct login to the `root` account via SSH. Instead, require users to log in with a regular user account and then use `sudo` for elevated privileges. This provides an audit trail for root actions and prevents direct attacks on the root password. Login as a normal user, *then* `sudo` if needed." },
                    { title: "Change Default SSH Port", desc: "Move the SSH daemon from its default port (22) to a non-standard, high-numbered port (e.g., 2222, 22022). This is 'security by obscurity' but it drastically reduces the volume of automated brute-force attempts and port scans against the server, as most bots target the default port. It filters out the noisy attackers, saving your logs." },
                    { title: "Use Strong Ciphers & MACs", desc: "Configure `sshd` to use only strong, modern encryption ciphers (e.g., `aes256-gcm@openssh.com`) and Message Authentication Codes (MACs) to protect the confidentiality and integrity of SSH sessions, preventing known cryptographic weaknesses from being exploited. Outdated crypto is a liability." },
                    { title: "Allow only Specific Users/Groups", desc: "Restrict SSH access to a limited set of authorized users or members of a specific system group. This minimizes the attack surface by preventing unknown or unnecessary accounts from attempting SSH login. Explicitly define who can connect; deny everyone else implicitly." },
                    { title: "Login GraceTime & MaxAuthTries", desc: "Set `LoginGraceTime` (how long the server waits for successful authentication) to a low value (e.g., 30 seconds) and `MaxAuthTries` (maximum number of authentication attempts) to a small number (e.g., 3). This helps mitigate brute-force attacks by reducing the window of opportunity. Don't give attackers endless guesses." },
                    { title: "MFA Integration (Optional, Advanced)", desc: "Integrate Multi-Factor Authentication (MFA) with SSH, requiring users to provide a second factor (e.g., TOTP code from an authenticator app, hardware token) in addition to their SSH key or password. This provides a robust defense even if a private key is compromised. For ultimate security, add MFA. It's an extra layer that pays off." }
                ],
                examples: [
                    "Editing `/etc/ssh/sshd_config` to apply hardening rules, then restarting SSH: `sudo nano /etc/ssh/sshd_config`, then `sudo systemctl restart sshd`. (Backup the config first!)",
                    "Adding your public SSH key to the `authorized_keys` file on the server: `ssh-copy-id user@server_ip` (preferred) or manually copy to `~/.ssh/authorized_keys` with correct permissions (`chmod 600 ~/.ssh/authorized_keys`, `chmod 700 ~/.ssh`).",
                    "After changing the SSH port, updating firewall rules (e.g., `ufw`): `sudo ufw allow 2222/tcp`."
                ],
                technicalDetails: "SSH hardening involves modifying the `sshd` configuration file and restarting the service. Proper file permissions on `~/.ssh/` and `~/.ssh/authorized_keys` are *critical* for key-based authentication to work and to prevent unauthorized key injection. `sshd` will simply refuse connections if permissions are too broad. Tools like `fail2ban` monitor SSH logs (`/var/log/auth.log` or `journalctl -u sshd`) and dynamically update firewall rules to block suspicious IPs after repeated failed attempts. Don't just set these and forget them; regularly review your SSH logs for anomalies.",
                tools: "/etc/ssh/sshd_config, ssh-keygen, ssh-copy-id, ~/.ssh/authorized_keys, fail2ban, ufw/firewalld/iptables, `auditd` (for monitoring SSH events), `sshd_config(5)`."
            },
            'selinux-apparmor': {
                name: "SELinux & AppArmor",
                purpose: "To provide Mandatory Access Control (MAC) mechanisms on Linux systems, enhancing security by enforcing granular access rules beyond traditional Discretionary Access Control (DAC) (user/group/other permissions). They restrict what processes and users can access, even for privileged accounts like root, mitigating the impact of compromised applications. These are your ultimate last line of defense. They are not for the faint of heart, but they stop determined attackers.",
                features: [
                    { title: "SELinux (Security-Enhanced Linux)", desc: "A Linux kernel security module developed by the NSA that provides a mechanism for supporting access control security policies, including Mandatory Access Control (MAC). It labels all system resources (files, processes, ports) with security contexts and uses policy rules to define how these contexts can interact. Highly flexible but complex. It's comprehensive, powerful, and will teach you humility." },
                    { title: "AppArmor (Application Armor)", desc: "A Linux kernel security module that implements Mandatory Access Control (MAC) based on pathnames. It confines programs to a limited set of resources (files, network access, capabilities) using 'profiles' that specify permitted behaviors. Simpler to manage than SELinux, but less comprehensive in its enforcement. If SELinux feels like too much, AppArmor is a gentler introduction to MAC." },
                    { title: "Policy Enforcement", desc: "Both enforce security policies by intercepting system calls and checking them against predefined rules before allowing or denying access. This adds a crucial layer of defense, even if a vulnerable application or a root account is compromised. They prevent 'breakouts' even if standard permissions are bypassed." },
                    { title: "Deny-by-Default", desc: "A core principle: unless explicitly permitted by a policy, access is denied. This is a strong security posture, as it prevents unauthorized actions by default, requiring administrators to explicitly grant necessary permissions. If you don't allow it, it doesn't happen. Simple, secure." },
                    { title: "Container Security", desc: "Essential for container environments (e.g., Docker, Kubernetes). SELinux and AppArmor can confine containers, preventing them from breaking out of their isolation and accessing sensitive host resources or other containers, even if a vulnerability is exploited within the container. Your containers aren't truly isolated without these." },
                    { title: "Audit Logging", desc: "Both generate detailed audit logs for policy violations, providing critical information for security monitoring and forensic analysis. This helps administrators identify when a legitimate process is attempting an unauthorized action or when an attack is underway. Your first stop when something *should* work but doesn't, and for post-incident analysis." }
                ],
                examples: [
                    "A web server process (e.g., Apache, Nginx) confined by SELinux, preventing it from writing to directories outside its designated web root (`/var/www/html`), even if it gets compromised by an attacker. No web shell for you!",
                    "An AppArmor profile for a custom application, allowing it to read from its configuration directory but preventing it from writing to `/etc` or connecting to arbitrary network ports. Fine-grained control over application behavior." ,
                    "Using `setenforce 0` to temporarily set SELinux to permissive mode to troubleshoot an application issue (you'll see denials but they won't be blocked), then `setenforce 1` to re-enable enforcing mode after the issue is identified. For troubleshooting, permissive mode is your friend."
                ],
                technicalDetails: "SELinux operates at a very low level, labeling every object and subject in the kernel with a security context (e.g., `unconfined_t`, `httpd_t`). Policies define the allowed interactions between these contexts. AppArmor uses path-based profiles loaded into the kernel, which are generally easier to write and understand but less granular than SELinux. Both are kernel modules. Troubleshooting MAC issues involves checking the audit logs (primarily `/var/log/audit/audit.log` for SELinux) and using specific utilities (`sealert`, `audit2allow` for SELinux; `aa-logprof`, `aa-genprof` for AppArmor) to generate or fine-tune policies. MAC systems are complex, but they provide a crucial layer of defense against sophisticated attacks by limiting the damage an attacker can inflict *after* gaining initial access.",
                tools: "SELinux: `setenforce`, `sestatus`, `semanage`, `restorecon`, `audit2allow`, `sealert`, `/etc/selinux/config`, `chcon`. AppArmor: `aa-status`, `aa-enforce`, `aa-complain`, `aa-logprof`, `aa-genprof`, `/etc/apparmor.d/`, `apparmor_parser`."
            },
            'vulnerability-scanning': {
                name: "Vulnerability Scanning (Nessus, OpenVAS)",
                purpose: "To automatically identify known security vulnerabilities (weaknesses) in IT systems, networks, and applications. These scans provide a comprehensive assessment of an organization's exposure to common cyber threats. Don't think a scan solves your problems; it just tells you where they are. You still have to fix them.",
                features: [
                    { title: "Network Scanning", desc: "Scans network devices, servers, and workstations for open ports, running services, weak configurations, default credentials, and missing security patches. It typically uses port scanning techniques and banner grabbing to identify potential entry points. It's like knocking on every door and seeing if anyone answers, or if the door is unlocked." },
                    { title: "Operating System & Application Vulnerability Detection", desc: "Identifies vulnerabilities in operating systems (e.g., outdated kernels, insecure services) and installed applications (e.g., vulnerable web servers, unpatched software versions). It often compares installed software versions against databases of known vulnerabilities (CVEs - Common Vulnerabilities and Exposures). This is crucial for keeping your software up-to-date and secure." },
                    { title: "Compliance Auditing", desc: "Many scanners can assess systems against industry-standard benchmarks and regulatory compliance frameworks (e.g., CIS Benchmarks, PCI DSS, HIPAA), reporting on deviations from desired security configurations. For auditors, this is gold. For you, it's a checklist to ensure you're not missing obvious security gaps." },
                    { title: "Authenticated vs. Unauthenticated Scans", desc: "**Unauthenticated scan (Black-box):** Simulates an external attacker with no prior knowledge of the system. **Authenticated scan (Grey-box):** Scans with valid credentials (e.g., SSH for Linux), providing deeper insights into the system's internal configurations and missing patches, leading to more accurate results. Authenticated scans are almost always better; they give you the full picture." },
                    { title: "Reporting & Prioritization", desc: "Generates detailed reports listing identified vulnerabilities, their severity (e.g., CVSS score), potential impact, and recommended remediation steps. Scanners often include features to prioritize vulnerabilities based on risk and asset criticality. Don't just get a report; *act* on it. Prioritize the high-risk, high-impact issues." },
                    { title: "Scheduled Scanning", desc: "Allows administrators to schedule regular vulnerability scans (daily, weekly, monthly) to ensure continuous monitoring of the security posture and timely detection of new vulnerabilities. Security isn't a one-time event. Automate your scans." }
                ],
                examples: [
                    "Running a weekly authenticated vulnerability scan on all production Linux servers to identify missing security patches for the kernel, OpenSSH, and web server software (e.g., Nginx, Apache).",
                    "Performing an unauthenticated network scan of an external-facing IP range to check for any unintentionally exposed services or open ports that could be exploited by attackers.",
                    "Generating a report after a scan that highlights all high-severity vulnerabilities on critical database servers, along with recommended patches or configuration changes, then assigning these tasks to your team."
                ],
                technicalDetails: "Vulnerability scanners maintain massive databases of Common Vulnerabilities and Exposures (CVEs) and Common Weakness Enumerations (CWEs). They use various techniques: port scanning (e.g., Nmap), service banner analysis, vulnerability enumeration via authenticated checks (e.g., querying package managers like `rpm` or `dpkg` via SSH for installed versions), and exploiting publicly known vulnerabilities (with caution). Remember, scanners only find *known* vulnerabilities. They don't find zero-days. False positives (reporting non-existent vulnerabilities) and false negatives (missing actual vulnerabilities) are common challenges. Integrate scanning into your CI/CD pipeline (DevSecOps) for earlier detection.",
                tools: "Tenable Nessus (commercial), Qualys Vulnerability Management (commercial), Rapid7 InsightVM (commercial), OpenVAS (open source), Nmap (for port scanning and service detection), Lynis (Linux auditing tool), `CVE` databases, `NVD` (National Vulnerability Database)."
            },
            'audit-d': {
                name: "Auditd & System Auditing",
                purpose: "To provide a comprehensive auditing system on Linux that records system calls, file access, and other security-relevant events. It acts as a tamper-proof log of activities, crucial for security monitoring, forensic investigations, and regulatory compliance. If something bad happens, these logs are the only truth you'll get.",
                features: [
                    { title: "Audit Daemon (`auditd`)", desc: "The user-space component that collects audit records generated by the Linux kernel. It is responsible for writing these records to disk (typically `/var/log/audit/audit.log`) and can also send them to a SIEM or remote log server. This is the core component; it listens to the kernel and writes down everything interesting." },
                    { title: "Audit Rules", desc: "Administrators define rules to specify which system calls, file accesses, or events should be audited. Rules can be based on user IDs, group IDs, specific file paths, syscall types, and more. Rules are loaded into the kernel by `auditctl` or managed via configuration files (`/etc/audit/rules.d/`). Define precisely what you want to audit; don't audit everything, or you'll drown in data." },
                    { title: "Immutable Logging", desc: "Configuring `auditd` for immutable logging (e.g., setting the `immutable` boot parameter for the audit subsystem, or making the log directory read-only for non-audit users) ensures that audit logs cannot be modified or deleted, even by the root user, providing a strong defense against log tampering by attackers. If an attacker can clear your logs, they can hide their tracks. Prevent that." },
                    { title: "Real-time Monitoring & Alerting", desc: "Audit logs can be monitored in real-time. Tools and integrations can parse these logs and generate alerts for suspicious activities, such as unauthorized file modifications, privilege escalation attempts, or access to sensitive directories. Don't just collect; act on it. Connect this to your SIEM." },
                    { title: "Forensic Analysis & Reporting", desc: "Audit logs provide a detailed chronological record of system events, making them invaluable for post-incident forensic investigations. Tools like `ausearch` and `aureport` are used to search and summarize audit data for specific events or trends, crucial for compliance. This is your evidence. Learn to parse it." },
                    { title: "Compliance Requirements", desc: "Meeting various regulatory compliance standards (e.g., PCI DSS, HIPAA, SOX, NIST 800-53) often requires robust system auditing, and `auditd` is a primary tool for collecting the necessary evidence on Linux. If the auditors ask, your `auditd` logs better be there and be complete." }
                ],
                examples: [
                    "Auditing all attempts to delete or modify critical configuration files (e.g., `/etc/passwd`, `/etc/shadow`): `auditctl -w /etc/passwd -p wa -k passwd_changes` (write/attribute change, key for easy searching).",
                    "Monitoring all execution of the `sudo` command: `auditctl -a always,exit -F arch=b64 -S execve -F a0=sudo -k sudo_exec`.",
                    "Searching for all login failures from a specific IP address in audit logs: `ausearch -i --start today --end now -hn 192.168.1.10 --failed-logins`.",
                    "Generating a report of all failed logins for the past week: `aureport --failed --login -ts 'last week'`.",
                    "Testing audit rules: `auditctl -l` (list rules), `auditctl -D` (delete all rules)."
                ],
                technicalDetails: "`auditd` operates at the kernel level, using the Linux Auditing System to intercept specific system calls as they occur. It's a low-level, high-volume logging system, so careful rule tuning is essential to avoid 'audit fatigue' (overwhelming log volume) while still capturing critical events. Audit logs are written to `/var/log/audit/audit.log` (default). For security, ensure log files are only readable by root. Audit logs are typically integrated with SIEM (Security Information and Event Management) systems for centralized collection, correlation, and analysis. This provides a unified view of security events across your infrastructure. Don't just enable `auditd`; actively manage its rules and review its output.",
                tools: "auditd, auditctl, ausearch, aureport, `/etc/audit/rules.d/` (for persistent rules), `/var/log/audit/audit.log`, `logger`, rsyslog (for forwarding audit logs), SIEM systems (e.g., Splunk, QRadar, ELK Stack)."
            },
            'bash-scripting': {
                name: "Bash Scripting",
                purpose: "To automate repetitive tasks, create custom commands, and orchestrate complex operations on Linux systems. Bash scripts are sequences of shell commands executed sequentially, making administration more efficient and less prone to human error. If you're doing something more than twice, script it. If you're doing it more than ten times, automate it with Ansible. But Bash is your starting point.",
                features: [
                    { title: "Command Sequencing", desc: "Executing multiple commands in a defined order. Scripts can run commands one after another, or conditionally based on the success/failure of previous commands. This is the core: get commands to run in the right order." },
                    { title: "Variables", desc: "Storing data in named variables (e.g., `NAME=\"John\"`, `COUNT=10`). Variables allow scripts to be dynamic and reusable, taking input or storing intermediate results. Don't hardcode; use variables. It makes your scripts flexible." },
                    { title: "Conditional Logic (if/else)", desc: "Making decisions within a script based on conditions (e.g., checking if a file exists, comparing values, checking command exit status). This allows scripts to adapt their behavior to different situations. Your scripts need to be smart enough to react to different scenarios." },
                    { title: "Loops (for, while)", desc: "Repeating a set of commands multiple times. `for` loops iterate over lists of items (e.g., files, numbers). `while` loops repeat as long as a condition is true. Useful for processing multiple files or continuous monitoring. Don't copy-paste commands dozens of times; loop it." },
                    { title: "Functions", desc: "Defining reusable blocks of code within a script. Functions help organize complex scripts, improve readability, and prevent code duplication. For larger scripts, break them into functions. It makes debugging easier." },
                    { title: "Input/Output & Redirection", desc: "Reading input from the user or files (`read`), and directing output to files or other commands (piping, `>` `>>`). Essential for interactive scripts and managing data flow. Master this, it's fundamental to Unix philosophy." },
                    { title: "Error Handling & Robustness", desc: "Implementing mechanisms to detect and respond to errors gracefully. Use `set -e` (exit on first error), `set -u` (fail on unset variables), `set -o pipefail` (fail if any command in a pipeline fails). Use `trap` for signals. Always check command exit status (`$?`). Write robust scripts. Don't let them fail silently." }
                ],
                examples: [
                    "Creating a daily backup script that tars and compresses specific directories and moves the archive to a backup location.",
                    "Writing a script to monitor disk space and email an alert if usage exceeds a threshold.",
                    "Automating the deployment of a simple web application: fetching code from Git, installing dependencies, configuring Nginx, and starting the service.",
                    "A script to add multiple new users to the system based on a list in a file.",
                    "Checking if a service is running before attempting to restart: `if systemctl is-active --quiet myapp; then sudo systemctl restart myapp; fi`."
                ],
                technicalDetails: "Bash scripts are interpreted by the Bash shell itself. They execute commands in a subshell, inheriting the environment. Understanding the difference between shell built-ins (e.g., `cd`, `echo`) and external commands (e.g., `ls`, `grep`) is important for performance and behavior. Command substitution (`$(command)`) captures command output. Variable expansion, quoting rules (single vs. double quotes), and special variables (`$0`, `$1`, `$?`) are critical. Always start with `#!/bin/bash` (the shebang line) and make your scripts executable (`chmod +x script.sh`). For serious scripting, debug with `bash -x myscript.sh` and validate your syntax rigorously.",
                tools: "bash, sh, awk, sed, grep, cut, sort, uniq, find, xargs, tee, exit, functions, variables, control flow (if, for, while, case), `read`, `printf`, `test` (`[ ]`), `[[ ]]`, `source`, `export`, `man bash`."
            },
            'ansible': {
                name: "Ansible (Configuration Management)",
                purpose: "An open-source automation engine that automates software provisioning, configuration management, and application deployment. It's agentless, relying on SSH for communication, making it easy to set up and manage Linux servers at scale. If you have more than a few servers, Ansible is your friend. It scales.",
                features: [
                    { title: "Agentless Architecture", desc: "Does not require any special agent software to be installed on target Linux machines. It communicates over standard SSH protocols (or WinRM for Windows), simplifying deployment and reducing overhead on managed nodes. This is a huge advantage; no agents to install, maintain, or troubleshoot." },
                    { title: "YAML-based Playbooks", desc: "Automation tasks are defined in human-readable YAML files called 'playbooks'. Playbooks describes a desired state for systems, making them easy to write, understand, and version control. They define tasks, roles, and variables. Declarative, not imperative. Describe the *what*, not the *how*." },
                    { title: "Idempotency", desc: "Ansible operations are idempotent, meaning running the same playbook multiple times will result in the same desired state, without creating duplicate resources or unintended side effects. This ensures consistency and makes changes predictable. This is paramount for reliable automation. Run it once, run it a hundred times, same result." },
                    { title: "Modules", desc: "Pre-built, reusable units of code that perform specific tasks (e.g., installing a package, copying a file, starting a service, managing users). Ansible has a vast library of modules for managing almost any aspect of a Linux system. Don't write your own loops for packages; use the `package` module." },
                    { title: "Inventory", desc: "A list of managed nodes (servers) that Ansible can connect to. The inventory can be a simple static text file or a dynamic script that pulls host information from cloud providers or CMDBs. It groups hosts for easier targeting of tasks. Your list of targets. Organize it well." },
                    { title: "Roles", desc: "A way to organize Ansible content (tasks, handlers, variables, templates) into reusable and modular units. Roles promote best practices and make playbooks more organized and shareable for complex configurations. For complex environments, use roles. They provide structure." },
                    { title: "Templating (Jinja2)", desc: "Ansible uses Jinja2 for templating, allowing dynamic generation of configuration files or other text content within playbooks using variables and control structures. Perfect for generating `nginx.conf` or `ssh_config` based on host variables." }
                ],
                examples: [
                    "Automating the installation of a web server (Nginx) and deploying a simple static website to multiple Linux servers using a single Ansible playbook. `ansible-playbook webservers.yml`.",
                    "Ensuring all development servers have consistent security configurations (e.g., SSH hardening, firewall rules) applied automatically. `ansible-playbook security_baseline.yml`.",
                    "Patching a fleet of Linux servers by running an Ansible playbook that executes package manager updates (APT or DNF) on all targeted hosts. `ansible-playbook patch_servers.yml`.",
                    "Managing user accounts and SSH keys across dozens of Linux jump hosts, ensuring consistency and simplified access control."
                ],
                technicalDetails: "Ansible's agentless nature means it relies on SSH for transport. It pushes small Python modules to the target machine, executes them, and then removes them. This makes it very lightweight on the managed nodes. Playbooks are YAML files parsed by the Ansible control node, which then translates tasks into module calls. Its idempotency is achieved by modules checking the *current* state before making changes. For larger teams and more advanced use cases, AWX (open-source) or Ansible Tower (commercial) provide a web UI, RBAC, and API for managing Ansible executions. Ansible is a powerful tool for Infrastructure as Code (IaC) and automation, bridging the gap between developers and operations.",
                tools: "Ansible Engine, Ansible Playbooks (YAML), SSH, Python, Jinja2, Ansible Galaxy (for sharing roles), Ansible Tower/AWX (for enterprise management), `ansible-lint` (for playbook best practices)."
            },
            'python-automation': {
                name: "Python for Automation",
                purpose: "To use Python as a versatile scripting language for automating system administration tasks, data processing, network operations, and interacting with APIs on Linux systems. Its readability, extensive libraries, and cross-platform compatibility make it a popular choice. When Bash gets too hairy, Python steps in. It's the Swiss Army knife for sysadmins.",
                features: [
                    { title: "System Interaction (`os`, `subprocess`)", desc: "Python's `os` and `subprocess` modules allow scripts to interact directly with the operating system, execute shell commands, manage files and directories, and retrieve system information, making it suitable for low-level system administration. For anything more complex than a simple command, use `subprocess`." },
                    { title: "File & Directory Management", desc: "Built-in modules (`os`, `shutil`, `pathlib`) provide powerful capabilities for creating, deleting, moving, copying files and directories, checking file permissions, and traversing file systems, surpassing the capabilities of simple Bash commands for complex scenarios. Don't reinvent the wheel; Python has modules for everything." },
                    { title: "Networking & Web Interaction", desc: "Libraries like `requests` (for HTTP/S), `socket` (for low-level networking), and `paramiko` (for SSH) enable Python scripts to interact with network services, automate web requests, and securely manage remote Linux servers. Integrate with anything that has an API. It's fantastic for automating cloud interactions." },
                    { title: "Data Parsing & Manipulation", desc: "Python excels at parsing various data formats (JSON, XML, CSV, text files) and manipulating data. Libraries like `json`, `csv`, and regular expressions (`re`) are invaluable for processing log files, configuration data, and API responses. If you're dealing with structured data, Python is your friend. Stop parsing text with `awk` and `sed` for complex tasks." },
                    { title: "Error Handling & Logging", desc: "Python's `try-except` blocks provide robust error handling, allowing scripts to gracefully manage unexpected situations. The `logging` module offers a flexible framework for generating detailed and configurable log messages, crucial for debugging and auditing. Don't write silent scripts; make them verbose and resilient." },
                    { title: "External Library Ecosystem", desc: "Access to a vast ecosystem of third-party libraries (via `pip`) for almost any automation need, including cloud API integrations (e.g., Boto3 for AWS, Azure SDK), database connectors, machine learning, and data visualization. This makes Python highly versatile. Whatever you need to automate, there's probably a library for it." },
                    { title: "Virtual Environments (`venv`)", desc: "Crucial for managing Python project dependencies. `venv` creates isolated Python environments, preventing conflicts between different projects' library versions. Use them always. Don't pollute your system Python installation." }
                ],
                examples: [
                    "Writing a Python script to automatically analyze Apache web server access logs, identify the top 10 most visited pages, and generate a report.",
                    "Creating a script that uses `paramiko` to connect to multiple Linux servers via SSH, check their disk space, and send an email alert if any server is running low.",
                    "Automating the creation of user accounts, setting passwords, and assigning group memberships by reading user data from a CSV file.",
                    "A script that periodically fetches data from a REST API, processes it, and then updates a database on a local Linux server.",
                    "Using Python with `boto3` to manage AWS EC2 instances or S3 buckets from your Linux workstation."
                ],
                technicalDetails: "Python is an interpreted, high-level language. Scripts are executed by the Python interpreter. `pip` is the standard package installer, making it easy to extend Python's functionality. Virtual environments (`venv` or `conda`) are crucial for isolating project dependencies and maintaining a clean system. Python interacts with the Linux kernel through system calls, which are wrapped by modules like `os` and `subprocess`. For tasks requiring heavy interaction with external commands, Bash might be simpler. For complex logic, data manipulation, or API integration, Python is superior. It's more than just a scripting language; it's a full programming language that excels at automation.",
                tools: "Python interpreter, pip, venv, os, subprocess, shutil, pathlib, requests, paramiko, json, csv, re, logging, `argparse` (for command-line arguments), `fabric` (for remote execution), `boto3` (AWS SDK), `azure-sdk`."
            }
        };

        let currentActiveBranch = null; // Tracks the currently active main branch

        /**
         * Toggles the visibility of sub-services (categories) within a main branch.
         * Closes other open branches when a new one is opened.
         * @param {string} branchId - The ID of the branch element to toggle.
         */
        function toggleBranch(branchId) {
            const subServices = document.getElementById(branchId);
            // If there's an active branch and it's not the one just clicked, close it
            if (currentActiveBranch && currentActiveBranch !== subServices) {
                currentActiveBranch.classList.remove('active');
            }
            // Toggle the 'active' class for the clicked branch's sub-services
            subServices.classList.toggle('active');
            // Update the currentActiveBranch variable
            currentActiveBranch = subServices.classList.contains('active') ? subServices : null;
        }

        /**
         * Displays the detailed information about a Linux SysAdmin category in a modal.
         * @param {string} categoryId - The ID of the category to display.
         * @param {string} initialFeatureTitle - Optional: The title of a specific feature to show initially.
         */
        function showCategoryDetails(categoryId, initialFeatureTitle = null) {
            const data = linuxSysAdminData[categoryId];
            if (!data) return; // Exit if category data is not found

            const modalContent = document.getElementById('modalContent');
            
            // Store the current category and features for navigation
            modalContent.dataset.currentCategoryId = categoryId;
            modalContent.dataset.features = JSON.stringify(data.features.map(f => f.title));

            // Generate Features HTML with feature-tag and feature-details
            const featuresHtml = data.features.map(feature => `
                <span class="feature-tag" onclick="toggleFeatureDetails('${categoryId}', '${feature.title}')">${feature.title}</span>
            `).join('');

            const featureDetailsHtml = data.features.map((feature, index) => {
                const featureCleanId = feature.title.replace(/[\s\/.-]/g, ''); // Clean ID for direct access
                const howToStepsHtml = feature.howToSteps ? `
                    <div class="how-to-steps">
                        <h3>💡 How-to Steps:</h3>
                        <ol>
                            ${feature.howToSteps.map(step => `<li>${step}</li>`).join('')}
                        </ol>
                    </div>
                ` : ''; // Only render if howToSteps exist

                return `
                    <div id="feature-details-${categoryId}-${featureCleanId}" class="feature-details">
                        <div class="sub-feature">
                            <div class="sub-feature-title">${feature.title}</div>
                            <div class="sub-feature-desc">${feature.desc}</div>
                        </div>
                        ${howToStepsHtml} <!-- Include How-to Steps here -->
                        <div class="feature-nav">
                            <button ${index === 0 ? 'disabled' : ''} onclick="navigateFeature('${categoryId}', ${index + 1})">Previous Feature</button>
                            <span>${index + 1} / ${data.features.length}</span>
                            <button ${index === data.features.length - 1 ? 'disabled' : ''} onclick="navigateFeature('${categoryId}', ${index + 1})">Next Feature</button>
                        </div>
                    </div>
                `;
            }).join('');

            // Populate the modal with category details
            modalContent.innerHTML = `
                <h2>${data.name}</h2>
                <p class="category-desc">${data.purpose}</p>
                <div style="display: flex; gap: 10px; margin-top: 10px; flex-wrap: wrap;">
                    <button class="llm-action-button" onclick="summarizeCategoryPurpose('${data.name}', '${data.purpose}', this)">Summarize Purpose ✨</button>
                    <button class="llm-action-button" onclick="generateMoreExamples('${data.name}', '${data.examples.join(', ')}', this)">Suggest More Examples ✨</button>
                    <button class="llm-action-button" onclick="explainTechnicalDetails('${data.name}', '${data.technicalDetails}', this)">Explain Technical Details ✨</button>
                </div>
                <div id="llm-category-output" class="llm-output-area" style="display: none;"></div>
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>🌟 Key Features (click to expand)</h3>
                <div class="features" id="feature-tags-container">
                    ${featuresHtml}
                </div>
                ${featureDetailsHtml}
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>🎯 Examples / Use Cases</h3>
                <div class="scenario-box">
                    <ul class="use-cases-list">
                        ${data.examples.map(example => `<li>${example}</li>`).join('')}
                    </ul>
                </div>
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>💻 Technical Details</h3>
                <div class="tech-stack-list">
                    <p>${data.technicalDetails}</p>
                </div>
                <hr style="margin: 20px 0; border-color: rgba(255,255,255,0.1);">

                <h3>🛠️ Common Tools</h3>
                <div class="pricing-info-box">
                    <p>${data.tools}</p>
                </div>
            `;
            document.getElementById('categoryModal').style.display = 'block'; // Show the modal

            // Automatically show the first feature details or a specified one
            if (data.features.length > 0) {
                const featureToShow = initialFeatureTitle || data.features[0].title;
                toggleFeatureDetails(categoryId, featureToShow); // Fixed: Changed newFeatureTitle to featureToShow
            }
        }

        /**
         * Toggles the visibility of specific feature details within the category modal.
         * Ensures only one feature detail section is open at a time.
         * @param {string} categoryId - The ID of the current category.
         * @param {string} featureTitle - The title of the feature to toggle.
         */
        function toggleFeatureDetails(categoryId, featureTitle) {
            // Clean ID for consistency with how it's generated
            const featureCleanId = featureTitle.replace(/[\s\/.-]/g, '');
            const featureId = `feature-details-${categoryId}-${featureCleanId}`;
            const featureDetailsElement = document.getElementById(featureId);

            // Get all feature tags and feature details elements within the current modal
            const allFeatureDetailsInModal = document.querySelectorAll('#modalContent .feature-details');
            const allFeatureTagsInModal = document.querySelectorAll('#modalContent .feature-tag');

            // Deactivate all tags and hide all details initially
            allFeatureTagsInModal.forEach(tag => tag.classList.remove('active-tag'));
            allFeatureDetailsInModal.forEach(element => element.classList.remove('active'));

            // Activate the clicked tag and show its corresponding details
            const clickedTag = document.querySelector(`#feature-tags-container .feature-tag[onclick*="toggleFeatureDetails('${categoryId}', '${featureTitle}')"]`);
            if (clickedTag) {
                clickedTag.classList.add('active-tag');
            }
            if (featureDetailsElement) {
                featureDetailsElement.classList.add('active');
            }
        }

        /**
         * Navigates to the previous or next feature within the currently open category modal.
         * @param {string} categoryId - The ID of the current category.
         * @param {number} newIndex - The index of the feature to navigate to.
         */
        function navigateFeature(categoryId, newIndex) {
            const modalContent = document.getElementById('modalContent');
            const features = JSON.parse(modalContent.dataset.features);

            if (newIndex >= 0 && newIndex < features.length) {
                const newFeatureTitle = features[newIndex];
                toggleFeatureDetails(categoryId, newFeatureTitle);
            }
        }

        /**
         * Closes the category details modal.
         */
        function closeModal() {
            document.getElementById('categoryModal').style.display = 'none';
            // Optionally, clear modal content or reset state when closing
            document.getElementById('modalContent').innerHTML = '';
        }

        // Close modal when clicking outside of it
        window.onclick = function(event) {
            const modal = document.getElementById('categoryModal');
            if (event.target == modal) {
                closeModal(); // Use the existing closeModal function
            }
        }

        // LLM specific functions
        /**
         * Summarizes the given category purpose using the Gemini API.
         * @param {string} categoryName - The name of the Linux SysAdmin category.
         * @param {string} purpose - The category purpose to summarize.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function summarizeCategoryPurpose(categoryName, purpose, buttonElement) {
            const prompt = `Summarize the purpose of "${categoryName}" in Linux System Administration concisely in 2-3 sentences:\n\n"${purpose}"`;
            await callGeminiAPI(prompt, 'llm-category-output', buttonElement);
        }

        /**
         * Generates new examples for a given Linux SysAdmin category using the Gemini API.
         * @param {string} categoryName - The name of the Linux SysAdmin category.
         * @param {string} existingExamples - Comma-separated existing examples.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function generateMoreExamples(categoryName, existingExamples, buttonElement) {
            const prompt = `Given the Linux System Administration category "${categoryName}" with existing examples: "${existingExamples}", suggest 2-3 additional distinct real-world examples or use cases in bullet point format, specifically highlighting Linux command-line scenarios.`;
            await callGeminiAPI(prompt, 'llm-category-output', buttonElement);
        }

        /**
         * Explains the technical details for a given Linux SysAdmin category using the Gemini API.
         * @param {string} categoryName - The name of the Linux SysAdmin category.
         * @param {string} technicalDetails - The existing technical details.
         * @param {HTMLElement} buttonElement - The button element that triggered the call.
         */
        async function explainTechnicalDetails(categoryName, technicalDetails, buttonElement) {
            const prompt = `Elaborate on the technical details for the Linux System Administration feature "${categoryName}" based on this information: "${technicalDetails}". Explain how it fundamentally works and any relevant underlying technologies or concepts in a Linux context. Keep it concise (3-5 sentences).`;
            await callGeminiAPI(prompt, 'llm-category-output', buttonElement);
        }

        /**
         * Calls the Gemini API with a given prompt and displays the response.
         * @param {string} prompt - The text prompt to send to the LLM.
         * @param {string} outputElementId - The ID of the HTML element where the response should be displayed.
         * @param {HTMLElement} buttonElement - The button element that triggered the call, to manage its state.
         */
        async function callGeminiAPI(prompt, outputElementId, buttonElement) {
            const outputElement = document.getElementById(outputElementId);
            const originalButtonText = buttonElement.innerHTML; // Store original button text

            outputElement.style.display = 'block'; // Ensure output area is visible
            outputElement.innerHTML = '<div class="loading-indicator"></div> Loading AI response...'; // Show loading

            buttonElement.disabled = true; // Disable button during API call
            buttonElement.innerHTML = `<div class="loading-indicator"></div> Thinking...`; // Change button text to show loading

            try {
                let chatHistory = [];
                chatHistory.push({ role: "user", parts: [{ text: prompt }] });
                const payload = { contents: chatHistory };
                const apiKey = ""; // Canvas will automatically provide the API key here.
                const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`HTTP error! status: ${response.status}, message: ${errorText}`);
                }

                const result = await response.json();

                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    const text = result.candidates[0].content.parts[0].text;
                    outputElement.innerHTML = text; // Display the response
                } else {
                    outputElement.innerHTML = 'Error: Could not get a valid response from the AI. Unexpected structure.';
                }
            } catch (error) {
                outputElement.innerHTML = `Error: Failed to connect to AI. Details: ${error.message}`;
            } finally {
                buttonElement.innerHTML = originalButtonText; // Restore button text
                buttonElement.disabled = false; // Re-enable button
            }
        }

        // Draggable functionality for the floating search bar
        let isDragging = false;
        let offset = { x: 0, y: 0 };
        const floatingSearchElement = document.getElementById('floatingAISearch');

        floatingSearchElement.addEventListener('mousedown', (e) => {
            // Only start dragging if the bar is not expanded or if the click is on the toggle button itself
            if (!floatingSearchElement.classList.contains('expanded') || e.target.closest('.search-toggle-button')) {
                isDragging = true;
                offset = {
                    x: e.clientX - floatingSearchElement.getBoundingClientRect().left,
                    y: e.clientY - floatingSearchElement.getBoundingClientRect().top
                };
                floatingSearchElement.style.cursor = 'grabbing';
            }
        });

        document.addEventListener('mousemove', (e) => {
            if (!isDragging) return;

            // Calculate new position
            let newX = e.clientX - offset.x;
            let newY = e.clientY - offset.y;

            // Get viewport dimensions to constrain dragging
            const viewportWidth = window.innerWidth;
            const viewportHeight = window.innerHeight;
            const elementWidth = floatingSearchElement.offsetWidth;
            const elementHeight = floatingSearchElement.offsetHeight;

            // Constrain newX to stay within viewport bounds
            newX = Math.max(0, Math.min(newX, viewportWidth - elementWidth));
            // Constrain newY to stay within viewport bounds
            newY = Math.max(0, Math.min(newY, viewportHeight - elementHeight));

            // Set position using left/top (overriding right/bottom)
            floatingSearchElement.style.left = `${newX}px`;
            floatingSearchElement.style.top = `${newY}px`;
            floatingSearchElement.style.right = 'auto'; // Disable right/bottom positioning when dragging via left/top
            floatingSearchElement.style.bottom = 'auto';
        });

        document.addEventListener('mouseup', () => {
            isDragging = false;
            floatingSearchElement.style.cursor = floatingSearchElement.classList.contains('expanded') ? 'auto' : 'grab';
        });

        /**
         * Toggles the visibility and expanded state of the floating AI search bar.
         * Also handles dynamic positioning (left/right) based on current location.
         */
        function toggleFloatingSearch() {
            const floatingSearch = document.getElementById('floatingAISearch');
            const searchIcon = document.getElementById('searchIcon');

            // Get current position before toggling the class
            const currentLeft = floatingSearch.getBoundingClientRect().left;
            const viewportWidth = window.innerWidth;

            floatingSearch.classList.toggle('expanded');

            if (floatingSearch.classList.contains('expanded')) {
                searchIcon.textContent = '✖'; // Change icon to close
                document.getElementById('ai-search-input').focus(); // Focus on input when expanded

                // Determine whether to open to the left or right
                if (currentLeft > (viewportWidth / 2)) {
                    // It's on the right half, open to the left
                    floatingSearch.style.right = '20px';
                    floatingSearch.style.left = 'auto'; // Ensure left is auto
                } else {
                    // It's on the left half, open to the right
                    floatingSearch.style.left = '20px';
                    floatingSearch.style.right = 'auto'; // Ensure right is auto
                }
                // Ensure top is maintained or set if not dragged
                if (floatingSearch.style.top === 'auto' || floatingSearch.style.top === '') {
                    floatingSearch.style.bottom = '20px';
                    floatingSearch.style.top = 'auto';
                }

            } else {
                searchIcon.textContent = '🔍'; // Change icon to default
                document.getElementById('ai-search-output').style.display = 'none'; // Hide output when collapsed
                document.getElementById('ai-search-output').innerHTML = ''; // Clear output when collapsed
                document.getElementById('ai-search-input').value = ''; // Clear input when collapsed

                // Reset position to default bottom-right on collapse
                floatingSearch.style.right = '20px';
                floatingSearch.style.bottom = '20px';
                floatingSearch.style.left = 'auto';
                floatingSearch.style.top = 'auto';
            }
        }

        // Remove onclick from central node as it does nothing in this version
        document.querySelector('.central-node').onclick = null;
    </script>
</body>
</html>
